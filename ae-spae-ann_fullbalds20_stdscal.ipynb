{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# TensorFlow wizardry\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Donâ€™t pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "from keras import optimizers, regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Activation, Dense, Dropout, Input\n",
    "from keras import backend as k\n",
    "\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "#k.tensorflow_backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Import modules------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(23)\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from datetime import datetime \n",
    "import os.path\n",
    "\n",
    "dsnum=20\n",
    "verbose_level=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/01Code/00Datasets_final/00BalancedDS/FullCloneID20bal_stdscal.csv\n"
     ]
    }
   ],
   "source": [
    "pathds = os.path.abspath('/home/user/01Code/00Datasets_final/00BalancedDS')\n",
    "file_name = \"FullCloneID\"+str(dsnum)+\"bal_stdscal.csv\"\n",
    "full_path = os.path.join(pathds,file_name)\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2686202, 67)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "neurons=df.shape[1]-1\n",
    "batch_size=df.shape[1]-1\n",
    "# batch_size=(df.shape[1]-1)*2\n",
    "\n",
    "print(neurons)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Explaining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1343101\n",
      "Class 1: 1343101\n",
      "Proportion: 1.0 : 1\n"
     ]
    }
   ],
   "source": [
    "#if you don't have an intuitive sense of how imbalanced these two classes are, let's go visual\n",
    "count_classes = pd.value_counts(df['class'], sort = True)\n",
    "print('Class 0:', count_classes[0])\n",
    "print('Class 1:', count_classes[1])\n",
    "print('Proportion:', round(count_classes[0] / count_classes[1], 3), ': 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.xticks(range(2), ['Normal [0]','Malicious [1]'])\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed and percentage of test data\n",
    "RANDOM_SEED = 23 #used to help randomly select the data points\n",
    "TEST_PCT = 0.20 # 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df, test_size=TEST_PCT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ df -> original dataset \n",
    "+ train -> subset of 80% from original dataset \n",
    "+ test_df -> subset of 20% from original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df = train_test_split(train, test_size=TEST_PCT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train -> subset of 80% from original dataset \n",
    "+ train_df -> subset of 80% from train\n",
    "+ dev_df -> subset of 20% from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000465341374433\n",
      "0.49896578120164825\n",
      "0.5006784664610482\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of mal samples in train and test set\n",
    "print(train_df.iloc[:, batch_size].sum()/train_df.shape[0]) \n",
    "print(dev_df.iloc[:, batch_size].sum()/dev_df.shape[0]) \n",
    "print(test_df.iloc[:, batch_size].sum()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.iloc[:, :batch_size] \n",
    "dev_x = dev_df.iloc[:, :batch_size] \n",
    "test_x = test_df.iloc[:, :batch_size] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train_x -> features of train_df **Training subset for AE**\n",
    "+ dev_x -> features of dev_df **Validation subset for AE**\n",
    "+ test_x -> features of test_df **Testing subset for ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final train and test sets\n",
    "train_y = train_df.iloc[:,batch_size]\n",
    "dev_y = dev_df.iloc[:,batch_size]\n",
    "test_y = test_df.iloc[:,batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train_y -> **Labels for supervised training of ANN**\n",
    "+ dev_y -> labels of dev_df  *not used for AE neither ANN*\n",
    "+ test_y -> labels of test_df  **Ground Truth for predictions of supervised ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "train_x =np.array(train_x)\n",
    "dev_x =np.array(dev_x)\n",
    "test_x = np.array(test_x)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "dev_y = np.array(dev_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "print(train_x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae(factor_enc_dim, enc_activation, dec_activation, \n",
    "                optimizer, loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer #RELU\n",
    "    encoded = Dense(encoding_dim, activation=enc_activation, name='encoded_bottle_neck')(input_data)\n",
    "    ### Define decoding layer #SIMOID\n",
    "    decoded = Dense(train_x.shape[1], activation=dec_activation)(encoded)\n",
    "    ### Create the autoencoder model\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(autoencoder.summary())\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return autoencoder,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spae(factor_enc_dim,dec_activation,enc_activation,\n",
    "         optimizer,loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer\n",
    "    encoded = Dense(encoding_dim, activity_regularizer=regularizers.l1(1e-4), activation=enc_activation, name='encoded_bottle_neck')(input_data)\n",
    "    ### Define decoding layer\n",
    "    decoded = Dense(train_x.shape[1], activation=dec_activation)(encoded)\n",
    "    ### Create the autoencoder model\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(autoencoder.summary())\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return autoencoder,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pca(thr):\n",
    "    #train_x_pca,test_x_pca = to_pca(0.95)\n",
    "    pca = PCA(n_components = thr, svd_solver = 'full')\n",
    "    train_x_ = np.array(train_x)\n",
    "    print(type(train_x_))\n",
    "\n",
    "    test_x_ = np.array(test_x)\n",
    "    print(type(test_x_))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(time.ctime(start_time))\n",
    "\n",
    "    train_x_pca = pca.fit_transform(train_x_)\n",
    "    print(train_x_pca.shape)\n",
    "\n",
    "    test_x_pca = pca.fit_transform(test_x_)\n",
    "    print(test_x_pca.shape)\n",
    "\n",
    "    elapsed_time = (time.time() - start_time)\n",
    "\n",
    "    print(\"--- PCA spent %s seconds ---\" %elapsed_time )\n",
    "    \n",
    "    return  train_x_pca,test_x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ae(checkpoint_file, autoencoder,\n",
    "           epochs, batch_size, shuffle):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    cp = ModelCheckpoint(filepath=checkpoint_file,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=verbose_level)\n",
    "\n",
    "    tb = TensorBoard(log_dir='./logs',\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=True)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))\n",
    "\n",
    "    hist_auto = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    verbose=verbose_level,\n",
    "                    callbacks=[early_stopping, cp, tb],\n",
    "                    validation_data=(dev_x, dev_x))\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "    \n",
    "    return hist_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_auto(hist_auto, fig_file):\n",
    "    best_loss_value = hist_auto.history['loss'][-1]\n",
    "    print('Best loss value:', best_loss_value)\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.figure()\n",
    "    plt.plot(hist_auto.history['loss'])\n",
    "    plt.plot(hist_auto.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.savefig(fig_file)\n",
    "    plt.show()\n",
    "    \n",
    "    return best_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h(neurons,encoded_train_x,init_mode,activation_input,\n",
    "               weight_constraint,dropout_rate,activation_output,\n",
    "               loss,optimizer):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(int(neurons-int(neurons/4)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "\n",
    "    model.add(Dense(int(neurons-int((neurons/4)*2)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h_():\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=input_dim,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(int(neurons-int(neurons/4)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "\n",
    "    model.add(Dense(int(neurons-int((neurons/4)*2)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_fit(checkpoint_file,ann,enc_train_x,train_y,epochs,shuffle,batch_size):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    cp = ModelCheckpoint(filepath=checkpoint_file,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=verbose_level)\n",
    "\n",
    "    tb = TensorBoard(log_dir='./logs',\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=True)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))\n",
    "\n",
    "    history = ann.fit(enc_train_x,\n",
    "                      train_y,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[early_stopping, cp, tb],\n",
    "                      epochs=epochs,\n",
    "                      shuffle=shuffle,\n",
    "                      batch_size=batch_size,\n",
    "                      verbose=verbose_level)\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict(ann,enc_test_x):\n",
    "    pred_ann_prob = ann.predict(enc_test_x)\n",
    "    pred_ann_prob.shape\n",
    "    pred_ann_prob = pred_ann_prob[:,0]\n",
    "    pred_ann_01 = np.where(pred_ann_prob > 0.5, 1, 0)\n",
    "    \n",
    "    #Print accuracy\n",
    "    acc_ann = accuracy_score(test_y, pred_ann_01)\n",
    "    print('Overall accuracy of Neural Network model:', acc_ann)\n",
    "\n",
    "    classiBM = \"NN\"\n",
    "    preBM = (sm.precision_score(test_y, pred_ann_01)*100) \n",
    "    recallBM = (sm.recall_score(test_y, pred_ann_01)*100) \n",
    "    f1scoreBM = (sm.f1_score(test_y, pred_ann_01)*100)\n",
    "    print(sm.classification_report(test_y, pred_ann_01,digits=4))\n",
    "    \n",
    "    return pred_ann_prob, pred_ann_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict_():\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))  \n",
    "\n",
    "    modelk = KerasClassifier(build_fn=ann_2h_,\n",
    "                             epochs=epochs, \n",
    "                             batch_size=batch_size, \n",
    "                             verbose=verbose_level\n",
    "                            )\n",
    "\n",
    "    pred_ann_prob = cross_val_predict(modelk,\n",
    "                                      enc_test_x,\n",
    "                                      test_y,\n",
    "                                      cv=KFold(n_splits=5, random_state=23),\n",
    "                                      verbose=1)\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "    pred_ann_prob.shape\n",
    "    pred_ann_prob = pred_ann_prob[:,0]\n",
    "    pred_ann_01 = np.where(pred_ann_prob > 0.5, 1, 0)\n",
    "\n",
    "    #Print accuracy\n",
    "    acc_ann = accuracy_score(test_y, pred_ann_01)\n",
    "    print('Overall accuracy of Neural Network model:', acc_ann)\n",
    "\n",
    "    classiBM = \"NN\"\n",
    "    preBM = (sm.precision_score(test_y, pred_ann_01)*100) \n",
    "    recallBM = (sm.recall_score(test_y, pred_ann_01)*100) \n",
    "    f1scoreBM = (sm.f1_score(test_y, pred_ann_01)*100)\n",
    "    print(sm.classification_report(test_y, pred_ann_01,digits=4))\n",
    "    \n",
    "    return pred_ann_prob,pred_ann_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_cm(pred_ann_prob, pred_ann_01, roc_file, cm_file):\n",
    "    false_positive_rate, recall, thresholds = roc_curve(test_y, pred_ann_prob)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    plt.figure()\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Fall-out (1-Specificity)')\n",
    "    plt.savefig(roc_file)\n",
    "    plt.show()\n",
    "    \n",
    "    cm = confusion_matrix(test_y, pred_ann_01)\n",
    "    labels = ['Normal', 'Malicious']\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm,xticklabels=labels, yticklabels=labels, annot=True, fmt='d', cmap=\"RdYlGn\", vmin = 0.2);\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.savefig(cm_file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- PCA Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_pca,test_x_pca = to_pca(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- AE Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/envs/deepl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 66)                0         \n",
      "_________________________________________________________________\n",
      "encoded_bottle_neck (Dense)  (None, 44)                2948      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 66)                2970      \n",
      "=================================================================\n",
      "Total params: 5,918\n",
      "Trainable params: 5,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ae_sigmoid_adam_mse,enc_train_x_asam,enc_test_x_asam = ae(factor_enc_dim = 1.5,\n",
    "                                                          enc_activation = 'relu',\n",
    "                                                          dec_activation = 'sigmoid',\n",
    "                                                          optimizer='Adam',\n",
    "                                                          loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_sigmoid_adam_mse = load_model('ae_sigmoid_adam_mse_redds10bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  1 16:25:57 2019\n",
      "Train on 1719168 samples, validate on 429793 samples\n",
      "Epoch 1/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.1979 - val_loss: 0.1575 - val_acc: 0.1939\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15752, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 2/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.1979 - val_loss: 0.1575 - val_acc: 0.1968\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15752 to 0.15752, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 3/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.2057 - val_loss: 0.1575 - val_acc: 0.2208\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15752 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 4/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.2265 - val_loss: 0.1575 - val_acc: 0.2314\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 5/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.2353 - val_loss: 0.1575 - val_acc: 0.2272\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 6/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1568 - acc: 0.2350 - val_loss: 0.1575 - val_acc: 0.2298\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 7/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.2238 - val_loss: 0.1575 - val_acc: 0.2254\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 8/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.2218 - val_loss: 0.1575 - val_acc: 0.2139\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 9/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.2120 - val_loss: 0.1575 - val_acc: 0.2072\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 10/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1568 - acc: 0.2088 - val_loss: 0.1575 - val_acc: 0.2092\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 11/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2089 - val_loss: 0.1575 - val_acc: 0.2065\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 12/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2036 - val_loss: 0.1575 - val_acc: 0.1976\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 13/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2000 - val_loss: 0.1575 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.15751\n",
      "Epoch 14/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1966 - val_loss: 0.1575 - val_acc: 0.1934\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 15/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1958 - val_loss: 0.1575 - val_acc: 0.1946\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 16/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1951 - val_loss: 0.1575 - val_acc: 0.1910\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 17/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1939 - val_loss: 0.1575 - val_acc: 0.1927\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 18/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1926 - val_loss: 0.1575 - val_acc: 0.1903\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 19/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1903 - val_loss: 0.1575 - val_acc: 0.1889\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 20/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1894 - val_loss: 0.1575 - val_acc: 0.1890\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 21/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1898 - val_loss: 0.1575 - val_acc: 0.1900\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 22/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1914 - val_loss: 0.1575 - val_acc: 0.1927\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 23/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1954 - val_loss: 0.1575 - val_acc: 0.1946\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 24/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1963 - val_loss: 0.1575 - val_acc: 0.1972\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 25/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1980 - val_loss: 0.1575 - val_acc: 0.1978\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 26/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1996 - val_loss: 0.1575 - val_acc: 0.2006\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 27/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2006 - val_loss: 0.1575 - val_acc: 0.1999\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 28/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2006 - val_loss: 0.1575 - val_acc: 0.2004\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 29/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2022 - val_loss: 0.1575 - val_acc: 0.2024\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 30/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2041 - val_loss: 0.1575 - val_acc: 0.2067\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 31/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2061 - val_loss: 0.1575 - val_acc: 0.2067\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15751\n",
      "Epoch 32/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2099 - val_loss: 0.1575 - val_acc: 0.2072\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.15751 to 0.15751, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 33/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2084 - val_loss: 0.1575 - val_acc: 0.2068\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15751\n",
      "Epoch 34/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2217 - val_loss: 0.1574 - val_acc: 0.2235\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.15751 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 35/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2206 - val_loss: 0.1574 - val_acc: 0.2121\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 36/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2162 - val_loss: 0.1574 - val_acc: 0.2107\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 37/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2122 - val_loss: 0.1574 - val_acc: 0.2086\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 38/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2094 - val_loss: 0.1574 - val_acc: 0.2097\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 39/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2107 - val_loss: 0.1574 - val_acc: 0.2116\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 40/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2134 - val_loss: 0.1574 - val_acc: 0.2152\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 41/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2139 - val_loss: 0.1574 - val_acc: 0.2157\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 42/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2065 - val_loss: 0.1574 - val_acc: 0.2060\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.15743\n",
      "Epoch 43/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2076 - val_loss: 0.1574 - val_acc: 0.2103\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 44/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2072 - val_loss: 0.1574 - val_acc: 0.2037\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.15743\n",
      "Epoch 45/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2066 - val_loss: 0.1574 - val_acc: 0.2103\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.15743\n",
      "Epoch 46/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2082 - val_loss: 0.1574 - val_acc: 0.1916\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 47/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2040 - val_loss: 0.1574 - val_acc: 0.2061\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 48/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2075 - val_loss: 0.1574 - val_acc: 0.2064\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.15743\n",
      "Epoch 49/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2151 - val_loss: 0.1574 - val_acc: 0.2249\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.15743 to 0.15743, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 50/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2203 - val_loss: 0.1574 - val_acc: 0.2167\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.15743 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 51/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2166 - val_loss: 0.1574 - val_acc: 0.2127\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.15742\n",
      "Epoch 52/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.2196 - val_loss: 0.1574 - val_acc: 0.2423\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 53/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.2322 - val_loss: 0.1574 - val_acc: 0.2218\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 54/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2174 - val_loss: 0.1574 - val_acc: 0.2106\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 55/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2081 - val_loss: 0.1574 - val_acc: 0.2047\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.15742\n",
      "Epoch 56/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2043 - val_loss: 0.1574 - val_acc: 0.2022\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.15742\n",
      "Epoch 57/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2038 - val_loss: 0.1574 - val_acc: 0.2048\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 58/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2024 - val_loss: 0.1574 - val_acc: 0.2010\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 59/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2012 - val_loss: 0.1574 - val_acc: 0.1998\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 60/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.2004 - val_loss: 0.1574 - val_acc: 0.1982\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 61/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.2000 - val_loss: 0.1574 - val_acc: 0.1984\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 62/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1995 - val_loss: 0.1574 - val_acc: 0.1974\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 63/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1990 - val_loss: 0.1574 - val_acc: 0.1982\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 64/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1988 - val_loss: 0.1574 - val_acc: 0.1974\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 65/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1976 - val_loss: 0.1574 - val_acc: 0.1955\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 66/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1969 - val_loss: 0.1574 - val_acc: 0.1948\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 67/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1950 - val_loss: 0.1574 - val_acc: 0.1928\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 68/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1936 - val_loss: 0.1574 - val_acc: 0.1919\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 69/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1942 - val_loss: 0.1574 - val_acc: 0.1957\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.15742\n",
      "Epoch 70/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1970 - val_loss: 0.1574 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 71/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1946 - val_loss: 0.1574 - val_acc: 0.1925\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 72/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1940 - val_loss: 0.1574 - val_acc: 0.1922\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 73/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1907 - val_loss: 0.1574 - val_acc: 0.1972\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 74/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1935 - val_loss: 0.1574 - val_acc: 0.1860\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 75/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1843 - val_loss: 0.1574 - val_acc: 0.1801\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 76/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1813 - val_loss: 0.1574 - val_acc: 0.1875\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 77/200\n",
      "1719168/1719168 [==============================] - 23s 13us/step - loss: 0.1567 - acc: 0.1788 - val_loss: 0.1574 - val_acc: 0.1754\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.15742 to 0.15742, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 78/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1753 - val_loss: 0.1574 - val_acc: 0.1729\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.15742 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 79/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1711 - val_loss: 0.1574 - val_acc: 0.1704\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 80/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1724 - val_loss: 0.1574 - val_acc: 0.1748\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.15741\n",
      "Epoch 81/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1699 - val_loss: 0.1574 - val_acc: 0.1704\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 82/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1720 - val_loss: 0.1574 - val_acc: 0.1778\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.15741\n",
      "Epoch 83/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1763 - val_loss: 0.1574 - val_acc: 0.1736\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 84/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1725 - val_loss: 0.1574 - val_acc: 0.1706\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 85/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1716 - val_loss: 0.1574 - val_acc: 0.1706\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 86/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1718 - val_loss: 0.1574 - val_acc: 0.1705\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 87/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1567 - acc: 0.1709 - val_loss: 0.1574 - val_acc: 0.1690\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 88/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1712 - val_loss: 0.1574 - val_acc: 0.1721\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 89/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1735 - val_loss: 0.1574 - val_acc: 0.1742\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 90/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1567 - acc: 0.1765 - val_loss: 0.1574 - val_acc: 0.1759\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 91/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1773 - val_loss: 0.1574 - val_acc: 0.1763\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 92/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1777 - val_loss: 0.1574 - val_acc: 0.1807\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 93/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1774 - val_loss: 0.1574 - val_acc: 0.1801\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 94/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1796 - val_loss: 0.1574 - val_acc: 0.1755\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 95/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1758 - val_loss: 0.1574 - val_acc: 0.1759\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 96/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1799 - val_loss: 0.1574 - val_acc: 0.1796\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 97/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1810 - val_loss: 0.1574 - val_acc: 0.1784\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 98/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1788 - val_loss: 0.1574 - val_acc: 0.1800\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.15741\n",
      "Epoch 99/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1835 - val_loss: 0.1574 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 100/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1786 - val_loss: 0.1574 - val_acc: 0.1914\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.15741\n",
      "Epoch 101/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1958 - val_loss: 0.1574 - val_acc: 0.1925\n",
      "\n",
      "Epoch 00101: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 102/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1883 - val_loss: 0.1574 - val_acc: 0.1874\n",
      "\n",
      "Epoch 00102: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 103/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1847 - val_loss: 0.1574 - val_acc: 0.1835\n",
      "\n",
      "Epoch 00103: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 104/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1830 - val_loss: 0.1574 - val_acc: 0.1835\n",
      "\n",
      "Epoch 00104: val_loss improved from 0.15741 to 0.15741, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 105/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1851 - val_loss: 0.1574 - val_acc: 0.1928\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.15741\n",
      "Epoch 106/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1920 - val_loss: 0.1574 - val_acc: 0.1871\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.15741\n",
      "Epoch 107/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1877 - val_loss: 0.1574 - val_acc: 0.1862\n",
      "\n",
      "Epoch 00107: val_loss improved from 0.15741 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 108/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1880 - val_loss: 0.1574 - val_acc: 0.1889\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.15740\n",
      "Epoch 109/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1876 - val_loss: 0.1574 - val_acc: 0.2000\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 0.15740\n",
      "Epoch 110/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1914 - val_loss: 0.1574 - val_acc: 0.1847\n",
      "\n",
      "Epoch 00110: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 111/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1864 - val_loss: 0.1574 - val_acc: 0.1837\n",
      "\n",
      "Epoch 00111: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 112/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1833 - val_loss: 0.1574 - val_acc: 0.1941\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.15740\n",
      "Epoch 113/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1930 - val_loss: 0.1574 - val_acc: 0.1883\n",
      "\n",
      "Epoch 00113: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 114/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1903 - val_loss: 0.1574 - val_acc: 0.1881\n",
      "\n",
      "Epoch 00114: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 115/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1888 - val_loss: 0.1574 - val_acc: 0.1882\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.15740\n",
      "Epoch 116/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1872 - val_loss: 0.1574 - val_acc: 0.1848\n",
      "\n",
      "Epoch 00116: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 117/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1859 - val_loss: 0.1574 - val_acc: 0.1840\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 118/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1854 - val_loss: 0.1574 - val_acc: 0.1837\n",
      "\n",
      "Epoch 00118: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 119/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1837 - val_loss: 0.1574 - val_acc: 0.1822\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.15740\n",
      "Epoch 120/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1817 - val_loss: 0.1574 - val_acc: 0.1811\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.15740\n",
      "Epoch 121/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1804 - val_loss: 0.1574 - val_acc: 0.1796\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.15740\n",
      "Epoch 122/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1794 - val_loss: 0.1574 - val_acc: 0.1792\n",
      "\n",
      "Epoch 00122: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 123/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1800 - val_loss: 0.1574 - val_acc: 0.1797\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.15740\n",
      "Epoch 124/200\n",
      "1719168/1719168 [==============================] - 23s 13us/step - loss: 0.1566 - acc: 0.1793 - val_loss: 0.1574 - val_acc: 0.1797\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 125/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1802 - val_loss: 0.1574 - val_acc: 0.1805\n",
      "\n",
      "Epoch 00125: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 126/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1806 - val_loss: 0.1574 - val_acc: 0.1799\n",
      "\n",
      "Epoch 00126: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 127/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1782 - val_loss: 0.1574 - val_acc: 0.1779\n",
      "\n",
      "Epoch 00127: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 128/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1774 - val_loss: 0.1574 - val_acc: 0.1776\n",
      "\n",
      "Epoch 00128: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 129/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1779 - val_loss: 0.1574 - val_acc: 0.1786\n",
      "\n",
      "Epoch 00129: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 130/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1785 - val_loss: 0.1574 - val_acc: 0.1786\n",
      "\n",
      "Epoch 00130: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 131/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1792 - val_loss: 0.1574 - val_acc: 0.1830\n",
      "\n",
      "Epoch 00131: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 132/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1828 - val_loss: 0.1574 - val_acc: 0.1820\n",
      "\n",
      "Epoch 00132: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 133/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1815 - val_loss: 0.1574 - val_acc: 0.1807\n",
      "\n",
      "Epoch 00133: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 134/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1819 - val_loss: 0.1574 - val_acc: 0.1810\n",
      "\n",
      "Epoch 00134: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 135/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1793 - val_loss: 0.1574 - val_acc: 0.1802\n",
      "\n",
      "Epoch 00135: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 136/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1813 - val_loss: 0.1574 - val_acc: 0.1823\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.15740\n",
      "Epoch 137/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1830 - val_loss: 0.1574 - val_acc: 0.1831\n",
      "\n",
      "Epoch 00137: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 138/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1838 - val_loss: 0.1574 - val_acc: 0.1841\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.15740\n",
      "Epoch 139/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1875 - val_loss: 0.1574 - val_acc: 0.1839\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.15740\n",
      "Epoch 140/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1854 - val_loss: 0.1574 - val_acc: 0.1884\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.15740\n",
      "Epoch 141/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1877 - val_loss: 0.1574 - val_acc: 0.1868\n",
      "\n",
      "Epoch 00141: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 142/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1918 - val_loss: 0.1574 - val_acc: 0.1892\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.15740\n",
      "Epoch 143/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1888 - val_loss: 0.1574 - val_acc: 0.1877\n",
      "\n",
      "Epoch 00143: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 144/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1955 - val_loss: 0.1574 - val_acc: 0.1974\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.15740\n",
      "Epoch 145/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1963 - val_loss: 0.1574 - val_acc: 0.1948\n",
      "\n",
      "Epoch 00145: val_loss improved from 0.15740 to 0.15740, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 146/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1954 - val_loss: 0.1574 - val_acc: 0.1916\n",
      "\n",
      "Epoch 00146: val_loss improved from 0.15740 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 147/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1924 - val_loss: 0.1574 - val_acc: 0.1912\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.15739\n",
      "Epoch 148/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1931 - val_loss: 0.1574 - val_acc: 0.1923\n",
      "\n",
      "Epoch 00148: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 149/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1934 - val_loss: 0.1574 - val_acc: 0.1917\n",
      "\n",
      "Epoch 00149: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 150/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1970 - val_loss: 0.1574 - val_acc: 0.1975\n",
      "\n",
      "Epoch 00150: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 151/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1928 - val_loss: 0.1574 - val_acc: 0.1922\n",
      "\n",
      "Epoch 00151: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 152/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1909 - val_loss: 0.1574 - val_acc: 0.1903\n",
      "\n",
      "Epoch 00152: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 153/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1908 - val_loss: 0.1574 - val_acc: 0.1921\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.15739\n",
      "Epoch 154/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1983 - val_loss: 0.1574 - val_acc: 0.1988\n",
      "\n",
      "Epoch 00154: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 155/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1973 - val_loss: 0.1574 - val_acc: 0.1967\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.15739\n",
      "Epoch 156/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1978 - val_loss: 0.1574 - val_acc: 0.1970\n",
      "\n",
      "Epoch 00156: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 157/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1966 - val_loss: 0.1574 - val_acc: 0.1977\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.15739\n",
      "Epoch 158/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1984 - val_loss: 0.1574 - val_acc: 0.1981\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.15739\n",
      "Epoch 159/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1983 - val_loss: 0.1574 - val_acc: 0.1973\n",
      "\n",
      "Epoch 00159: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 160/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1977 - val_loss: 0.1574 - val_acc: 0.1974\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.15739\n",
      "Epoch 161/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1960 - val_loss: 0.1574 - val_acc: 0.1941\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.15739\n",
      "Epoch 162/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1954 - val_loss: 0.1574 - val_acc: 0.1951\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 163/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1954 - val_loss: 0.1574 - val_acc: 0.1945\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.15739\n",
      "Epoch 164/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1944 - val_loss: 0.1574 - val_acc: 0.1947\n",
      "\n",
      "Epoch 00164: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 165/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1943 - val_loss: 0.1574 - val_acc: 0.1941\n",
      "\n",
      "Epoch 00165: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 166/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1940 - val_loss: 0.1574 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.15739\n",
      "Epoch 167/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1960 - val_loss: 0.1574 - val_acc: 0.1952\n",
      "\n",
      "Epoch 00167: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 168/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1937 - val_loss: 0.1574 - val_acc: 0.1931\n",
      "\n",
      "Epoch 00168: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 169/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1931 - val_loss: 0.1574 - val_acc: 0.1931\n",
      "\n",
      "Epoch 00169: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 170/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1936 - val_loss: 0.1574 - val_acc: 0.1930\n",
      "\n",
      "Epoch 00170: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 171/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1933 - val_loss: 0.1574 - val_acc: 0.1927\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.15739\n",
      "Epoch 172/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1936 - val_loss: 0.1574 - val_acc: 0.1932\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.15739\n",
      "Epoch 173/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.1936 - val_loss: 0.1574 - val_acc: 0.1935\n",
      "\n",
      "Epoch 00173: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 174/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1949 - val_loss: 0.1574 - val_acc: 0.1959\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.15739\n",
      "Epoch 175/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1987 - val_loss: 0.1574 - val_acc: 0.2035\n",
      "\n",
      "Epoch 00175: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 176/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2017 - val_loss: 0.1574 - val_acc: 0.2012\n",
      "\n",
      "Epoch 00176: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 177/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2076 - val_loss: 0.1574 - val_acc: 0.2114\n",
      "\n",
      "Epoch 00177: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 178/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2117 - val_loss: 0.1574 - val_acc: 0.2111\n",
      "\n",
      "Epoch 00178: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 179/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2124 - val_loss: 0.1574 - val_acc: 0.2091\n",
      "\n",
      "Epoch 00179: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 180/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2111 - val_loss: 0.1574 - val_acc: 0.2083\n",
      "\n",
      "Epoch 00180: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 181/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2118 - val_loss: 0.1574 - val_acc: 0.2069\n",
      "\n",
      "Epoch 00181: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 182/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.2194 - val_loss: 0.1574 - val_acc: 0.2141\n",
      "\n",
      "Epoch 00182: val_loss improved from 0.15739 to 0.15739, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 183/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2176 - val_loss: 0.1574 - val_acc: 0.2151\n",
      "\n",
      "Epoch 00183: val_loss improved from 0.15739 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 184/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.2142 - val_loss: 0.1574 - val_acc: 0.2120\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.15738\n",
      "Epoch 185/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2120 - val_loss: 0.1574 - val_acc: 0.2076\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.15738\n",
      "Epoch 186/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2088 - val_loss: 0.1574 - val_acc: 0.2051\n",
      "\n",
      "Epoch 00186: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 187/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.2088 - val_loss: 0.1574 - val_acc: 0.2087\n",
      "\n",
      "Epoch 00187: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 188/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2077 - val_loss: 0.1574 - val_acc: 0.2068\n",
      "\n",
      "Epoch 00188: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 189/200\n",
      "1719168/1719168 [==============================] - 24s 14us/step - loss: 0.1566 - acc: 0.2070 - val_loss: 0.1574 - val_acc: 0.2054\n",
      "\n",
      "Epoch 00189: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 190/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2016 - val_loss: 0.1574 - val_acc: 0.1991\n",
      "\n",
      "Epoch 00190: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 191/200\n",
      "1719168/1719168 [==============================] - 23s 13us/step - loss: 0.1566 - acc: 0.1989 - val_loss: 0.1574 - val_acc: 0.1975\n",
      "\n",
      "Epoch 00191: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 192/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1985 - val_loss: 0.1574 - val_acc: 0.1985\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 193/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.1986 - val_loss: 0.1574 - val_acc: 0.1981\n",
      "\n",
      "Epoch 00193: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 194/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2004 - val_loss: 0.1574 - val_acc: 0.1988\n",
      "\n",
      "Epoch 00194: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 195/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2046 - val_loss: 0.1574 - val_acc: 0.2033\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.15738\n",
      "Epoch 196/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2058 - val_loss: 0.1574 - val_acc: 0.2005\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.15738\n",
      "Epoch 197/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2017 - val_loss: 0.1574 - val_acc: 0.2009\n",
      "\n",
      "Epoch 00197: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 198/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2006 - val_loss: 0.1574 - val_acc: 0.1995\n",
      "\n",
      "Epoch 00198: val_loss improved from 0.15738 to 0.15738, saving model to ./H5files/ae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 199/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2031 - val_loss: 0.1574 - val_acc: 0.2004\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.15738\n",
      "Epoch 200/200\n",
      "1719168/1719168 [==============================] - 23s 14us/step - loss: 0.1566 - acc: 0.2010 - val_loss: 0.1574 - val_acc: 0.2013\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.15738\n",
      "Time elapsed (hh:mm:ss.ms) 1:18:30.079416\n"
     ]
    }
   ],
   "source": [
    "hist_ae_sigmoid_adam_mse = fit_ae(checkpoint_file = \"./H5files/ae_sigmoid_adam_mse_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                  autoencoder = ae_sigmoid_adam_mse, \n",
    "                                  epochs = 200, \n",
    "#                                   batch_size = batch_size,\n",
    "                                  batch_size = batch_size*4,\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss value: 0.1566214199688203\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_loss_value_ae_sigmoid_adam_mse  = plot_hist_auto(hist_ae_sigmoid_adam_mse, './Figures/hist_ae_sigmoid_adam_mse.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- SPAE Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 66)                0         \n",
      "_________________________________________________________________\n",
      "encoded_bottle_neck (Dense)  (None, 44)                2948      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 66)                2970      \n",
      "=================================================================\n",
      "Total params: 5,918\n",
      "Trainable params: 5,918\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "spae_sigmoid_adam_mse,enc_train_x_spsam,enc_test_x_spsam = spae(factor_enc_dim = 1.5,\n",
    "                                                          enc_activation = 'relu',\n",
    "                                                          dec_activation = 'sigmoid',\n",
    "                                                          optimizer='Adam',\n",
    "                                                          loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spae_sigmoid_adam_mse = load_model('spae_sigmoid_adam_mse_redds20bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  1 17:44:53 2019\n",
      "Train on 1719168 samples, validate on 429793 samples\n",
      "Epoch 1/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2768 - acc: 0.0245 - val_loss: 0.2391 - val_acc: 0.0265\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23910, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 2/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2299 - acc: 0.0264 - val_loss: 0.2252 - val_acc: 0.0269\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23910 to 0.22518, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 3/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2214 - acc: 0.0284 - val_loss: 0.2196 - val_acc: 0.0295\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.22518 to 0.21963, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 4/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2163 - acc: 0.0314 - val_loss: 0.2144 - val_acc: 0.0295\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.21963 to 0.21437, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 5/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2117 - acc: 0.0344 - val_loss: 0.2103 - val_acc: 0.0258\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.21437 to 0.21028, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 6/200\n",
      "1719168/1719168 [==============================] - 25s 14us/step - loss: 0.2082 - acc: 0.0284 - val_loss: 0.2078 - val_acc: 0.0284\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21028 to 0.20780, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 7/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2062 - acc: 0.0320 - val_loss: 0.2061 - val_acc: 0.0362\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.20780 to 0.20614, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 8/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2048 - acc: 0.0546 - val_loss: 0.2050 - val_acc: 0.0672\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.20614 to 0.20497, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 9/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2037 - acc: 0.0708 - val_loss: 0.2041 - val_acc: 0.0757\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20497 to 0.20408, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 10/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2029 - acc: 0.0763 - val_loss: 0.2034 - val_acc: 0.0798\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20408 to 0.20336, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 11/200\n",
      "1719168/1719168 [==============================] - 25s 14us/step - loss: 0.2023 - acc: 0.0789 - val_loss: 0.2028 - val_acc: 0.0825\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.20336 to 0.20279, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 12/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2018 - acc: 0.0815 - val_loss: 0.2023 - val_acc: 0.0845\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.20279 to 0.20230, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 13/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2013 - acc: 0.0836 - val_loss: 0.2019 - val_acc: 0.0866\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.20230 to 0.20187, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 14/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2009 - acc: 0.0855 - val_loss: 0.2015 - val_acc: 0.0893\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.20187 to 0.20152, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 15/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2006 - acc: 0.0874 - val_loss: 0.2012 - val_acc: 0.0920\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.20152 to 0.20122, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 16/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2003 - acc: 0.0891 - val_loss: 0.2010 - val_acc: 0.0931\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.20122 to 0.20096, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 17/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.2000 - acc: 0.0905 - val_loss: 0.2007 - val_acc: 0.0940\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.20096 to 0.20070, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 18/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1998 - acc: 0.0938 - val_loss: 0.2004 - val_acc: 0.1099\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.20070 to 0.20036, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 19/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1994 - acc: 0.1303 - val_loss: 0.1999 - val_acc: 0.1414\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.20036 to 0.19992, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 20/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1989 - acc: 0.1429 - val_loss: 0.1996 - val_acc: 0.1408\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.19992 to 0.19956, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 21/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1986 - acc: 0.1431 - val_loss: 0.1992 - val_acc: 0.1389\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.19956 to 0.19924, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 22/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1983 - acc: 0.1438 - val_loss: 0.1990 - val_acc: 0.1409\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.19924 to 0.19898, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 23/200\n",
      "1719168/1719168 [==============================] - 25s 14us/step - loss: 0.1981 - acc: 0.1449 - val_loss: 0.1988 - val_acc: 0.1425\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.19898 to 0.19880, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 24/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1979 - acc: 0.1469 - val_loss: 0.1986 - val_acc: 0.1437\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19880 to 0.19863, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 25/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1978 - acc: 0.1486 - val_loss: 0.1985 - val_acc: 0.1463\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.19863 to 0.19847, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 26/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1976 - acc: 0.1515 - val_loss: 0.1983 - val_acc: 0.1548\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.19847 to 0.19832, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 27/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1975 - acc: 0.1553 - val_loss: 0.1982 - val_acc: 0.1618\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.19832 to 0.19820, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 28/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1974 - acc: 0.1585 - val_loss: 0.1982 - val_acc: 0.1622\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.19820 to 0.19817, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 29/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1973 - acc: 0.1621 - val_loss: 0.1980 - val_acc: 0.2313\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.19817 to 0.19804, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 30/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1972 - acc: 0.1672 - val_loss: 0.1979 - val_acc: 0.1676\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.19804 to 0.19789, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 31/200\n",
      "1719168/1719168 [==============================] - 25s 14us/step - loss: 0.1971 - acc: 0.1707 - val_loss: 0.1978 - val_acc: 0.2181\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.19789 to 0.19780, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 32/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1970 - acc: 0.1739 - val_loss: 0.1977 - val_acc: 0.1953\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.19780 to 0.19774, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 33/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1969 - acc: 0.1796 - val_loss: 0.1976 - val_acc: 0.1936\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.19774 to 0.19761, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 34/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1969 - acc: 0.1866 - val_loss: 0.1976 - val_acc: 0.2308\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.19761\n",
      "Epoch 35/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1968 - acc: 0.1889 - val_loss: 0.1975 - val_acc: 0.1705\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.19761 to 0.19750, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 36/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1967 - acc: 0.1959 - val_loss: 0.1975 - val_acc: 0.2070\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.19750 to 0.19746, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 37/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1967 - acc: 0.2009 - val_loss: 0.1974 - val_acc: 0.1923\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.19746 to 0.19739, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 38/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1966 - acc: 0.2055 - val_loss: 0.1973 - val_acc: 0.2087\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.19739 to 0.19733, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 39/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1966 - acc: 0.2110 - val_loss: 0.1973 - val_acc: 0.2089\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.19733 to 0.19727, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 40/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1965 - acc: 0.2151 - val_loss: 0.1973 - val_acc: 0.2341\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.19727 to 0.19726, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 41/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1965 - acc: 0.2218 - val_loss: 0.1972 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.19726 to 0.19717, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 42/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1964 - acc: 0.2256 - val_loss: 0.1971 - val_acc: 0.2472\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.19717 to 0.19710, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 43/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1964 - acc: 0.2305 - val_loss: 0.1971 - val_acc: 0.2475\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.19710\n",
      "Epoch 44/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1963 - acc: 0.2348 - val_loss: 0.1970 - val_acc: 0.2523\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.19710 to 0.19704, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 45/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1963 - acc: 0.2385 - val_loss: 0.1970 - val_acc: 0.2473\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.19704 to 0.19701, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 46/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1963 - acc: 0.2423 - val_loss: 0.1970 - val_acc: 0.2354\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.19701 to 0.19700, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 47/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1962 - acc: 0.2459 - val_loss: 0.1970 - val_acc: 0.2338\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.19700 to 0.19695, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 48/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1962 - acc: 0.2497 - val_loss: 0.1969 - val_acc: 0.2591\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.19695 to 0.19690, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 49/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1961 - acc: 0.2527 - val_loss: 0.1969 - val_acc: 0.2011\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.19690\n",
      "Epoch 50/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1961 - acc: 0.2562 - val_loss: 0.1968 - val_acc: 0.2434\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.19690 to 0.19685, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 51/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1961 - acc: 0.2577 - val_loss: 0.1968 - val_acc: 0.2352\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.19685 to 0.19683, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 52/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1961 - acc: 0.2595 - val_loss: 0.1968 - val_acc: 0.2645\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.19683\n",
      "Epoch 53/200\n",
      "1719168/1719168 [==============================] - 25s 14us/step - loss: 0.1960 - acc: 0.2605 - val_loss: 0.1969 - val_acc: 0.2547\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.19683\n",
      "Epoch 54/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1960 - acc: 0.2634 - val_loss: 0.1967 - val_acc: 0.2431\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.19683 to 0.19670, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 55/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1960 - acc: 0.2632 - val_loss: 0.1967 - val_acc: 0.2393\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.19670\n",
      "Epoch 56/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1959 - acc: 0.2659 - val_loss: 0.1967 - val_acc: 0.2706\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.19670\n",
      "Epoch 57/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1959 - acc: 0.2679 - val_loss: 0.1966 - val_acc: 0.2579\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.19670 to 0.19664, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 58/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1959 - acc: 0.2686 - val_loss: 0.1967 - val_acc: 0.2613\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.19664\n",
      "Epoch 59/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1959 - acc: 0.2705 - val_loss: 0.1966 - val_acc: 0.2645\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.19664 to 0.19660, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 60/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1959 - acc: 0.2706 - val_loss: 0.1966 - val_acc: 0.2638\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.19660 to 0.19657, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 61/200\n",
      "1719168/1719168 [==============================] - 25s 14us/step - loss: 0.1958 - acc: 0.2726 - val_loss: 0.1966 - val_acc: 0.2751\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.19657 to 0.19656, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 62/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1958 - acc: 0.2731 - val_loss: 0.1966 - val_acc: 0.2743\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.19656 to 0.19656, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 63/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1958 - acc: 0.2755 - val_loss: 0.1966 - val_acc: 0.2760\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.19656 to 0.19655, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 64/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1958 - acc: 0.2767 - val_loss: 0.1966 - val_acc: 0.2531\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.19655\n",
      "Epoch 65/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1958 - acc: 0.2786 - val_loss: 0.1965 - val_acc: 0.2728\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.19655 to 0.19648, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 66/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1957 - acc: 0.2784 - val_loss: 0.1964 - val_acc: 0.2712\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.19648 to 0.19645, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 67/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1957 - acc: 0.2793 - val_loss: 0.1966 - val_acc: 0.2517\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.19645\n",
      "Epoch 68/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1957 - acc: 0.2799 - val_loss: 0.1965 - val_acc: 0.2840\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.19645\n",
      "Epoch 69/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1957 - acc: 0.2806 - val_loss: 0.1964 - val_acc: 0.2847\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.19645 to 0.19638, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 70/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1957 - acc: 0.2817 - val_loss: 0.1965 - val_acc: 0.2796\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.19638\n",
      "Epoch 71/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1957 - acc: 0.2830 - val_loss: 0.1964 - val_acc: 0.2776\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.19638\n",
      "Epoch 72/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1957 - acc: 0.2833 - val_loss: 0.1963 - val_acc: 0.2864\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.19638 to 0.19635, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 73/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1956 - acc: 0.2832 - val_loss: 0.1965 - val_acc: 0.2769\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.19635\n",
      "Epoch 74/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1956 - acc: 0.2862 - val_loss: 0.1963 - val_acc: 0.2787\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.19635 to 0.19630, saving model to ./H5files/spae_sigmoid_adam_mse_redds20bal.h5\n",
      "Epoch 75/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1956 - acc: 0.2850 - val_loss: 0.1965 - val_acc: 0.2846\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.19630\n",
      "Epoch 76/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1957 - acc: 0.2874 - val_loss: 0.1964 - val_acc: 0.2920\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.19630\n",
      "Epoch 77/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1956 - acc: 0.2866 - val_loss: 0.1964 - val_acc: 0.2792\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.19630\n",
      "Epoch 78/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1956 - acc: 0.2892 - val_loss: 0.1964 - val_acc: 0.2828\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.19630\n",
      "Epoch 79/200\n",
      "1719168/1719168 [==============================] - 25s 15us/step - loss: 0.1956 - acc: 0.2891 - val_loss: 0.1963 - val_acc: 0.2871\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.19630\n",
      "Time elapsed (hh:mm:ss.ms) 0:33:03.819041\n"
     ]
    }
   ],
   "source": [
    "hist_spae_sigmoid_adam_mse = fit_ae(checkpoint_file = \"./H5files/spae_sigmoid_adam_mse_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                  autoencoder = spae_sigmoid_adam_mse, \n",
    "                                  epochs = 200, \n",
    "                                  batch_size = batch_size*4,\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss value: 0.19556844635141205\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_loss_value_spae_sigmoid_adam_mse  = plot_hist_auto(hist_spae_sigmoid_adam_mse, './Figures/hist_spae_sigmoid_adam_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valueDict = {\n",
    "    'loss_value_ae_sigmoid_adam_mse': best_loss_value_ae_sigmoid_adam_mse,\n",
    "    'loss_value_spae_sigmoid_adam_mse': best_loss_value_spae_sigmoid_adam_mse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_value_ae_sigmoid_adam_mse': 0.1566214199688203,\n",
       " 'loss_value_spae_sigmoid_adam_mse': 0.19556844635141205}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1719168, 44)\n",
      "(537241, 44)\n",
      "(1719168, 44)\n",
      "(537241, 44)\n"
     ]
    }
   ],
   "source": [
    "print(enc_train_x_asam.shape)\n",
    "print(enc_test_x_asam.shape)\n",
    "\n",
    "print(enc_train_x_spsam.shape)\n",
    "print(enc_test_x_spsam.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with ae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ae_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=enc_train_x_asam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  1 18:17:57 2019\n",
      "Train on 1375334 samples, validate on 343834 samples\n",
      "Epoch 1/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.4688 - acc: 0.7604 - val_loss: 0.3698 - val_acc: 0.8202\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.36977, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 2/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.3283 - acc: 0.8464 - val_loss: 0.2972 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.36977 to 0.29716, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 3/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2884 - acc: 0.8649 - val_loss: 0.2732 - val_acc: 0.8730\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.29716 to 0.27325, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 4/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2678 - acc: 0.8740 - val_loss: 0.2628 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.27325 to 0.26280, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 5/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2548 - acc: 0.8798 - val_loss: 0.2578 - val_acc: 0.8764\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.26280 to 0.25779, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 6/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2447 - acc: 0.8844 - val_loss: 0.2418 - val_acc: 0.8861\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.25779 to 0.24179, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 7/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2372 - acc: 0.8876 - val_loss: 0.2379 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24179 to 0.23787, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 8/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2302 - acc: 0.8908 - val_loss: 0.2260 - val_acc: 0.8944\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.23787 to 0.22599, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 9/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2248 - acc: 0.8930 - val_loss: 0.2175 - val_acc: 0.8979\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22599 to 0.21754, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 10/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2206 - acc: 0.8948 - val_loss: 0.2129 - val_acc: 0.9004\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.21754 to 0.21285, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 11/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2158 - acc: 0.8969 - val_loss: 0.2158 - val_acc: 0.8985\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.21285\n",
      "Epoch 12/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2120 - acc: 0.8986 - val_loss: 0.2076 - val_acc: 0.9020\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.21285 to 0.20760, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 13/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2082 - acc: 0.9007 - val_loss: 0.2177 - val_acc: 0.8958\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.20760\n",
      "Epoch 14/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2054 - acc: 0.9018 - val_loss: 0.2039 - val_acc: 0.9048\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.20760 to 0.20390, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 15/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.2026 - acc: 0.9029 - val_loss: 0.2088 - val_acc: 0.9018\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.20390\n",
      "Epoch 16/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1998 - acc: 0.9042 - val_loss: 0.1991 - val_acc: 0.9073\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.20390 to 0.19905, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 17/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1977 - acc: 0.9051 - val_loss: 0.1908 - val_acc: 0.9095\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.19905 to 0.19084, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 18/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1957 - acc: 0.9060 - val_loss: 0.1957 - val_acc: 0.9077\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.19084\n",
      "Epoch 19/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1938 - acc: 0.9068 - val_loss: 0.1858 - val_acc: 0.9119\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.19084 to 0.18583, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 20/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1914 - acc: 0.9081 - val_loss: 0.1852 - val_acc: 0.9137\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.18583 to 0.18519, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 21/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1900 - acc: 0.9084 - val_loss: 0.1790 - val_acc: 0.9172\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.18519 to 0.17902, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 22/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1882 - acc: 0.9095 - val_loss: 0.1858 - val_acc: 0.9123\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17902\n",
      "Epoch 23/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1865 - acc: 0.9104 - val_loss: 0.1832 - val_acc: 0.9127\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17902\n",
      "Epoch 24/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1854 - acc: 0.9107 - val_loss: 0.1862 - val_acc: 0.9125\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.17902\n",
      "Epoch 25/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1839 - acc: 0.9113 - val_loss: 0.1868 - val_acc: 0.9102\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.17902\n",
      "Epoch 26/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1825 - acc: 0.9121 - val_loss: 0.1762 - val_acc: 0.9169\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.17902 to 0.17617, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 27/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1811 - acc: 0.9126 - val_loss: 0.1804 - val_acc: 0.9144\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.17617\n",
      "Epoch 28/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1806 - acc: 0.9129 - val_loss: 0.1741 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.17617 to 0.17410, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 29/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1792 - acc: 0.9134 - val_loss: 0.1750 - val_acc: 0.9161\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.17410\n",
      "Epoch 30/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1789 - acc: 0.9139 - val_loss: 0.1744 - val_acc: 0.9193\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.17410\n",
      "Epoch 31/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1778 - acc: 0.9143 - val_loss: 0.1772 - val_acc: 0.9175\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.17410\n",
      "Epoch 32/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1770 - acc: 0.9148 - val_loss: 0.1712 - val_acc: 0.9201\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.17410 to 0.17122, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 33/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1768 - acc: 0.9148 - val_loss: 0.1720 - val_acc: 0.9196\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.17122\n",
      "Epoch 34/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1750 - acc: 0.9156 - val_loss: 0.1740 - val_acc: 0.9173\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.17122\n",
      "Epoch 35/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1749 - acc: 0.9156 - val_loss: 0.1706 - val_acc: 0.9203\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.17122 to 0.17061, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 36/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1746 - acc: 0.9159 - val_loss: 0.1672 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.17061 to 0.16718, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 37/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1734 - acc: 0.9164 - val_loss: 0.1688 - val_acc: 0.9192\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16718\n",
      "Epoch 38/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1728 - acc: 0.9167 - val_loss: 0.1718 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16718\n",
      "Epoch 39/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1722 - acc: 0.9170 - val_loss: 0.1644 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.16718 to 0.16443, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 40/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1718 - acc: 0.9173 - val_loss: 0.1675 - val_acc: 0.9216\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.16443\n",
      "Epoch 41/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1715 - acc: 0.9173 - val_loss: 0.1707 - val_acc: 0.9207\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.16443\n",
      "Epoch 42/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1708 - acc: 0.9176 - val_loss: 0.1658 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.16443\n",
      "Epoch 43/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1703 - acc: 0.9177 - val_loss: 0.1709 - val_acc: 0.9204\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.16443\n",
      "Epoch 44/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1701 - acc: 0.9178 - val_loss: 0.1631 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.16443 to 0.16311, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 45/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1697 - acc: 0.9181 - val_loss: 0.1647 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.16311\n",
      "Epoch 46/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1685 - acc: 0.9186 - val_loss: 0.1643 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.16311\n",
      "Epoch 47/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1685 - acc: 0.9186 - val_loss: 0.1628 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.16311 to 0.16279, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 48/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1679 - acc: 0.9189 - val_loss: 0.1643 - val_acc: 0.9229\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.16279\n",
      "Epoch 49/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1675 - acc: 0.9192 - val_loss: 0.1634 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.16279\n",
      "Epoch 50/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1673 - acc: 0.9191 - val_loss: 0.1639 - val_acc: 0.9224\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.16279\n",
      "Epoch 51/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1667 - acc: 0.9195 - val_loss: 0.1587 - val_acc: 0.9241\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.16279 to 0.15869, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 52/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1663 - acc: 0.9197 - val_loss: 0.1631 - val_acc: 0.9223\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.15869\n",
      "Epoch 53/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1657 - acc: 0.9198 - val_loss: 0.1587 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.15869\n",
      "Epoch 54/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1653 - acc: 0.9199 - val_loss: 0.1636 - val_acc: 0.9234\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.15869\n",
      "Epoch 55/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1654 - acc: 0.9199 - val_loss: 0.1619 - val_acc: 0.9249\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.15869\n",
      "Epoch 56/200\n",
      "1375334/1375334 [==============================] - 37s 27us/step - loss: 0.1644 - acc: 0.9204 - val_loss: 0.1599 - val_acc: 0.9244\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.15869\n",
      "Time elapsed (hh:mm:ss.ms) 0:34:31.020457\n"
     ]
    }
   ],
   "source": [
    "hist_ae_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ae_ann_2h_unisoftsigbinlosadam_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                        ann = ae_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = enc_train_x_asam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ae_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_ae_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_ae_ann_2h_unisoftsigbinlosadam, './Figures/ae_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_ae_ann_2h_prob_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam = ann_predict(ae_ann_2h_unisoftsigbinlosadam,enc_test_x_asam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_ae_ann_2h_01_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_ae_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_ae_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=enc_train_x_asam\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=enc_test_x_asam\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug  1 18:52:29 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429792/429792 [==============================] - 43s 100us/step - loss: 0.5757 - acc: 0.6825\n",
      "Epoch 2/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.4659 - acc: 0.7630\n",
      "Epoch 3/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.4143 - acc: 0.7956\n",
      "Epoch 4/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3877 - acc: 0.8103\n",
      "Epoch 5/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3693 - acc: 0.8218\n",
      "Epoch 6/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3577 - acc: 0.8288\n",
      "Epoch 7/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3479 - acc: 0.8333\n",
      "Epoch 8/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.3396 - acc: 0.8383\n",
      "Epoch 9/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3330 - acc: 0.8417\n",
      "Epoch 10/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3269 - acc: 0.8452\n",
      "Epoch 11/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3226 - acc: 0.8472\n",
      "Epoch 12/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3169 - acc: 0.8491\n",
      "Epoch 13/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3133 - acc: 0.8515\n",
      "Epoch 14/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3092 - acc: 0.8542\n",
      "Epoch 15/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3054 - acc: 0.8565\n",
      "Epoch 16/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.3024 - acc: 0.8578\n",
      "Epoch 17/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2985 - acc: 0.8608\n",
      "Epoch 18/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2958 - acc: 0.8615\n",
      "Epoch 19/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2925 - acc: 0.8627\n",
      "Epoch 20/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2913 - acc: 0.8636\n",
      "Epoch 21/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2883 - acc: 0.8653\n",
      "Epoch 22/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2870 - acc: 0.8659\n",
      "Epoch 23/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2845 - acc: 0.8664\n",
      "Epoch 24/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2830 - acc: 0.8683\n",
      "Epoch 25/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2821 - acc: 0.8686\n",
      "Epoch 26/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2800 - acc: 0.8690\n",
      "Epoch 27/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2787 - acc: 0.8706\n",
      "Epoch 28/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2775 - acc: 0.8708\n",
      "Epoch 29/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2761 - acc: 0.8713\n",
      "Epoch 30/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2748 - acc: 0.8725\n",
      "Epoch 31/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2740 - acc: 0.8729\n",
      "Epoch 32/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2717 - acc: 0.8739\n",
      "Epoch 33/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2712 - acc: 0.8742\n",
      "Epoch 34/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2705 - acc: 0.8737\n",
      "Epoch 35/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2691 - acc: 0.8750\n",
      "Epoch 36/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2679 - acc: 0.8750\n",
      "Epoch 37/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2679 - acc: 0.8753\n",
      "Epoch 38/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2669 - acc: 0.8766\n",
      "Epoch 39/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2653 - acc: 0.8762\n",
      "Epoch 40/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2663 - acc: 0.8758\n",
      "Epoch 41/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2643 - acc: 0.8778\n",
      "Epoch 42/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2644 - acc: 0.8776\n",
      "Epoch 43/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2631 - acc: 0.8782\n",
      "Epoch 44/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2630 - acc: 0.8779\n",
      "Epoch 45/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2620 - acc: 0.8782\n",
      "Epoch 46/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2620 - acc: 0.8784\n",
      "Epoch 47/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2608 - acc: 0.8786\n",
      "Epoch 48/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2608 - acc: 0.8797\n",
      "Epoch 49/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2596 - acc: 0.8797\n",
      "Epoch 50/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2609 - acc: 0.8785\n",
      "Epoch 51/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2597 - acc: 0.8793\n",
      "Epoch 52/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2598 - acc: 0.8793\n",
      "Epoch 53/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2585 - acc: 0.8802\n",
      "Epoch 54/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2580 - acc: 0.8799\n",
      "Epoch 55/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2577 - acc: 0.8804\n",
      "Epoch 56/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2575 - acc: 0.8806\n",
      "Epoch 57/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2571 - acc: 0.8809\n",
      "Epoch 58/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2569 - acc: 0.8808\n",
      "Epoch 59/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2575 - acc: 0.8807\n",
      "Epoch 60/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2568 - acc: 0.8804\n",
      "Epoch 61/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2560 - acc: 0.8810\n",
      "Epoch 62/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2559 - acc: 0.8812\n",
      "Epoch 63/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2555 - acc: 0.8813\n",
      "Epoch 64/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2553 - acc: 0.8811\n",
      "Epoch 65/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2555 - acc: 0.8816\n",
      "Epoch 66/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2550 - acc: 0.8818\n",
      "Epoch 67/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2546 - acc: 0.8821\n",
      "Epoch 68/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2543 - acc: 0.8818\n",
      "Epoch 69/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2539 - acc: 0.8827\n",
      "Epoch 70/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2540 - acc: 0.8822\n",
      "Epoch 71/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2543 - acc: 0.8816\n",
      "Epoch 72/100\n",
      "429792/429792 [==============================] - 43s 99us/step - loss: 0.2543 - acc: 0.8821\n",
      "Epoch 73/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2537 - acc: 0.8821\n",
      "Epoch 74/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2529 - acc: 0.8826\n",
      "Epoch 75/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2530 - acc: 0.8822\n",
      "Epoch 76/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2525 - acc: 0.8827\n",
      "Epoch 77/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2530 - acc: 0.8822\n",
      "Epoch 78/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2524 - acc: 0.8827\n",
      "Epoch 79/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2521 - acc: 0.8827\n",
      "Epoch 80/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2516 - acc: 0.8835\n",
      "Epoch 81/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2506 - acc: 0.8837\n",
      "Epoch 82/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2518 - acc: 0.8826\n",
      "Epoch 83/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2512 - acc: 0.8831\n",
      "Epoch 84/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2511 - acc: 0.8827\n",
      "Epoch 85/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2509 - acc: 0.8836\n",
      "Epoch 86/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2508 - acc: 0.8843\n",
      "Epoch 87/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2511 - acc: 0.8839\n",
      "Epoch 88/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2506 - acc: 0.8843\n",
      "Epoch 89/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2512 - acc: 0.8834\n",
      "Epoch 90/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2493 - acc: 0.8843\n",
      "Epoch 91/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2501 - acc: 0.8839\n",
      "Epoch 92/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2488 - acc: 0.8849\n",
      "Epoch 93/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2490 - acc: 0.8848\n",
      "Epoch 94/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2484 - acc: 0.8854\n",
      "Epoch 95/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2490 - acc: 0.8849\n",
      "Epoch 96/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2485 - acc: 0.8856\n",
      "Epoch 97/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2483 - acc: 0.8849\n",
      "Epoch 98/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2480 - acc: 0.8852\n",
      "Epoch 99/100\n",
      "429792/429792 [==============================] - 42s 98us/step - loss: 0.2483 - acc: 0.8851\n",
      "Epoch 100/100\n",
      "429792/429792 [==============================] - 42s 99us/step - loss: 0.2484 - acc: 0.8855\n",
      "107449/107449 [==============================] - 2s 16us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.5684 - acc: 0.6867\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.4456 - acc: 0.7772\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.3893 - acc: 0.8099\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.3577 - acc: 0.8264\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3370 - acc: 0.8369\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.3206 - acc: 0.8465\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3089 - acc: 0.8529\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.3005 - acc: 0.8566\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2935 - acc: 0.8605\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2871 - acc: 0.8634\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2823 - acc: 0.8661\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2767 - acc: 0.8692\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2715 - acc: 0.8714\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2676 - acc: 0.8735\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2640 - acc: 0.8752\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2609 - acc: 0.8766\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2587 - acc: 0.8778\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2560 - acc: 0.8787\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2521 - acc: 0.8803\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2504 - acc: 0.8816\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2476 - acc: 0.8830\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2457 - acc: 0.8831\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2431 - acc: 0.8850\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2416 - acc: 0.8856\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2396 - acc: 0.8869\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2383 - acc: 0.8866\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2358 - acc: 0.8882\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2345 - acc: 0.8888\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2334 - acc: 0.8890\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2307 - acc: 0.8899\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2296 - acc: 0.8907\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2270 - acc: 0.8923\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2266 - acc: 0.8927\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2253 - acc: 0.8929\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2232 - acc: 0.8944\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2218 - acc: 0.8946\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2208 - acc: 0.8950\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2199 - acc: 0.8956\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2190 - acc: 0.8955\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2181 - acc: 0.8966\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2166 - acc: 0.8980\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2165 - acc: 0.8969\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2155 - acc: 0.8974\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2145 - acc: 0.8982\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2139 - acc: 0.8980\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2137 - acc: 0.8984\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2131 - acc: 0.8990\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2126 - acc: 0.8991\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2116 - acc: 0.8997\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2116 - acc: 0.8991\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2106 - acc: 0.8996\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2104 - acc: 0.8997\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2100 - acc: 0.9001\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2091 - acc: 0.9007\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2085 - acc: 0.9010\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2085 - acc: 0.9009\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2077 - acc: 0.9012\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2080 - acc: 0.9011\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2073 - acc: 0.9018\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2067 - acc: 0.9016\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2066 - acc: 0.9020\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2063 - acc: 0.9021\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2057 - acc: 0.9027\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2061 - acc: 0.9022\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2054 - acc: 0.9027\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2048 - acc: 0.9025\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2054 - acc: 0.9027\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2040 - acc: 0.9034\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2036 - acc: 0.9031\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2034 - acc: 0.9036\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2026 - acc: 0.9037\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2025 - acc: 0.9037\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2029 - acc: 0.9039\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2021 - acc: 0.9041\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2018 - acc: 0.9036\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2024 - acc: 0.9033\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2011 - acc: 0.9047\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2012 - acc: 0.9044\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2009 - acc: 0.9041\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2000 - acc: 0.9046\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2003 - acc: 0.9045\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2000 - acc: 0.9047\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1994 - acc: 0.9048\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1998 - acc: 0.9055\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2000 - acc: 0.9045\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1993 - acc: 0.9055\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2000 - acc: 0.9052\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1993 - acc: 0.9057\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1990 - acc: 0.9054\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1991 - acc: 0.9052\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.1983 - acc: 0.9053\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1979 - acc: 0.9060\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1981 - acc: 0.9059\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1982 - acc: 0.9055\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1980 - acc: 0.9059\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.1985 - acc: 0.9057\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1974 - acc: 0.9064\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1977 - acc: 0.9058\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1981 - acc: 0.9062\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.1970 - acc: 0.9068\n",
      "107448/107448 [==============================] - 2s 17us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.5679 - acc: 0.6867\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.4464 - acc: 0.7755\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3936 - acc: 0.8085\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3633 - acc: 0.8255\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3419 - acc: 0.8364\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.3264 - acc: 0.8441\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3147 - acc: 0.8496\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3035 - acc: 0.8559\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2969 - acc: 0.8586\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2901 - acc: 0.8622\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2849 - acc: 0.8652\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2799 - acc: 0.8672\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2761 - acc: 0.8700\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2720 - acc: 0.8724\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2682 - acc: 0.8734\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2649 - acc: 0.8749\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2621 - acc: 0.8767\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2593 - acc: 0.8777\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2559 - acc: 0.8794\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2544 - acc: 0.8798\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2513 - acc: 0.8811\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2486 - acc: 0.8824\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2476 - acc: 0.8836\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2461 - acc: 0.8838\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2442 - acc: 0.8844\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2425 - acc: 0.8846\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2404 - acc: 0.8856\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2392 - acc: 0.8858\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2378 - acc: 0.8876\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2369 - acc: 0.8873\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2345 - acc: 0.8887\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2351 - acc: 0.8882\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2335 - acc: 0.8894\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2321 - acc: 0.8890\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2311 - acc: 0.8900\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2302 - acc: 0.8906\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2298 - acc: 0.8910\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2288 - acc: 0.8911\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2281 - acc: 0.8911\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2262 - acc: 0.8922\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2254 - acc: 0.8926\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2250 - acc: 0.8931\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2237 - acc: 0.8930\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2235 - acc: 0.8933\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2227 - acc: 0.8934\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2223 - acc: 0.8936\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2209 - acc: 0.8948\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2204 - acc: 0.8946\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2217 - acc: 0.8939\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2196 - acc: 0.8948\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2195 - acc: 0.8950\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2185 - acc: 0.8958\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2185 - acc: 0.8952\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2174 - acc: 0.8963\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2172 - acc: 0.8964\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2171 - acc: 0.8957\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2167 - acc: 0.8956\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2158 - acc: 0.8969\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2156 - acc: 0.8968\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2149 - acc: 0.8971\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2143 - acc: 0.8973\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2140 - acc: 0.8969\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2140 - acc: 0.8975\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2140 - acc: 0.8973\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2130 - acc: 0.8977\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2130 - acc: 0.8978\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2131 - acc: 0.8977\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2128 - acc: 0.8982\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2122 - acc: 0.8979\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2119 - acc: 0.8980\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2123 - acc: 0.8980\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2114 - acc: 0.8985\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2116 - acc: 0.8982\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2111 - acc: 0.8987\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2101 - acc: 0.8991\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2107 - acc: 0.8992\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2104 - acc: 0.8992\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2099 - acc: 0.8987\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2111 - acc: 0.8987\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2101 - acc: 0.8993\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2105 - acc: 0.8990\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2097 - acc: 0.8988\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2092 - acc: 0.8996\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2094 - acc: 0.8996\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2097 - acc: 0.8995\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2091 - acc: 0.8996\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2087 - acc: 0.9000\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2085 - acc: 0.8996\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2088 - acc: 0.8994\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2085 - acc: 0.8992\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2080 - acc: 0.9001\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2081 - acc: 0.8993\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2080 - acc: 0.8998\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 43s 99us/step - loss: 0.2069 - acc: 0.9003\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2079 - acc: 0.9001\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2078 - acc: 0.8999\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2075 - acc: 0.9003\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2070 - acc: 0.9004\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2074 - acc: 0.8999\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2070 - acc: 0.8999\n",
      "107448/107448 [==============================] - 2s 17us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 44s 102us/step - loss: 0.5638 - acc: 0.6928\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.4315 - acc: 0.7872\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.3762 - acc: 0.8178\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3465 - acc: 0.8332\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3279 - acc: 0.8421\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.3135 - acc: 0.8497\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.3038 - acc: 0.8541\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2945 - acc: 0.8589\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2866 - acc: 0.8622\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2820 - acc: 0.8648\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2767 - acc: 0.8675\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2713 - acc: 0.8695\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2679 - acc: 0.8711\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2642 - acc: 0.8730\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2605 - acc: 0.8755\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2576 - acc: 0.8767\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2553 - acc: 0.8776\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2537 - acc: 0.8786\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2504 - acc: 0.8798\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2483 - acc: 0.8813\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2465 - acc: 0.8818\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2453 - acc: 0.8833\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2437 - acc: 0.8832\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2414 - acc: 0.8847\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2402 - acc: 0.8851\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2392 - acc: 0.8861\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2374 - acc: 0.8863\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2352 - acc: 0.8878\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2340 - acc: 0.8884\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2322 - acc: 0.8889\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2309 - acc: 0.8905\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2298 - acc: 0.8906\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2287 - acc: 0.8914\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2282 - acc: 0.8921\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2270 - acc: 0.8922\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2258 - acc: 0.8926\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2249 - acc: 0.8934\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2244 - acc: 0.8942\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2244 - acc: 0.8937\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2230 - acc: 0.8946\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2223 - acc: 0.8941\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2214 - acc: 0.8948\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2217 - acc: 0.8946\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2204 - acc: 0.8955\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2202 - acc: 0.8953\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2192 - acc: 0.8960\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2188 - acc: 0.8961\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2181 - acc: 0.8967\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2176 - acc: 0.8971\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2172 - acc: 0.8971\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2179 - acc: 0.8969\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2157 - acc: 0.8976\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2162 - acc: 0.8972\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2156 - acc: 0.8979\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2148 - acc: 0.8977\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2152 - acc: 0.8979\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2151 - acc: 0.8974\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2141 - acc: 0.8984\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2129 - acc: 0.8994\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2138 - acc: 0.8983\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2124 - acc: 0.8990\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2133 - acc: 0.8988\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2121 - acc: 0.8994\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2126 - acc: 0.8992\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2117 - acc: 0.9002\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2116 - acc: 0.9000\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2123 - acc: 0.8994\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2113 - acc: 0.9002\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2097 - acc: 0.9005\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2102 - acc: 0.9002\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2105 - acc: 0.9000\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2098 - acc: 0.9009\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2099 - acc: 0.9009\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2095 - acc: 0.9009\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2096 - acc: 0.9007\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2090 - acc: 0.9006\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2088 - acc: 0.9011\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2096 - acc: 0.9012\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2085 - acc: 0.9014\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2088 - acc: 0.9011\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2093 - acc: 0.9007\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2078 - acc: 0.9016\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2076 - acc: 0.9021\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2079 - acc: 0.9012\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2070 - acc: 0.9017\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2070 - acc: 0.9019\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2075 - acc: 0.9017\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2068 - acc: 0.9018\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2072 - acc: 0.9019\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2070 - acc: 0.9021\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2062 - acc: 0.9027\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2065 - acc: 0.9021\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2060 - acc: 0.9027\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2059 - acc: 0.9028\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2061 - acc: 0.9023\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2059 - acc: 0.9030\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2062 - acc: 0.9026\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2057 - acc: 0.9024\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2055 - acc: 0.9026\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 43s 100us/step - loss: 0.2049 - acc: 0.9028\n",
      "107448/107448 [==============================] - 2s 18us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.5636 - acc: 0.6942\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.4415 - acc: 0.7786\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.3882 - acc: 0.8094\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.3584 - acc: 0.8256\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.3359 - acc: 0.8374\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.3194 - acc: 0.8461\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.3068 - acc: 0.8529\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2967 - acc: 0.8581\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2894 - acc: 0.8618\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2809 - acc: 0.8663\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2758 - acc: 0.8693\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2702 - acc: 0.8723\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2657 - acc: 0.8747\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2623 - acc: 0.8761\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2583 - acc: 0.8780\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2561 - acc: 0.8793\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2520 - acc: 0.8811\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2494 - acc: 0.8824\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2465 - acc: 0.8839\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2447 - acc: 0.8842\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2424 - acc: 0.8856\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2407 - acc: 0.8866\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2387 - acc: 0.8870\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2365 - acc: 0.8884\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2355 - acc: 0.8887\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2338 - acc: 0.8900\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2321 - acc: 0.8908\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2304 - acc: 0.8911\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2278 - acc: 0.8927\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2276 - acc: 0.8923\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2272 - acc: 0.8928\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2252 - acc: 0.8938\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2239 - acc: 0.8942\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2233 - acc: 0.8948\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2218 - acc: 0.8954\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2205 - acc: 0.8962\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2205 - acc: 0.8959\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2192 - acc: 0.8964\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2180 - acc: 0.8970\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2177 - acc: 0.8971\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2162 - acc: 0.8978\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2157 - acc: 0.8986\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2161 - acc: 0.8981\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2140 - acc: 0.8987\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2138 - acc: 0.8988\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2128 - acc: 0.8997\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2123 - acc: 0.8997\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2119 - acc: 0.9000\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2105 - acc: 0.9006\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2104 - acc: 0.9004\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 44s 102us/step - loss: 0.2096 - acc: 0.9012\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2089 - acc: 0.9019\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2093 - acc: 0.9014\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2084 - acc: 0.9018\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 44s 102us/step - loss: 0.2071 - acc: 0.9021\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2076 - acc: 0.9023\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2069 - acc: 0.9029\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2065 - acc: 0.9029\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2071 - acc: 0.9021\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2067 - acc: 0.9024\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2064 - acc: 0.9025\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2063 - acc: 0.9023\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 44s 102us/step - loss: 0.2052 - acc: 0.9032\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2056 - acc: 0.9027\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2049 - acc: 0.9026\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2043 - acc: 0.9035\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2044 - acc: 0.9032\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2040 - acc: 0.9038\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2035 - acc: 0.9043\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2037 - acc: 0.9040\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2035 - acc: 0.9035\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2022 - acc: 0.9048\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2026 - acc: 0.9040\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2025 - acc: 0.9045\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2021 - acc: 0.9048\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2018 - acc: 0.9046\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2023 - acc: 0.9045\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2016 - acc: 0.9052\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2011 - acc: 0.9050\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2018 - acc: 0.9047\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.2002 - acc: 0.9055\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2001 - acc: 0.9057\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.2006 - acc: 0.9055\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1999 - acc: 0.9058\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1996 - acc: 0.9064\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1994 - acc: 0.9064\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1990 - acc: 0.9065\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1992 - acc: 0.9064\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.1994 - acc: 0.9062\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1990 - acc: 0.9065\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.1982 - acc: 0.9066\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1992 - acc: 0.9064\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.1988 - acc: 0.9068\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1983 - acc: 0.9069\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.1988 - acc: 0.9066\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1977 - acc: 0.9067\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1991 - acc: 0.9064\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.1977 - acc: 0.9069\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 44s 101us/step - loss: 0.1986 - acc: 0.9063\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 43s 101us/step - loss: 0.1982 - acc: 0.9065\n",
      "107448/107448 [==============================] - 2s 19us/step\n",
      "Time elapsed (hh:mm:ss.ms) 5:57:50.524383\n",
      "Overall accuracy of Neural Network model: 0.9016344620012248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 357.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8878    0.9192    0.9032    268256\n",
      "           1     0.9165    0.8841    0.9000    268985\n",
      "\n",
      "    accuracy                         0.9016    537241\n",
      "   macro avg     0.9021    0.9017    0.9016    537241\n",
      "weighted avg     0.9021    0.9016    0.9016    537241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_ae_ann_2h_prob_unisoftsigbinlosadam,pred_ae_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_cm(pred_ae_ann_2h_01_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_ae_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_ae_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with spae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sp_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=enc_train_x_spsam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  2 00:50:23 2019\n",
      "Train on 1375334 samples, validate on 343834 samples\n",
      "Epoch 1/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.4415 - acc: 0.7769 - val_loss: 0.3479 - val_acc: 0.8374\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34793, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 2/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.3052 - acc: 0.8574 - val_loss: 0.2838 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.34793 to 0.28379, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 3/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.2676 - acc: 0.8744 - val_loss: 0.2599 - val_acc: 0.8793\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.28379 to 0.25986, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 4/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.2483 - acc: 0.8831 - val_loss: 0.2341 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.25986 to 0.23406, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 5/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.2346 - acc: 0.8889 - val_loss: 0.2253 - val_acc: 0.8977\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.23406 to 0.22526, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 6/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.2237 - acc: 0.8942 - val_loss: 0.2128 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.22526 to 0.21284, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 7/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.2153 - acc: 0.8980 - val_loss: 0.2113 - val_acc: 0.8997\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.21284 to 0.21126, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 8/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.2094 - acc: 0.9010 - val_loss: 0.2007 - val_acc: 0.9056\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.21126 to 0.20072, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 9/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.2038 - acc: 0.9034 - val_loss: 0.1954 - val_acc: 0.9081\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.20072 to 0.19538, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 10/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1981 - acc: 0.9063 - val_loss: 0.1916 - val_acc: 0.9092\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.19538 to 0.19161, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 11/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1937 - acc: 0.9082 - val_loss: 0.1833 - val_acc: 0.9130\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.19161 to 0.18335, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 12/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1895 - acc: 0.9102 - val_loss: 0.1900 - val_acc: 0.9111\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.18335\n",
      "Epoch 13/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1869 - acc: 0.9118 - val_loss: 0.1831 - val_acc: 0.9143\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.18335 to 0.18314, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 14/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1836 - acc: 0.9129 - val_loss: 0.1795 - val_acc: 0.9165\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.18314 to 0.17947, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 15/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1814 - acc: 0.9141 - val_loss: 0.1715 - val_acc: 0.9191\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17947 to 0.17155, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 16/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1788 - acc: 0.9154 - val_loss: 0.2043 - val_acc: 0.9051\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.17155\n",
      "Epoch 17/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1770 - acc: 0.9161 - val_loss: 0.1777 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.17155\n",
      "Epoch 18/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1747 - acc: 0.9170 - val_loss: 0.1699 - val_acc: 0.9211\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.17155 to 0.16988, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 19/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1735 - acc: 0.9178 - val_loss: 0.1689 - val_acc: 0.9205\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.16988 to 0.16895, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 20/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1719 - acc: 0.9183 - val_loss: 0.1681 - val_acc: 0.9209\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.16895 to 0.16813, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 21/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1696 - acc: 0.9197 - val_loss: 0.1691 - val_acc: 0.9225\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.16813\n",
      "Epoch 22/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1685 - acc: 0.9201 - val_loss: 0.1647 - val_acc: 0.9221\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16813 to 0.16468, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 23/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1669 - acc: 0.9205 - val_loss: 0.1625 - val_acc: 0.9233\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.16468 to 0.16255, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 24/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1658 - acc: 0.9211 - val_loss: 0.1586 - val_acc: 0.9256\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.16255 to 0.15863, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 25/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1646 - acc: 0.9217 - val_loss: 0.1594 - val_acc: 0.9251\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.15863\n",
      "Epoch 26/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1637 - acc: 0.9220 - val_loss: 0.1605 - val_acc: 0.9245\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.15863\n",
      "Epoch 27/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1622 - acc: 0.9226 - val_loss: 0.1599 - val_acc: 0.9242\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.15863\n",
      "Epoch 28/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1616 - acc: 0.9228 - val_loss: 0.1626 - val_acc: 0.9231\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.15863\n",
      "Epoch 29/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1605 - acc: 0.9234 - val_loss: 0.1531 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15863 to 0.15310, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 30/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1593 - acc: 0.9241 - val_loss: 0.1549 - val_acc: 0.9283\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.15310\n",
      "Epoch 31/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1589 - acc: 0.9243 - val_loss: 0.1667 - val_acc: 0.9217\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.15310\n",
      "Epoch 32/200\n",
      "1375334/1375334 [==============================] - 38s 28us/step - loss: 0.1582 - acc: 0.9244 - val_loss: 0.1599 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.15310\n",
      "Epoch 33/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1569 - acc: 0.9253 - val_loss: 0.1552 - val_acc: 0.9270\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.15310\n",
      "Epoch 34/200\n",
      "1375334/1375334 [==============================] - 39s 28us/step - loss: 0.1562 - acc: 0.9254 - val_loss: 0.1566 - val_acc: 0.9257\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.15310\n",
      "Time elapsed (hh:mm:ss.ms) 0:21:57.071038\n"
     ]
    }
   ],
   "source": [
    "hist_sp_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ann_2h_unisoftsigbinlosadam_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                        ann = sp_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = enc_train_x_spsam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_sp_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_sp_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_sp_ann_2h_unisoftsigbinlosadam, './Figures/sp_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam = ann_predict(sp_ann_2h_unisoftsigbinlosadam,enc_test_x_spsam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_sp_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_sp_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=enc_train_x_asam\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=enc_test_x_spsam\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  2 01:12:21 2019\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "429792/429792 [==============================] - 45s 105us/step - loss: 0.5590 - acc: 0.6921\n",
      "Epoch 2/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.4237 - acc: 0.7903\n",
      "Epoch 3/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.3716 - acc: 0.8190\n",
      "Epoch 4/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.3425 - acc: 0.8344\n",
      "Epoch 5/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.3204 - acc: 0.8474\n",
      "Epoch 6/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.3060 - acc: 0.8556\n",
      "Epoch 7/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2928 - acc: 0.8620\n",
      "Epoch 8/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2831 - acc: 0.8667\n",
      "Epoch 9/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2749 - acc: 0.8714\n",
      "Epoch 10/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2680 - acc: 0.8746\n",
      "Epoch 11/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2619 - acc: 0.8774\n",
      "Epoch 12/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2567 - acc: 0.8801\n",
      "Epoch 13/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2511 - acc: 0.8826\n",
      "Epoch 14/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2462 - acc: 0.8859\n",
      "Epoch 15/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2434 - acc: 0.8868\n",
      "Epoch 16/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2407 - acc: 0.8883\n",
      "Epoch 17/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2363 - acc: 0.8902\n",
      "Epoch 18/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2346 - acc: 0.8909\n",
      "Epoch 19/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2315 - acc: 0.8926\n",
      "Epoch 20/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2283 - acc: 0.8943\n",
      "Epoch 21/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2252 - acc: 0.8955\n",
      "Epoch 22/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2240 - acc: 0.8962\n",
      "Epoch 23/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2221 - acc: 0.8971\n",
      "Epoch 24/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2203 - acc: 0.8980\n",
      "Epoch 25/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2179 - acc: 0.8990\n",
      "Epoch 26/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2165 - acc: 0.8998\n",
      "Epoch 27/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2156 - acc: 0.9000\n",
      "Epoch 28/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2145 - acc: 0.9009\n",
      "Epoch 29/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2121 - acc: 0.9023\n",
      "Epoch 30/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2113 - acc: 0.9026\n",
      "Epoch 31/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2100 - acc: 0.9028\n",
      "Epoch 32/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2083 - acc: 0.9036\n",
      "Epoch 33/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2071 - acc: 0.9041\n",
      "Epoch 34/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2059 - acc: 0.9048\n",
      "Epoch 35/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2043 - acc: 0.9058\n",
      "Epoch 36/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2028 - acc: 0.9063\n",
      "Epoch 37/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.2025 - acc: 0.9065\n",
      "Epoch 38/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2012 - acc: 0.9067\n",
      "Epoch 39/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.2002 - acc: 0.9075\n",
      "Epoch 40/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1995 - acc: 0.9078\n",
      "Epoch 41/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1985 - acc: 0.9083\n",
      "Epoch 42/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1986 - acc: 0.9081\n",
      "Epoch 43/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1987 - acc: 0.9083\n",
      "Epoch 44/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1979 - acc: 0.9090\n",
      "Epoch 45/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1972 - acc: 0.9088\n",
      "Epoch 46/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1953 - acc: 0.9094\n",
      "Epoch 47/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1949 - acc: 0.9106\n",
      "Epoch 48/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1949 - acc: 0.9103\n",
      "Epoch 49/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1946 - acc: 0.9100\n",
      "Epoch 50/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1937 - acc: 0.9102\n",
      "Epoch 51/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1928 - acc: 0.9108\n",
      "Epoch 52/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1924 - acc: 0.9114\n",
      "Epoch 53/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1915 - acc: 0.9116\n",
      "Epoch 54/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1911 - acc: 0.9116\n",
      "Epoch 55/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1910 - acc: 0.9122\n",
      "Epoch 56/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1907 - acc: 0.9119\n",
      "Epoch 57/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1897 - acc: 0.9128\n",
      "Epoch 58/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1894 - acc: 0.9127\n",
      "Epoch 59/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1881 - acc: 0.9133\n",
      "Epoch 60/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1887 - acc: 0.9130\n",
      "Epoch 61/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1880 - acc: 0.9129\n",
      "Epoch 62/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1874 - acc: 0.9141\n",
      "Epoch 63/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1869 - acc: 0.9141\n",
      "Epoch 64/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1868 - acc: 0.9141\n",
      "Epoch 65/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1868 - acc: 0.9142\n",
      "Epoch 66/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1872 - acc: 0.9135\n",
      "Epoch 67/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1854 - acc: 0.9149\n",
      "Epoch 68/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1855 - acc: 0.9141\n",
      "Epoch 69/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1856 - acc: 0.9150\n",
      "Epoch 70/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1843 - acc: 0.9154\n",
      "Epoch 71/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1842 - acc: 0.9152\n",
      "Epoch 72/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1849 - acc: 0.9150\n",
      "Epoch 73/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1846 - acc: 0.9151\n",
      "Epoch 74/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1832 - acc: 0.9156\n",
      "Epoch 75/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1838 - acc: 0.9154\n",
      "Epoch 76/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1835 - acc: 0.9151\n",
      "Epoch 77/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1833 - acc: 0.9156\n",
      "Epoch 78/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1835 - acc: 0.9154\n",
      "Epoch 79/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1827 - acc: 0.9163\n",
      "Epoch 80/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1824 - acc: 0.9161\n",
      "Epoch 81/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1821 - acc: 0.9161\n",
      "Epoch 82/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1822 - acc: 0.9164\n",
      "Epoch 83/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1823 - acc: 0.9165\n",
      "Epoch 84/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1816 - acc: 0.9167\n",
      "Epoch 85/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1817 - acc: 0.9164\n",
      "Epoch 86/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1816 - acc: 0.9163\n",
      "Epoch 87/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1815 - acc: 0.9168\n",
      "Epoch 88/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1819 - acc: 0.9160\n",
      "Epoch 89/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1813 - acc: 0.9165\n",
      "Epoch 90/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1809 - acc: 0.9166\n",
      "Epoch 91/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1812 - acc: 0.9165\n",
      "Epoch 92/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1803 - acc: 0.9167\n",
      "Epoch 93/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1802 - acc: 0.9170\n",
      "Epoch 94/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1800 - acc: 0.9170\n",
      "Epoch 95/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1800 - acc: 0.9169\n",
      "Epoch 96/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1803 - acc: 0.9175\n",
      "Epoch 97/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1798 - acc: 0.9175\n",
      "Epoch 98/100\n",
      "429792/429792 [==============================] - 44s 102us/step - loss: 0.1806 - acc: 0.9170\n",
      "Epoch 99/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1802 - acc: 0.9175\n",
      "Epoch 100/100\n",
      "429792/429792 [==============================] - 44s 103us/step - loss: 0.1795 - acc: 0.9173\n",
      "107449/107449 [==============================] - 2s 20us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 46s 106us/step - loss: 0.5618 - acc: 0.6897\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.4330 - acc: 0.7863\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.3804 - acc: 0.8177\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.3506 - acc: 0.8341\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.3326 - acc: 0.8430\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.3179 - acc: 0.8507\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.3064 - acc: 0.8566\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2969 - acc: 0.8615\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2887 - acc: 0.8657\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2819 - acc: 0.8685\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2765 - acc: 0.8716\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2714 - acc: 0.8742\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2658 - acc: 0.8771\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2630 - acc: 0.8781\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2598 - acc: 0.8796\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2555 - acc: 0.8817\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2531 - acc: 0.8821\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2513 - acc: 0.8835\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2482 - acc: 0.8846\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2458 - acc: 0.8857\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2434 - acc: 0.8871\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2420 - acc: 0.8879\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2404 - acc: 0.8885\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2387 - acc: 0.8890\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2363 - acc: 0.8906\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2345 - acc: 0.8907\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2336 - acc: 0.8909\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2318 - acc: 0.8925\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2312 - acc: 0.8923\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2294 - acc: 0.8929\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2288 - acc: 0.8940\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2281 - acc: 0.8942\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2267 - acc: 0.8949\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2249 - acc: 0.8957\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2237 - acc: 0.8965\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2232 - acc: 0.8968\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2219 - acc: 0.8969\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2206 - acc: 0.8975\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2211 - acc: 0.8975\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2196 - acc: 0.8977\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2188 - acc: 0.8981\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2183 - acc: 0.8993\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2179 - acc: 0.8992\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2161 - acc: 0.9000\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2160 - acc: 0.9001\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2154 - acc: 0.9005\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2149 - acc: 0.8999\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2139 - acc: 0.9010\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2136 - acc: 0.9012\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2128 - acc: 0.9018\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2130 - acc: 0.9012\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2126 - acc: 0.9012\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2120 - acc: 0.9020\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2115 - acc: 0.9016\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2115 - acc: 0.9024\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2112 - acc: 0.9020\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2102 - acc: 0.9025\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2088 - acc: 0.9032\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2087 - acc: 0.9034\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2091 - acc: 0.9033\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2078 - acc: 0.9042\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2077 - acc: 0.9039\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2073 - acc: 0.9045\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2076 - acc: 0.9036\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2068 - acc: 0.9043\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2070 - acc: 0.9042\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2063 - acc: 0.9046\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2064 - acc: 0.9041\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2053 - acc: 0.9050\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2052 - acc: 0.9048\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2051 - acc: 0.9058\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2047 - acc: 0.9053\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2043 - acc: 0.9058\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2043 - acc: 0.9057\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2039 - acc: 0.9052\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2045 - acc: 0.9054\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2033 - acc: 0.9061\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2027 - acc: 0.9059\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2036 - acc: 0.9055\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2032 - acc: 0.9059\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2033 - acc: 0.9065\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2028 - acc: 0.9062\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2033 - acc: 0.9059\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2024 - acc: 0.9066\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2023 - acc: 0.9058\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2031 - acc: 0.9060\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2020 - acc: 0.9066\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2015 - acc: 0.9063\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2015 - acc: 0.9064\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2014 - acc: 0.9068\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2019 - acc: 0.9064\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2016 - acc: 0.9070\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2009 - acc: 0.9074\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2005 - acc: 0.9072\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2003 - acc: 0.9073\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2012 - acc: 0.9066\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2003 - acc: 0.9072\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2007 - acc: 0.9072\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2002 - acc: 0.9072\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.1997 - acc: 0.9079\n",
      "107448/107448 [==============================] - 2s 21us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 46s 106us/step - loss: 0.5625 - acc: 0.6902\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.4268 - acc: 0.7894\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.3713 - acc: 0.8225\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.3405 - acc: 0.8397\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.3213 - acc: 0.8499\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.3073 - acc: 0.8569\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2952 - acc: 0.8628\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2853 - acc: 0.8679\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2775 - acc: 0.8712\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 44s 104us/step - loss: 0.2704 - acc: 0.8746\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2645 - acc: 0.8778\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2592 - acc: 0.8798\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2546 - acc: 0.8823\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2514 - acc: 0.8840\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2468 - acc: 0.8865\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2439 - acc: 0.8876\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.2415 - acc: 0.8885\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2384 - acc: 0.8893\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2356 - acc: 0.8910\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2330 - acc: 0.8923\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2311 - acc: 0.8934\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2291 - acc: 0.8944\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2276 - acc: 0.8950\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2246 - acc: 0.8962\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2242 - acc: 0.8964\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2224 - acc: 0.8977\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2206 - acc: 0.8976\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2184 - acc: 0.8991\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2178 - acc: 0.8992\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2158 - acc: 0.9000\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2152 - acc: 0.9004\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2138 - acc: 0.9010\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2122 - acc: 0.9016\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2113 - acc: 0.9023\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2109 - acc: 0.9022\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2090 - acc: 0.9031\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2089 - acc: 0.9034\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2079 - acc: 0.9039\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2068 - acc: 0.9041\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2057 - acc: 0.9049\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2052 - acc: 0.9050\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2047 - acc: 0.9055\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2028 - acc: 0.9059\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2038 - acc: 0.9055\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2026 - acc: 0.9065\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2013 - acc: 0.9064\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2011 - acc: 0.9066\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2012 - acc: 0.9070\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2006 - acc: 0.9065\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1997 - acc: 0.9075\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1994 - acc: 0.9077\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1994 - acc: 0.9076\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1992 - acc: 0.9072\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1983 - acc: 0.9071\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.1978 - acc: 0.9082\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1974 - acc: 0.9083\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1967 - acc: 0.9085\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1973 - acc: 0.9083\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.1968 - acc: 0.9087\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1959 - acc: 0.9092\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1951 - acc: 0.9092\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1949 - acc: 0.9094\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1944 - acc: 0.9100\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1951 - acc: 0.9094\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1936 - acc: 0.9100\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1938 - acc: 0.9099\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1941 - acc: 0.9097\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1935 - acc: 0.9099\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1939 - acc: 0.9101\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1929 - acc: 0.9105\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1931 - acc: 0.9103\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1925 - acc: 0.9107\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1924 - acc: 0.9102\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1924 - acc: 0.9108\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1928 - acc: 0.9108\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1919 - acc: 0.9108\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1912 - acc: 0.9113\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1917 - acc: 0.9108\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1916 - acc: 0.9110\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1912 - acc: 0.9109\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1917 - acc: 0.9107\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1907 - acc: 0.9115\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1905 - acc: 0.9119\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1901 - acc: 0.9120\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1907 - acc: 0.9113\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1904 - acc: 0.9116\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1899 - acc: 0.9116\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1904 - acc: 0.9117\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1906 - acc: 0.9117\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1898 - acc: 0.9116\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1898 - acc: 0.9119\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1896 - acc: 0.9119\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1900 - acc: 0.9114\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 44s 104us/step - loss: 0.1896 - acc: 0.9123\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 44s 103us/step - loss: 0.1895 - acc: 0.9117\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1890 - acc: 0.9121\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1891 - acc: 0.9121\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1892 - acc: 0.9115\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1887 - acc: 0.9127\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1888 - acc: 0.9122\n",
      "107448/107448 [==============================] - 2s 22us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.5612 - acc: 0.6908\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.4245 - acc: 0.7933\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3702 - acc: 0.8241\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3388 - acc: 0.8416\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.3167 - acc: 0.8526\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3007 - acc: 0.8604\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2896 - acc: 0.8653\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2815 - acc: 0.8695\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2726 - acc: 0.8739\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2664 - acc: 0.8769\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2604 - acc: 0.8798\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2547 - acc: 0.8820\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2487 - acc: 0.8849\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2445 - acc: 0.8871\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2407 - acc: 0.8889\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2371 - acc: 0.8909\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2329 - acc: 0.8927\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2311 - acc: 0.8929\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2281 - acc: 0.8945\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2257 - acc: 0.8960\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2231 - acc: 0.8973\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2206 - acc: 0.8981\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2195 - acc: 0.8989\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2170 - acc: 0.9000\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2154 - acc: 0.9011\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2132 - acc: 0.9012\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2122 - acc: 0.9023\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2110 - acc: 0.9025\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2096 - acc: 0.9033\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2079 - acc: 0.9044\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2065 - acc: 0.9049\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2055 - acc: 0.9051\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2049 - acc: 0.9057\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2042 - acc: 0.9058\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2024 - acc: 0.9064\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2020 - acc: 0.9071\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2016 - acc: 0.9077\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2009 - acc: 0.9074\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2008 - acc: 0.9076\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1980 - acc: 0.9084\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1985 - acc: 0.9092\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1973 - acc: 0.9093\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1971 - acc: 0.9090\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1968 - acc: 0.9099\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1956 - acc: 0.9103\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1952 - acc: 0.9101\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1956 - acc: 0.9101\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1945 - acc: 0.9106\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1936 - acc: 0.9107\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1930 - acc: 0.9108\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1927 - acc: 0.9114\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1928 - acc: 0.9112\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1909 - acc: 0.9127\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1918 - acc: 0.9119\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1910 - acc: 0.9120\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1908 - acc: 0.9122\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1907 - acc: 0.9123\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1893 - acc: 0.9123\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1896 - acc: 0.9127\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1883 - acc: 0.9134\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1885 - acc: 0.9132\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1882 - acc: 0.9128\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1877 - acc: 0.9130\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1867 - acc: 0.9140\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1866 - acc: 0.9143\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1862 - acc: 0.9144\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1856 - acc: 0.9141\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1872 - acc: 0.9135\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1847 - acc: 0.9146\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1855 - acc: 0.9147\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1849 - acc: 0.9149\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1847 - acc: 0.9152\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1850 - acc: 0.9142\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1848 - acc: 0.9143\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1848 - acc: 0.9145\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1843 - acc: 0.9149\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1839 - acc: 0.9153\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1840 - acc: 0.9151\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1836 - acc: 0.9148\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1836 - acc: 0.9150\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1828 - acc: 0.9156\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1824 - acc: 0.9159\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1826 - acc: 0.9158\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1815 - acc: 0.9162\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1821 - acc: 0.9156\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1824 - acc: 0.9157\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1820 - acc: 0.9159\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1822 - acc: 0.9156\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1810 - acc: 0.9164\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1812 - acc: 0.9167\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1800 - acc: 0.9167\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1812 - acc: 0.9165\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1805 - acc: 0.9170\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1801 - acc: 0.9165\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1807 - acc: 0.9165\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1805 - acc: 0.9168\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1793 - acc: 0.9174\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.1800 - acc: 0.9169\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1805 - acc: 0.9167\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.1798 - acc: 0.9174\n",
      "107448/107448 [==============================] - 2s 22us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 66)                2970      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 8,169\n",
      "Trainable params: 8,103\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.5583 - acc: 0.6926\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.4373 - acc: 0.7837\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3906 - acc: 0.8108\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3626 - acc: 0.8278\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3436 - acc: 0.8370\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3286 - acc: 0.8441\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3157 - acc: 0.8516\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.3065 - acc: 0.8547\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2980 - acc: 0.8595\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2911 - acc: 0.8632\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2852 - acc: 0.8657\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2801 - acc: 0.8684\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2758 - acc: 0.8706\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2721 - acc: 0.8727\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2690 - acc: 0.8747\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2655 - acc: 0.8755\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2631 - acc: 0.8771\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2600 - acc: 0.8789\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2582 - acc: 0.8793\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2560 - acc: 0.8806\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2539 - acc: 0.8818\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2522 - acc: 0.8824\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2501 - acc: 0.8831\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2481 - acc: 0.8842\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2472 - acc: 0.8847\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2448 - acc: 0.8858\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2432 - acc: 0.8868\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2424 - acc: 0.8872\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2407 - acc: 0.8878\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2394 - acc: 0.8887\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2382 - acc: 0.8892\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2365 - acc: 0.8898\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2355 - acc: 0.8897\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2347 - acc: 0.8905\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2328 - acc: 0.8914\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2324 - acc: 0.8922\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2317 - acc: 0.8921\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2310 - acc: 0.8927\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2295 - acc: 0.8933\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2295 - acc: 0.8932\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2282 - acc: 0.8941\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2273 - acc: 0.8939\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2267 - acc: 0.8945\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2257 - acc: 0.8948\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2254 - acc: 0.8952\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2249 - acc: 0.8947\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2236 - acc: 0.8960\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2240 - acc: 0.8957\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2234 - acc: 0.8960\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2222 - acc: 0.8965\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2215 - acc: 0.8973\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2207 - acc: 0.8975\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2204 - acc: 0.8977\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2204 - acc: 0.8976\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2187 - acc: 0.8982\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 45s 106us/step - loss: 0.2185 - acc: 0.8985\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2182 - acc: 0.8988\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2181 - acc: 0.8989\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2176 - acc: 0.8989\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2171 - acc: 0.8990\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2169 - acc: 0.8993\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2166 - acc: 0.8996\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 45s 106us/step - loss: 0.2160 - acc: 0.8992\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2162 - acc: 0.8988\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2154 - acc: 0.8995\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2153 - acc: 0.9000\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 45s 104us/step - loss: 0.2145 - acc: 0.8999\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2145 - acc: 0.9007\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2146 - acc: 0.9004\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2138 - acc: 0.9005\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2137 - acc: 0.9003\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2129 - acc: 0.9014\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2132 - acc: 0.9004\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2135 - acc: 0.9008\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2121 - acc: 0.9016\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2126 - acc: 0.9015\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2126 - acc: 0.9011\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2119 - acc: 0.9009\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2121 - acc: 0.9013\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2116 - acc: 0.9016\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2114 - acc: 0.9017\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2111 - acc: 0.9021\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2113 - acc: 0.9020\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2115 - acc: 0.9021\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2104 - acc: 0.9022\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2107 - acc: 0.9019\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2107 - acc: 0.9021\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2113 - acc: 0.9014\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2096 - acc: 0.9027\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2102 - acc: 0.9021\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2103 - acc: 0.9021\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2099 - acc: 0.9024\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2090 - acc: 0.9028\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2098 - acc: 0.9027\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2098 - acc: 0.9019\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2093 - acc: 0.9030\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2099 - acc: 0.9023\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2091 - acc: 0.9029\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2091 - acc: 0.9032\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 45s 105us/step - loss: 0.2095 - acc: 0.9027\n",
      "107448/107448 [==============================] - 2s 23us/step\n",
      "Time elapsed (hh:mm:ss.ms) 6:12:15.955674\n",
      "Overall accuracy of Neural Network model: 0.9131991043125897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 372.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9118    0.9146    0.9132    268256\n",
      "           1     0.9146    0.9118    0.9132    268985\n",
      "\n",
      "    accuracy                         0.9132    537241\n",
      "   macro avg     0.9132    0.9132    0.9132    537241\n",
      "weighted avg     0.9132    0.9132    0.9132    537241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_sp_ann_2h_prob_unisoftsigbinlosadam,pred_sp_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_cm(pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_sp_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_sp_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with no encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 9,621\n",
      "Trainable params: 9,555\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nodr_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=train_x,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  2 07:24:39 2019\n",
      "Train on 1375334 samples, validate on 343834 samples\n",
      "Epoch 1/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.3470 - acc: 0.8295 - val_loss: 0.2515 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.25153, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 2/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.2298 - acc: 0.8915 - val_loss: 0.2102 - val_acc: 0.9034\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.25153 to 0.21015, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 3/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.2004 - acc: 0.9057 - val_loss: 0.1974 - val_acc: 0.9089\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.21015 to 0.19742, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 4/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1835 - acc: 0.9138 - val_loss: 0.1728 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.19742 to 0.17282, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 5/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1723 - acc: 0.9189 - val_loss: 0.1650 - val_acc: 0.9219\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.17282 to 0.16501, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 6/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1634 - acc: 0.9232 - val_loss: 0.1561 - val_acc: 0.9279\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16501 to 0.15609, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 7/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1555 - acc: 0.9267 - val_loss: 0.1450 - val_acc: 0.9319\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.15609 to 0.14497, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 8/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1502 - acc: 0.9292 - val_loss: 0.1460 - val_acc: 0.9327\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.14497\n",
      "Epoch 9/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1455 - acc: 0.9315 - val_loss: 0.1407 - val_acc: 0.9346\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.14497 to 0.14075, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 10/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1414 - acc: 0.9334 - val_loss: 0.1378 - val_acc: 0.9367\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.14075 to 0.13778, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 11/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1379 - acc: 0.9352 - val_loss: 0.1328 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.13778 to 0.13280, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 12/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1347 - acc: 0.9365 - val_loss: 0.1294 - val_acc: 0.9399\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.13280 to 0.12938, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 13/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1314 - acc: 0.9380 - val_loss: 0.1256 - val_acc: 0.9421\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.12938 to 0.12564, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 14/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1292 - acc: 0.9391 - val_loss: 0.1214 - val_acc: 0.9435\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.12564 to 0.12137, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 15/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1271 - acc: 0.9399 - val_loss: 0.1216 - val_acc: 0.9442\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.12137\n",
      "Epoch 16/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1250 - acc: 0.9410 - val_loss: 0.1180 - val_acc: 0.9449\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.12137 to 0.11800, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 17/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1228 - acc: 0.9421 - val_loss: 0.1148 - val_acc: 0.9462\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.11800 to 0.11482, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 18/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1209 - acc: 0.9429 - val_loss: 0.1168 - val_acc: 0.9459\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.11482\n",
      "Epoch 19/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1189 - acc: 0.9438 - val_loss: 0.1122 - val_acc: 0.9480\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.11482 to 0.11223, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 20/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1179 - acc: 0.9442 - val_loss: 0.1100 - val_acc: 0.9489\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.11223 to 0.11001, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 21/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1163 - acc: 0.9452 - val_loss: 0.1182 - val_acc: 0.9457\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.11001\n",
      "Epoch 22/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1153 - acc: 0.9456 - val_loss: 0.1127 - val_acc: 0.9475\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.11001\n",
      "Epoch 23/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1139 - acc: 0.9462 - val_loss: 0.1104 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11001\n",
      "Epoch 24/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1121 - acc: 0.9471 - val_loss: 0.1110 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.11001\n",
      "Epoch 25/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1117 - acc: 0.9475 - val_loss: 0.1086 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.11001 to 0.10858, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 26/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1106 - acc: 0.9477 - val_loss: 0.1044 - val_acc: 0.9507\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.10858 to 0.10441, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 27/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1100 - acc: 0.9481 - val_loss: 0.1074 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.10441\n",
      "Epoch 28/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1093 - acc: 0.9484 - val_loss: 0.1046 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.10441\n",
      "Epoch 29/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1083 - acc: 0.9491 - val_loss: 0.1034 - val_acc: 0.9501\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.10441 to 0.10340, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 30/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1077 - acc: 0.9491 - val_loss: 0.1024 - val_acc: 0.9522\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.10340 to 0.10235, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 31/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1069 - acc: 0.9494 - val_loss: 0.1000 - val_acc: 0.9541\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.10235 to 0.09997, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 32/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1064 - acc: 0.9498 - val_loss: 0.1028 - val_acc: 0.9518\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.09997\n",
      "Epoch 33/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1055 - acc: 0.9505 - val_loss: 0.0977 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.09997 to 0.09766, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 34/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1052 - acc: 0.9506 - val_loss: 0.0992 - val_acc: 0.9536\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.09766\n",
      "Epoch 35/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1051 - acc: 0.9506 - val_loss: 0.0999 - val_acc: 0.9543\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.09766\n",
      "Epoch 36/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1044 - acc: 0.9509 - val_loss: 0.0979 - val_acc: 0.9551\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.09766\n",
      "Epoch 37/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1041 - acc: 0.9511 - val_loss: 0.0971 - val_acc: 0.9547\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.09766 to 0.09709, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 38/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1034 - acc: 0.9513 - val_loss: 0.0945 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.09709 to 0.09450, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds20bal.h5\n",
      "Epoch 39/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1034 - acc: 0.9515 - val_loss: 0.0986 - val_acc: 0.9549\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.09450\n",
      "Epoch 40/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1027 - acc: 0.9517 - val_loss: 0.0997 - val_acc: 0.9542\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.09450\n",
      "Epoch 41/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1027 - acc: 0.9518 - val_loss: 0.0957 - val_acc: 0.9557\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.09450\n",
      "Epoch 42/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1025 - acc: 0.9517 - val_loss: 0.0956 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.09450\n",
      "Epoch 43/200\n",
      "1375334/1375334 [==============================] - 44s 32us/step - loss: 0.1019 - acc: 0.9520 - val_loss: 0.1005 - val_acc: 0.9524\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.09450\n",
      "Time elapsed (hh:mm:ss.ms) 0:31:33.496958\n"
     ]
    }
   ],
   "source": [
    "hist_nodr_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ann_2h_unisoftsigbinlosadam_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                        ann = nodr_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = train_x,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_nodr_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_nodr_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_nodr_ann_2h_unisoftsigbinlosadam, './Figures/nodr_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_nodr_ann_2h_prob_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam = ann_predict(nodr_ann_2h_unisoftsigbinlosadam,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_nodr_ann_2h_01_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_nodr_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_nodr_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=train_x\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=test_x\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug  2 07:56:13 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 9,621\n",
      "Trainable params: 9,555\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429792/429792 [==============================] - 47s 110us/step - loss: 0.4425 - acc: 0.7719\n",
      "Epoch 2/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.3051 - acc: 0.8522\n",
      "Epoch 3/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.2631 - acc: 0.8750\n",
      "Epoch 4/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.2399 - acc: 0.8861\n",
      "Epoch 5/100\n",
      "429792/429792 [==============================] - 46s 108us/step - loss: 0.2257 - acc: 0.8933\n",
      "Epoch 6/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.2148 - acc: 0.8981\n",
      "Epoch 7/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.2059 - acc: 0.9019\n",
      "Epoch 8/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1987 - acc: 0.9054\n",
      "Epoch 9/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1928 - acc: 0.9084\n",
      "Epoch 10/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1875 - acc: 0.9111\n",
      "Epoch 11/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1829 - acc: 0.9124\n",
      "Epoch 12/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1780 - acc: 0.9156\n",
      "Epoch 13/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1751 - acc: 0.9170\n",
      "Epoch 14/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1713 - acc: 0.9188\n",
      "Epoch 15/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1685 - acc: 0.9203\n",
      "Epoch 16/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1657 - acc: 0.9216\n",
      "Epoch 17/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1632 - acc: 0.9224\n",
      "Epoch 18/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1613 - acc: 0.9234\n",
      "Epoch 19/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1595 - acc: 0.9241\n",
      "Epoch 20/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1571 - acc: 0.9255\n",
      "Epoch 21/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1553 - acc: 0.9263\n",
      "Epoch 22/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1543 - acc: 0.9266\n",
      "Epoch 23/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1527 - acc: 0.9269\n",
      "Epoch 24/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1518 - acc: 0.9275\n",
      "Epoch 25/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1509 - acc: 0.9284\n",
      "Epoch 26/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1495 - acc: 0.9285\n",
      "Epoch 27/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1488 - acc: 0.9290\n",
      "Epoch 28/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1480 - acc: 0.9293\n",
      "Epoch 29/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1470 - acc: 0.9296\n",
      "Epoch 30/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1466 - acc: 0.9296\n",
      "Epoch 31/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1457 - acc: 0.9304\n",
      "Epoch 32/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1448 - acc: 0.9308\n",
      "Epoch 33/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1441 - acc: 0.9312\n",
      "Epoch 34/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1435 - acc: 0.9314\n",
      "Epoch 35/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1429 - acc: 0.9318\n",
      "Epoch 36/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1418 - acc: 0.9320\n",
      "Epoch 37/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1418 - acc: 0.9325\n",
      "Epoch 38/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1413 - acc: 0.9322\n",
      "Epoch 39/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1405 - acc: 0.9329\n",
      "Epoch 40/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1400 - acc: 0.9332\n",
      "Epoch 41/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1399 - acc: 0.9329\n",
      "Epoch 42/100\n",
      "429792/429792 [==============================] - 46s 108us/step - loss: 0.1390 - acc: 0.9334\n",
      "Epoch 43/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1391 - acc: 0.9334\n",
      "Epoch 44/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1385 - acc: 0.9339\n",
      "Epoch 45/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1386 - acc: 0.9340\n",
      "Epoch 46/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1378 - acc: 0.9340\n",
      "Epoch 47/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1379 - acc: 0.9340\n",
      "Epoch 48/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1371 - acc: 0.9342\n",
      "Epoch 49/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1371 - acc: 0.9341\n",
      "Epoch 50/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1359 - acc: 0.9349\n",
      "Epoch 51/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1373 - acc: 0.9346\n",
      "Epoch 52/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1363 - acc: 0.9352\n",
      "Epoch 53/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1361 - acc: 0.9354\n",
      "Epoch 54/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1352 - acc: 0.9353\n",
      "Epoch 55/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1366 - acc: 0.9347\n",
      "Epoch 56/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1352 - acc: 0.9352\n",
      "Epoch 57/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1344 - acc: 0.9358\n",
      "Epoch 58/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1346 - acc: 0.9359\n",
      "Epoch 59/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1337 - acc: 0.9367\n",
      "Epoch 60/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1348 - acc: 0.9359\n",
      "Epoch 61/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1344 - acc: 0.9360\n",
      "Epoch 62/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1338 - acc: 0.9362\n",
      "Epoch 63/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1330 - acc: 0.9365\n",
      "Epoch 64/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1335 - acc: 0.9364\n",
      "Epoch 65/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1324 - acc: 0.9374\n",
      "Epoch 66/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1325 - acc: 0.9368\n",
      "Epoch 67/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1324 - acc: 0.9372\n",
      "Epoch 68/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1328 - acc: 0.9371\n",
      "Epoch 69/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1320 - acc: 0.9372\n",
      "Epoch 70/100\n",
      "429792/429792 [==============================] - 46s 106us/step - loss: 0.1314 - acc: 0.9375\n",
      "Epoch 71/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1317 - acc: 0.9372\n",
      "Epoch 72/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1316 - acc: 0.9379\n",
      "Epoch 73/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1312 - acc: 0.9379\n",
      "Epoch 74/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1315 - acc: 0.9377\n",
      "Epoch 75/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1314 - acc: 0.9378\n",
      "Epoch 76/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1315 - acc: 0.9375\n",
      "Epoch 77/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1306 - acc: 0.9380\n",
      "Epoch 78/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1300 - acc: 0.9382\n",
      "Epoch 79/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1304 - acc: 0.9383\n",
      "Epoch 80/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1306 - acc: 0.9381\n",
      "Epoch 81/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1303 - acc: 0.9381\n",
      "Epoch 82/100\n",
      "429792/429792 [==============================] - 46s 106us/step - loss: 0.1293 - acc: 0.9385\n",
      "Epoch 83/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1292 - acc: 0.9385\n",
      "Epoch 84/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1304 - acc: 0.9383\n",
      "Epoch 85/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1301 - acc: 0.9380\n",
      "Epoch 86/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1296 - acc: 0.9385\n",
      "Epoch 87/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1301 - acc: 0.9388\n",
      "Epoch 88/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1303 - acc: 0.9384\n",
      "Epoch 89/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1288 - acc: 0.9387\n",
      "Epoch 90/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1295 - acc: 0.9387\n",
      "Epoch 91/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1293 - acc: 0.9390\n",
      "Epoch 92/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1289 - acc: 0.9388\n",
      "Epoch 93/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1290 - acc: 0.9389\n",
      "Epoch 94/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1288 - acc: 0.9388\n",
      "Epoch 95/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1286 - acc: 0.9389\n",
      "Epoch 96/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1292 - acc: 0.9388\n",
      "Epoch 97/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1291 - acc: 0.9387\n",
      "Epoch 98/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1293 - acc: 0.9386\n",
      "Epoch 99/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1293 - acc: 0.9388\n",
      "Epoch 100/100\n",
      "429792/429792 [==============================] - 46s 107us/step - loss: 0.1292 - acc: 0.9389\n",
      "107449/107449 [==============================] - 3s 24us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_59 (Dense)             (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 9,621\n",
      "Trainable params: 9,555\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.4423 - acc: 0.7745\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.3069 - acc: 0.8518\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.2659 - acc: 0.8727\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.2427 - acc: 0.8845\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.2268 - acc: 0.8925\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.2152 - acc: 0.8982\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.2066 - acc: 0.9030\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1994 - acc: 0.9065\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1936 - acc: 0.9090\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1887 - acc: 0.9113\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1845 - acc: 0.9136\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1805 - acc: 0.9157\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1769 - acc: 0.9175\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1746 - acc: 0.9189\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1710 - acc: 0.9206\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1679 - acc: 0.9219\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1660 - acc: 0.9231\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1639 - acc: 0.9242\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1606 - acc: 0.9256\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1583 - acc: 0.9264\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1570 - acc: 0.9276\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1556 - acc: 0.9284\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1544 - acc: 0.9292\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1530 - acc: 0.9294\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1518 - acc: 0.9304\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1508 - acc: 0.9302\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1491 - acc: 0.9313\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1484 - acc: 0.9322\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1470 - acc: 0.9325\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1473 - acc: 0.9322\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1454 - acc: 0.9334\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1454 - acc: 0.9335\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1437 - acc: 0.9339\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1439 - acc: 0.9340\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1430 - acc: 0.9349\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1430 - acc: 0.9348\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1426 - acc: 0.9345\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1414 - acc: 0.9352\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1404 - acc: 0.9358\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1402 - acc: 0.9360\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1389 - acc: 0.9366\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1387 - acc: 0.9363\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1383 - acc: 0.9370\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1381 - acc: 0.9368\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1380 - acc: 0.9367\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1368 - acc: 0.9380\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1373 - acc: 0.9369\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1355 - acc: 0.9381\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1358 - acc: 0.9380\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1354 - acc: 0.9380\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1346 - acc: 0.9383\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1358 - acc: 0.9376\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1344 - acc: 0.9385\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1338 - acc: 0.9392\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1341 - acc: 0.9384\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1338 - acc: 0.9386\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1334 - acc: 0.9387\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1334 - acc: 0.9390\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1327 - acc: 0.9396\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1326 - acc: 0.9387\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1333 - acc: 0.9390\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1319 - acc: 0.9399\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1310 - acc: 0.9402\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1317 - acc: 0.9396\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1317 - acc: 0.9400\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1316 - acc: 0.9394\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1308 - acc: 0.9399\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1303 - acc: 0.9406\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1306 - acc: 0.9406\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1305 - acc: 0.9401\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1298 - acc: 0.9401\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1304 - acc: 0.9402\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1294 - acc: 0.9409\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1291 - acc: 0.9406\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1292 - acc: 0.9407\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1295 - acc: 0.9410\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1282 - acc: 0.9410\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1289 - acc: 0.9407\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1284 - acc: 0.9412\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1283 - acc: 0.9411\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1281 - acc: 0.9409\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1278 - acc: 0.9415\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1279 - acc: 0.9412\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1270 - acc: 0.9413\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1270 - acc: 0.9423\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1285 - acc: 0.9415\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1274 - acc: 0.9415\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1274 - acc: 0.9416\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1270 - acc: 0.9417\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1271 - acc: 0.9418\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1263 - acc: 0.9417\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1265 - acc: 0.9416\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1261 - acc: 0.9419\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1265 - acc: 0.9421\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1269 - acc: 0.9418\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1265 - acc: 0.9422\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 46s 107us/step - loss: 0.1257 - acc: 0.9424\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 46s 108us/step - loss: 0.1258 - acc: 0.9422\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1260 - acc: 0.9423\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1258 - acc: 0.9424\n",
      "107448/107448 [==============================] - 3s 27us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_63 (Dense)             (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 9,621\n",
      "Trainable params: 9,555\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 49s 115us/step - loss: 0.4470 - acc: 0.7699\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.3102 - acc: 0.8516\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2707 - acc: 0.8718\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2485 - acc: 0.8828\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2316 - acc: 0.8910\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2211 - acc: 0.8960\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2126 - acc: 0.9001\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2045 - acc: 0.9039\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1993 - acc: 0.9068\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1937 - acc: 0.9094\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1891 - acc: 0.9118\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1850 - acc: 0.9132\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1808 - acc: 0.9155\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1788 - acc: 0.9159\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1757 - acc: 0.9172\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1736 - acc: 0.9186\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1705 - acc: 0.9204\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1687 - acc: 0.9208\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1676 - acc: 0.9213\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1652 - acc: 0.9221\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1648 - acc: 0.9222\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1631 - acc: 0.9233\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1604 - acc: 0.9243\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1594 - acc: 0.9251\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1579 - acc: 0.9260\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1577 - acc: 0.9263\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1558 - acc: 0.9269\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1550 - acc: 0.9275\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1541 - acc: 0.9277\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1529 - acc: 0.9282\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1524 - acc: 0.9292\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1516 - acc: 0.9293\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1502 - acc: 0.9300\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1506 - acc: 0.9301\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1491 - acc: 0.9304\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1485 - acc: 0.9311\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1477 - acc: 0.9311\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1480 - acc: 0.9308\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1473 - acc: 0.9313\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1464 - acc: 0.9314\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1460 - acc: 0.9316\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1452 - acc: 0.9320\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1455 - acc: 0.9322\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1439 - acc: 0.9332\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1439 - acc: 0.9331\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1431 - acc: 0.9335\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1430 - acc: 0.9337\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1421 - acc: 0.9337\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1424 - acc: 0.9336\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1422 - acc: 0.9336\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1416 - acc: 0.9339\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1417 - acc: 0.9336\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1405 - acc: 0.9346\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1413 - acc: 0.9341\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1411 - acc: 0.9341\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1407 - acc: 0.9346\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1399 - acc: 0.9344\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1395 - acc: 0.9352\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1392 - acc: 0.9350\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1391 - acc: 0.9354\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1382 - acc: 0.9353\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1380 - acc: 0.9356\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1383 - acc: 0.9355\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1387 - acc: 0.9353\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1380 - acc: 0.9353\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1376 - acc: 0.9356\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1368 - acc: 0.9364\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1370 - acc: 0.9361\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1366 - acc: 0.9364\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1365 - acc: 0.9363\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1362 - acc: 0.9366\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1360 - acc: 0.9365\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1361 - acc: 0.9364\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1362 - acc: 0.9367\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1345 - acc: 0.9367\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1346 - acc: 0.9367\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1353 - acc: 0.9366\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1350 - acc: 0.9368\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1348 - acc: 0.9373\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1342 - acc: 0.9379\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1349 - acc: 0.9369\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1342 - acc: 0.9374\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1340 - acc: 0.9374\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 47s 108us/step - loss: 0.1345 - acc: 0.9369\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1335 - acc: 0.9376\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1345 - acc: 0.9373\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1333 - acc: 0.9378\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1335 - acc: 0.9378\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1334 - acc: 0.9381\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1329 - acc: 0.9380\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1336 - acc: 0.9377\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1322 - acc: 0.9382\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1324 - acc: 0.9382\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1335 - acc: 0.9373\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1327 - acc: 0.9382\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1323 - acc: 0.9380\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1320 - acc: 0.9383\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1320 - acc: 0.9386\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1329 - acc: 0.9381\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1323 - acc: 0.9383\n",
      "107448/107448 [==============================] - 3s 26us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_67 (Dense)             (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 9,621\n",
      "Trainable params: 9,555\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 49s 113us/step - loss: 0.4521 - acc: 0.7676\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.3158 - acc: 0.8492\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.2727 - acc: 0.8708\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.2494 - acc: 0.8824\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.2332 - acc: 0.8899\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.2216 - acc: 0.8961\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.2126 - acc: 0.9001\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.2056 - acc: 0.9032\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1996 - acc: 0.9058\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1940 - acc: 0.9089\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1903 - acc: 0.9108\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1859 - acc: 0.9132\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1811 - acc: 0.9156\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1782 - acc: 0.9163\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1758 - acc: 0.9179\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1725 - acc: 0.9193\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1698 - acc: 0.9208\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1673 - acc: 0.9215\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1655 - acc: 0.9229\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1632 - acc: 0.9238\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1609 - acc: 0.9246\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1599 - acc: 0.9250\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1581 - acc: 0.9259\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1571 - acc: 0.9266\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1557 - acc: 0.9272\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1550 - acc: 0.9276\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1535 - acc: 0.9285\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1529 - acc: 0.9282\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1518 - acc: 0.9294\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1512 - acc: 0.9294\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1508 - acc: 0.9297\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1497 - acc: 0.9304\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1491 - acc: 0.9300\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1488 - acc: 0.9310\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1473 - acc: 0.9313\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1479 - acc: 0.9309\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1470 - acc: 0.9312\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1463 - acc: 0.9313\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1460 - acc: 0.9316\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1450 - acc: 0.9324\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1446 - acc: 0.9324\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1442 - acc: 0.9324\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1441 - acc: 0.9330\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1430 - acc: 0.9332\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1429 - acc: 0.9332\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1424 - acc: 0.9332\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1420 - acc: 0.9335\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1420 - acc: 0.9331\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1421 - acc: 0.9336\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1413 - acc: 0.9336\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1408 - acc: 0.9336\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1406 - acc: 0.9343\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1411 - acc: 0.9343\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1403 - acc: 0.9343\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1401 - acc: 0.9342\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1399 - acc: 0.9347\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1390 - acc: 0.9352\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1392 - acc: 0.9351\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1390 - acc: 0.9352\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1384 - acc: 0.9354\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1381 - acc: 0.9358\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1383 - acc: 0.9360\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1389 - acc: 0.9352\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1369 - acc: 0.9361\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1387 - acc: 0.9357\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1376 - acc: 0.9364\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1374 - acc: 0.9361\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1370 - acc: 0.9360\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1363 - acc: 0.9362\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1362 - acc: 0.9367\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1369 - acc: 0.9365\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1366 - acc: 0.9362\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1359 - acc: 0.9367\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1357 - acc: 0.9370\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1358 - acc: 0.9371\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1353 - acc: 0.9368\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1353 - acc: 0.9370\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1344 - acc: 0.9375\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1347 - acc: 0.9374\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1346 - acc: 0.9373\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1346 - acc: 0.9373\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1339 - acc: 0.9381\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1348 - acc: 0.9373\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1342 - acc: 0.9375\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1336 - acc: 0.9381\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1337 - acc: 0.9380\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1341 - acc: 0.9379\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1336 - acc: 0.9379\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1338 - acc: 0.9376\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1332 - acc: 0.9379\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1323 - acc: 0.9384\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1322 - acc: 0.9383\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1332 - acc: 0.9383\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1319 - acc: 0.9389\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1322 - acc: 0.9387\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 47s 109us/step - loss: 0.1322 - acc: 0.9390\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1320 - acc: 0.9389\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1320 - acc: 0.9392\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1334 - acc: 0.9384\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1311 - acc: 0.9391\n",
      "107448/107448 [==============================] - 3s 27us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_71 (Dense)             (None, 66)                4422      \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 50)                3350      \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 33)                1683      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 33)                132       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 33)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 34        \n",
      "=================================================================\n",
      "Total params: 9,621\n",
      "Trainable params: 9,555\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "429793/429793 [==============================] - 49s 114us/step - loss: 0.4564 - acc: 0.7646\n",
      "Epoch 2/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.3183 - acc: 0.8472\n",
      "Epoch 3/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2746 - acc: 0.8692\n",
      "Epoch 4/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2511 - acc: 0.8804\n",
      "Epoch 5/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.2351 - acc: 0.8883\n",
      "Epoch 6/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.2232 - acc: 0.8934\n",
      "Epoch 7/100\n",
      "429793/429793 [==============================] - 47s 111us/step - loss: 0.2136 - acc: 0.8984\n",
      "Epoch 8/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.2062 - acc: 0.9019\n",
      "Epoch 9/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1991 - acc: 0.9054\n",
      "Epoch 10/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1932 - acc: 0.9082\n",
      "Epoch 11/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1887 - acc: 0.9103\n",
      "Epoch 12/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1839 - acc: 0.9121\n",
      "Epoch 13/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1794 - acc: 0.9149\n",
      "Epoch 14/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1773 - acc: 0.9157\n",
      "Epoch 15/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1743 - acc: 0.9169\n",
      "Epoch 16/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1715 - acc: 0.9179\n",
      "Epoch 17/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1689 - acc: 0.9196\n",
      "Epoch 18/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1666 - acc: 0.9209\n",
      "Epoch 19/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1647 - acc: 0.9219\n",
      "Epoch 20/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1632 - acc: 0.9221\n",
      "Epoch 21/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1613 - acc: 0.9233\n",
      "Epoch 22/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1595 - acc: 0.9242\n",
      "Epoch 23/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1577 - acc: 0.9252\n",
      "Epoch 24/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1561 - acc: 0.9261\n",
      "Epoch 25/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1545 - acc: 0.9267\n",
      "Epoch 26/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1539 - acc: 0.9264\n",
      "Epoch 27/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1526 - acc: 0.9270\n",
      "Epoch 28/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1520 - acc: 0.9273\n",
      "Epoch 29/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1503 - acc: 0.9284\n",
      "Epoch 30/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1504 - acc: 0.9286\n",
      "Epoch 31/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1489 - acc: 0.9292\n",
      "Epoch 32/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1489 - acc: 0.9290\n",
      "Epoch 33/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1479 - acc: 0.9297\n",
      "Epoch 34/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1479 - acc: 0.9292\n",
      "Epoch 35/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1471 - acc: 0.9300\n",
      "Epoch 36/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1472 - acc: 0.9299\n",
      "Epoch 37/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1463 - acc: 0.9306\n",
      "Epoch 38/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1459 - acc: 0.9309\n",
      "Epoch 39/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1454 - acc: 0.9307\n",
      "Epoch 40/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1451 - acc: 0.9307\n",
      "Epoch 41/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1454 - acc: 0.9311\n",
      "Epoch 42/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1448 - acc: 0.9310\n",
      "Epoch 43/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1444 - acc: 0.9312\n",
      "Epoch 44/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1436 - acc: 0.9317\n",
      "Epoch 45/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1442 - acc: 0.9315\n",
      "Epoch 46/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1433 - acc: 0.9320\n",
      "Epoch 47/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1430 - acc: 0.9319\n",
      "Epoch 48/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1433 - acc: 0.9318\n",
      "Epoch 49/100\n",
      "429793/429793 [==============================] - 47s 111us/step - loss: 0.1428 - acc: 0.9323\n",
      "Epoch 50/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1418 - acc: 0.9326\n",
      "Epoch 51/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1419 - acc: 0.9331\n",
      "Epoch 52/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1415 - acc: 0.9329\n",
      "Epoch 53/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1418 - acc: 0.9329\n",
      "Epoch 54/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1408 - acc: 0.9334\n",
      "Epoch 55/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1404 - acc: 0.9333\n",
      "Epoch 56/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1404 - acc: 0.9338\n",
      "Epoch 57/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1402 - acc: 0.9336\n",
      "Epoch 58/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1403 - acc: 0.9338\n",
      "Epoch 59/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1394 - acc: 0.9343\n",
      "Epoch 60/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1399 - acc: 0.9338\n",
      "Epoch 61/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1391 - acc: 0.9342\n",
      "Epoch 62/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1396 - acc: 0.9337\n",
      "Epoch 63/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1396 - acc: 0.9341\n",
      "Epoch 64/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1388 - acc: 0.9343\n",
      "Epoch 65/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1387 - acc: 0.9338\n",
      "Epoch 66/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1378 - acc: 0.9352\n",
      "Epoch 67/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1376 - acc: 0.9350\n",
      "Epoch 68/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1383 - acc: 0.9345\n",
      "Epoch 69/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1378 - acc: 0.9348\n",
      "Epoch 70/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1379 - acc: 0.9348\n",
      "Epoch 71/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1376 - acc: 0.9346\n",
      "Epoch 72/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1373 - acc: 0.9350\n",
      "Epoch 73/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1378 - acc: 0.9346\n",
      "Epoch 74/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1370 - acc: 0.9356\n",
      "Epoch 75/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1373 - acc: 0.9349\n",
      "Epoch 76/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1366 - acc: 0.9356\n",
      "Epoch 77/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1370 - acc: 0.9351\n",
      "Epoch 78/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1372 - acc: 0.9351\n",
      "Epoch 79/100\n",
      "429793/429793 [==============================] - 47s 110us/step - loss: 0.1380 - acc: 0.9347\n",
      "Epoch 80/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1356 - acc: 0.9356\n",
      "Epoch 81/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1367 - acc: 0.9349\n",
      "Epoch 82/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1364 - acc: 0.9348\n",
      "Epoch 83/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1363 - acc: 0.9351\n",
      "Epoch 84/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1362 - acc: 0.9355\n",
      "Epoch 85/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1364 - acc: 0.9353\n",
      "Epoch 86/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1353 - acc: 0.9357\n",
      "Epoch 87/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1359 - acc: 0.9360\n",
      "Epoch 88/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1359 - acc: 0.9359\n",
      "Epoch 89/100\n",
      "429793/429793 [==============================] - 48s 112us/step - loss: 0.1354 - acc: 0.9359\n",
      "Epoch 90/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1352 - acc: 0.9358\n",
      "Epoch 91/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1362 - acc: 0.9355\n",
      "Epoch 92/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1349 - acc: 0.9361\n",
      "Epoch 93/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1348 - acc: 0.9359\n",
      "Epoch 94/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1351 - acc: 0.9358\n",
      "Epoch 95/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1350 - acc: 0.9364\n",
      "Epoch 96/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1350 - acc: 0.9360\n",
      "Epoch 97/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1348 - acc: 0.9361\n",
      "Epoch 98/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1351 - acc: 0.9359\n",
      "Epoch 99/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1348 - acc: 0.9364\n",
      "Epoch 100/100\n",
      "429793/429793 [==============================] - 48s 111us/step - loss: 0.1336 - acc: 0.9366\n",
      "107448/107448 [==============================] - 3s 28us/step\n",
      "Time elapsed (hh:mm:ss.ms) 6:31:42.718199\n",
      "Overall accuracy of Neural Network model: 0.941404323199458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 391.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9379    0.9452    0.9416    268256\n",
      "           1     0.9449    0.9376    0.9413    268985\n",
      "\n",
      "    accuracy                         0.9414    537241\n",
      "   macro avg     0.9414    0.9414    0.9414    537241\n",
      "weighted avg     0.9414    0.9414    0.9414    537241\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_nodr_ann_2h_prob_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_cm(pred_nodr_ann_2h_01_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_nodr_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_nodr_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with ae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_ = PCA(n_components = 0.95, svd_solver = 'full').fit(train_x)\n",
    "\n",
    "# plt.figure(figsize=(8,5))\n",
    "# n_coml = [pca_.n_components_]\n",
    "\n",
    "# plt.plot(np.cumsum(pca_.explained_variance_ratio_))\n",
    "# plt.xlabel('Number of Components', fontsize=14)\n",
    "# plt.ylabel('Variance (%)', fontsize=14) #for each component\n",
    "# plt.title('Pulsar Dataset Explained Variance '+str(dsnum)+' node DS', fontsize=14)\n",
    "\n",
    "# n_coml = [*n_coml]\n",
    "\n",
    "# for i, v in enumerate(n_coml):\n",
    "#     plt.text(v-0.8, i+0.94, '{:.0f}'.format(v), color='navy', fontsize=14)\n",
    "\n",
    "# plt.savefig('./Figures/PCA_components_ds'+str(dsnum)+'bal.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=300, \n",
    "#                              criterion='gini', \n",
    "#                              max_depth=16, \n",
    "#                              #min_samples_split=2, \n",
    "#                              #min_samples_leaf=1, \n",
    "#                              max_features=0.3, \n",
    "#                              #bootstrap=True,\n",
    "#                              oob_score=True,\n",
    "#                              random_state=23)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# print(datetime.ctime(start_time))\n",
    "\n",
    "# clf.fit(enc_train_x_asam, train_y)\n",
    "\n",
    "# pred_y_ae_RF = cross_val_predict(estimator=clf,\n",
    "#                               X=np.array(enc_test_x_asam),\n",
    "#                               y=test_y,\n",
    "#                               cv=KFold(n_splits=5, random_state=23),\n",
    "#                               n_jobs=2)\n",
    "\n",
    "# time_elapsed = datetime.now() - start_time \n",
    "# print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "# print(sm.classification_report(test_y, pred_y_ae_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_y_ae_RF, pred_y_ae_RF, './Figures/ROC_ae_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png', './Figures/CM_ae_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with spae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# print(datetime.ctime(start_time))\n",
    "\n",
    "# clf.fit(enc_train_x_spsam, train_y)\n",
    "\n",
    "# pred_y_spae_RF = cross_val_predict(estimator=clf,\n",
    "#                               X=np.array(enc_test_x_spsam),\n",
    "#                               y=test_y,\n",
    "#                               cv=KFold(n_splits=5, random_state=23),\n",
    "#                               n_jobs=2)\n",
    "\n",
    "# time_elapsed = datetime.now() - start_time \n",
    "# print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "# print(sm.classification_report(test_y, pred_y_spae_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_y_spae_RF, pred_y_spae_RF, './Figures/ROC_spae_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png', './Figures/CM_spae_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with pca DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# print(datetime.ctime(start_time))\n",
    "\n",
    "# clf.fit(train_x_pca, train_y)\n",
    "\n",
    "# pred_y_pca_RF = cross_val_predict(estimator=clf,\n",
    "#                               X=np.array(test_x_pca),\n",
    "#                               y=test_y,\n",
    "#                               cv=KFold(n_splits=5, random_state=23),\n",
    "#                               n_jobs=2)\n",
    "\n",
    "# time_elapsed = datetime.now() - start_time \n",
    "# print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "# print(sm.classification_report(test_y, pred_y_pca_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_y_pca_RF, pred_y_pca_RF, './Figures/ROC_pca_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png', './Figures/CM_pca_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537241,)\n",
      "(537241,)\n",
      "(537241,)\n",
      "(537241,)\n",
      "(537241,)\n",
      "(537241,)\n"
     ]
    }
   ],
   "source": [
    "print(pred_ae_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_ae_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "print(pred_sp_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_sp_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "print(pred_nodr_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_nodr_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "# print(pred_y_ae_RF.shape)\n",
    "# print(pred_y_spae_RF.shape)\n",
    "# print(pred_y_pca_RF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "false_positive_rate_ae_ann, recall_ae_ann, thresholds_ae_ann = roc_curve(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_ae_ann = auc(false_positive_rate_ae_ann, recall_ae_ann)\n",
    "false_positive_rate_sp_ann, recall_sp_ann, thresholds_sp_ann = roc_curve(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_sp_ann = auc(false_positive_rate_sp_ann, recall_sp_ann)\n",
    "false_positive_rate_nodr_ann, recall_nodr_ann, thresholds_nodr_ann = roc_curve(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_nodr_ann = auc(false_positive_rate_nodr_ann, recall_nodr_ann)\n",
    "\n",
    "# false_positive_rate_ae_RF, recall_ae_RF, thresholds_ae_RF = roc_curve(test_y, pred_y_ae_RF)\n",
    "# roc_auc_ae_RF = auc(false_positive_rate_ae_RF, recall_ae_RF)\n",
    "# false_positive_rate_spae_RF, recall_spae_RF, thresholds_spae_RF = roc_curve(test_y, pred_y_spae_RF)\n",
    "# roc_auc_spae_RF = auc(false_positive_rate_spae_RF, recall_spae_RF)\n",
    "# false_positive_rate_pca_RF, recall_pca_RF, thresholds_pca_RF = roc_curve(test_y, pred_y_pca_RF)\n",
    "# roc_auc_pca_RF = auc(false_positive_rate_pca_RF, recall_pca_RF)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.title('Receiver Operating Characteristic (ROC)', fontsize=16)\n",
    "\n",
    "plt.plot(false_positive_rate_ae_ann, recall_ae_ann, 'b', label = 'AUC AE + DNN = %0.3f' %roc_auc_ae_ann)\n",
    "plt.plot(false_positive_rate_sp_ann, recall_sp_ann, 'g', label = 'AUC SAE + DNN = %0.3f' %roc_auc_sp_ann)\n",
    "plt.plot(false_positive_rate_nodr_ann, recall_nodr_ann, 'r', label = 'AUC DNN = %0.3f' %roc_auc_nodr_ann)\n",
    "# plt.plot(false_positive_rate_ae_RF, recall_ae_RF, 'c', label = 'AUC AE + RF = %0.3f' %roc_auc_ae_RF)\n",
    "# plt.plot(false_positive_rate_spae_RF, recall_spae_RF, 'm', label = 'AUC SAE + RF = %0.3f' %roc_auc_spae_RF)\n",
    "# plt.plot(false_positive_rate_pca_RF, recall_pca_RF, 'black', label = 'AUC PCA + RF = %0.3f' %roc_auc_pca_RF)\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "# plt.ylim([0.97,1.0])\n",
    "\n",
    "plt.ylabel('Recall - TPR', fontsize=14)\n",
    "plt.xlabel('Fall-out (1-Specificity) - FPR', fontsize=14)\n",
    "plt.savefig('./Figures/ROC_allmodels'+str(dsnum)+'bal.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title('Receiver Operating Characteristic (ROC) Zoom in', fontsize=16)\n",
    "\n",
    "plt.plot(false_positive_rate_ae_ann, recall_ae_ann, 'b', label = 'AUC AE + DNN = %0.3f' %roc_auc_ae_ann)\n",
    "plt.plot(false_positive_rate_sp_ann, recall_sp_ann, 'g', label = 'AUC SAE + DNN = %0.3f' %roc_auc_sp_ann)\n",
    "plt.plot(false_positive_rate_nodr_ann, recall_nodr_ann, 'r', label = 'AUC DNN = %0.3f' %roc_auc_nodr_ann)\n",
    "# plt.plot(false_positive_rate_ae_RF, recall_ae_RF, 'c', label = 'AUC AE + RF = %0.3f' %roc_auc_ae_RF)\n",
    "# plt.plot(false_positive_rate_spae_RF, recall_spae_RF, 'm', label = 'AUC SAE + RF = %0.3f' %roc_auc_spae_RF)\n",
    "# plt.plot(false_positive_rate_pca_RF, recall_pca_RF, 'black', label = 'AUC PCA + RF = %0.3f' %roc_auc_pca_RF)\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "# plt.ylim([0.0,1.0])\n",
    "plt.ylim([0.955,1.0])\n",
    "\n",
    "plt.ylabel('Recall - TPR', fontsize=14)\n",
    "plt.xlabel('Fall-out (1-Specificity) - FPR', fontsize=14)\n",
    "plt.savefig('./Figures/ROC_allmodels'+str(dsnum)+'bal_zoom.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier\tAcc\tPreci\tRecall\tF1Score\n",
      "AE+DNN\t\t90.16\t91.65\t88.41\t90.00\n",
      "SAE+DNN\t\t91.32\t91.46\t91.18\t91.32\n",
      "DNN\t\t94.14\t94.49\t93.76\t94.13\n"
     ]
    }
   ],
   "source": [
    "classi_ae_ann = \"AE+DNN\"\n",
    "acc_ae_ann = (sm.accuracy_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_ae_ann = (sm.precision_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_ae_ann = (sm.recall_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_ae_ann = (sm.f1_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "classi_sp_ann = \"SAE+DNN\"\n",
    "acc_sp_ann = (sm.accuracy_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_sp_ann = (sm.precision_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_sp_ann = (sm.recall_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_sp_ann = (sm.f1_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "classi_nodr_ann = \"DNN\"\n",
    "acc_nodr_ann = (sm.accuracy_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_nodr_ann = (sm.precision_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_nodr_ann = (sm.recall_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_nodr_ann = (sm.f1_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "# classi_ae_RF = \"AE+RF\"\n",
    "# acc_ae_RF = (sm.accuracy_score(test_y, pred_y_ae_RF)*100) \n",
    "# pre_ae_RF = (sm.precision_score(test_y, pred_y_ae_RF)*100) \n",
    "# recall_ae_RF = (sm.recall_score(test_y, pred_y_ae_RF)*100) \n",
    "# f1score_ae_RF = (sm.f1_score(test_y, pred_y_ae_RF)*100)\n",
    "\n",
    "# classi_spae_RF = \"SAE+RF\"\n",
    "# acc_spae_RF = (sm.accuracy_score(test_y, pred_y_spae_RF)*100) \n",
    "# pre_spae_RF = (sm.precision_score(test_y, pred_y_spae_RF)*100) \n",
    "# recall_spae_RF = (sm.recall_score(test_y, pred_y_spae_RF)*100) \n",
    "# f1score_spae_RF = (sm.f1_score(test_y, pred_y_spae_RF)*100)\n",
    "\n",
    "# classi_pca_RF = \"PCA+RF\"\n",
    "# acc_pca_RF = (sm.accuracy_score(test_y, pred_y_pca_RF)*100) \n",
    "# pre_pca_RF = (sm.precision_score(test_y, pred_y_pca_RF)*100) \n",
    "# recall_pca_RF = (sm.recall_score(test_y, pred_y_pca_RF)*100) \n",
    "# f1score_pca_RF = (sm.f1_score(test_y, pred_y_pca_RF)*100)\n",
    "\n",
    "\n",
    "print('Classifier\\tAcc\\tPreci\\tRecall\\tF1Score')\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_ae_ann, acc_ae_ann, pre_ae_ann, recall_ae_ann, f1score_ae_ann))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_sp_ann, acc_sp_ann, pre_sp_ann, recall_sp_ann, f1score_sp_ann))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_nodr_ann, acc_nodr_ann, pre_nodr_ann, recall_nodr_ann, f1score_nodr_ann))\n",
    "# print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_ae_RF, acc_ae_RF, pre_ae_RF, recall_ae_RF, f1score_ae_RF))\n",
    "# print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_spae_RF, acc_spae_RF, pre_spae_RF, recall_spae_RF, f1score_spae_RF))\n",
    "# print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_pca_RF, acc_pca_RF, pre_pca_RF, recall_pca_RF, f1score_pca_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1list = [[\"AE+DNN\",f1score_ae_ann],[\"SAE+DNN\",f1score_sp_ann],[\"DNN\",f1score_nodr_ann]]#,\n",
    "#           [\"AE+RF\",f1score_ae_RF],[\"SAE+RF\",f1score_spae_RF],[\"PCA+RF\",f1score_pca_RF]]\n",
    "\n",
    "xs, ys = [*zip(*f1list)]\n",
    "\n",
    "'{:.2f}'.format(f1score_ae_ann)\n",
    "\n",
    "plt.figure(figsize=(8,6), )\n",
    "plt.barh(xs, ys, color = \"purple\")\n",
    "plt.title(\"F1 score vs Classifier\", fontsize=16)\n",
    "plt.xlabel(\"Classifier\", fontsize=14)\n",
    "plt.ylabel(\"F1 score\", fontsize=14)\n",
    "plt.xticks(np.arange(0, 101, 10), fontsize=12)\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "for i, v in enumerate(ys):\n",
    "    plt.text(v+1, i+0.1, '{:.2f}'.format(v), color='purple', fontsize=14)\n",
    "\n",
    "plt.savefig('./Figures/F1scoreplot_allmodels'+str(dsnum)+'bal.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
