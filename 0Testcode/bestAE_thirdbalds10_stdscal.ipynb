{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# TensorFlow wizardry\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Donâ€™t pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.05\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "from keras import optimizers, regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Activation, Dense, Dropout, Input\n",
    "from keras import backend as k\n",
    "\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "#k.tensorflow_backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Import modules------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(23)\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathds = '/home/user/01Code/00Datasets_final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_chunk = pd.read_csv(pathds+'SubsetAllSamples/ThirdCloneID10bal_minmax.csv', chunksize=1000)\n",
    "#df = df_chunk.get_chunk(300000)\n",
    "df = pd.read_csv(pathds+'SubsetAllSamples/ThirdCloneID10bal_stdscal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Explaining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you don't have an intuitive sense of how imbalanced these two classes are, let's go visual\n",
    "count_classes = pd.value_counts(df['class'], sort = True)\n",
    "print('Class 0:', count_classes[0])\n",
    "print('Class 1:', count_classes[1])\n",
    "print('Proportion:', round(count_classes[0] / count_classes[1], 3), ': 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.xticks(range(2), ['Normal [0]','Malicious [1]'])\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed and percentage of test data\n",
    "RANDOM_SEED = 23 #used to help randomly select the data points\n",
    "TEST_PCT = 0.20 # 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df, test_size=TEST_PCT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ df -> original dataset \n",
    "+ train -> subset of 80% from original dataset \n",
    "+ test_df -> subset of 20% from original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df = train_test_split(train, test_size=TEST_PCT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train -> subset of 80% from original dataset \n",
    "+ train_df -> subset of 80% from train\n",
    "+ dev_df -> subset of 20% from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of mal samples in train and test set\n",
    "print(train_df.iloc[:, 48].sum()/train_df.shape[0]) \n",
    "print(dev_df.iloc[:, 48].sum()/dev_df.shape[0]) \n",
    "print(test_df.iloc[:, 48].sum()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.iloc[:, :48] \n",
    "dev_x = dev_df.iloc[:, :48] \n",
    "test_x = test_df.iloc[:, :48] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train_x -> features of train_df **Training subset for AE**\n",
    "+ dev_x -> features of dev_df **Validation subset for AE**\n",
    "+ test_x -> features of test_df **Testing subset for ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final train and test sets\n",
    "train_y = train_df.iloc[:, 48]\n",
    "dev_y = dev_df.iloc[:, 48]\n",
    "test_y = test_df.iloc[:, 48]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train_y -> **Labels for supervised training of ANN**\n",
    "+ dev_y -> labels of dev_df  *not used for AE neither ANN*\n",
    "+ test_y -> labels of test_df  **Ground Truth for predictions of supervised ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x =np.array(train_x)\n",
    "dev_x =np.array(dev_x)\n",
    "test_x = np.array(test_x)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "dev_y = np.array(dev_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "print(train_x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding_dim - 2\n",
    "\n",
    "Epoch 94/300 78596/78596 [==============================] - 10s 125us/step \n",
    "- loss: 3.8990e-05 - acc: 0.0237 - \n",
    "        val_loss: 3.9704e-05 - val_acc: 0.0236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae(factor_enc_dim, enc_activation, dec_activation, \n",
    "                optimizer, loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer #RELU\n",
    "    encoded = Dense(encoding_dim, activation=enc_activation, name='encoded_bottle_neck')(input_data)\n",
    "    ### Define decoding layer #SIMOID\n",
    "    decoded = Dense(train_x.shape[1], activation=dec_activation)(encoded)\n",
    "    ### Create the autoencoder model\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(autoencoder.summary())\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return autoencoder,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sae(factor_enc_dim, output_activation,\n",
    "        optimizer, loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer\n",
    "    encoded = Dense(encoding_dim, activation='relu', name='input_layer')(input_data)\n",
    "    encoded = Dense(int(encoding_dim/2), activation='relu')(encoded) ##Stacked AE\n",
    "    encoded_bottle_neck = Dense(int(encoding_dim/4), activation='relu', name='enc_bottle_neck')(encoded) ##Stacked AE\n",
    "    \n",
    "    ### Define decoding layer\n",
    "    decoded = Dense(int(encoding_dim/2), activation='relu')(encoded_bottle_neck) ##Stacked AE\n",
    "    decoded = Dense(encoding_dim, activation='relu')(decoded) ##Stacked AE\n",
    "    decoded = Dense(train_x.shape[1], activation=output_activation)(decoded)\n",
    "    \n",
    "    ### Create the autoencoder model\n",
    "    sae = Model(input_data, decoded)\n",
    "    sae.compile(optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    print(sae.summary())\n",
    "\n",
    "    encoder = Model(input_data, encoded_bottle_neck)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return sae,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spae(factor_enc_dim, output_activation, \n",
    "                optimizer, loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer\n",
    "    encoded = Dense(encoding_dim, activity_regularizer=regularizers.l1(1e-4), activation='relu', name='encoded_bottle_neck')(input_data)\n",
    "    ### Define decoding layer\n",
    "    decoded = Dense(train_x.shape[1], activation=output_activation)(encoded)\n",
    "    ### Create the autoencoder model\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(autoencoder.summary())\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return autoencoder,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ae(checkpoint_file, autoencoder,\n",
    "           epochs, batch_size, shuffle):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    cp = ModelCheckpoint(filepath=checkpoint_file,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=0)\n",
    "\n",
    "    tb = TensorBoard(log_dir='./logs',\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(time.ctime(start_time))\n",
    "\n",
    "    hist_auto = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    verbose=1,\n",
    "                    callbacks=[early_stopping, cp, tb],\n",
    "                    validation_data=(dev_x, dev_x))\n",
    "\n",
    "    elapsed_time = (time.time() - start_time)\n",
    "    print(\"--- AE spent %s seconds ---\" % elapsed_time)\n",
    "    \n",
    "    return hist_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_auto(hist_auto, fig_file):\n",
    "    best_loss_value = hist_auto.history['loss'][-1]\n",
    "    print('Best loss value:', best_loss_value)\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.figure()\n",
    "    plt.plot(hist_auto.history['loss'])\n",
    "    plt.plot(hist_auto.history['val_loss'])\n",
    "    plt.title('Autoencoder model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.savefig(fig_file)\n",
    "    plt.show()\n",
    "    \n",
    "    return best_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h(neurons,encoded_train_x,init_mode,activation_input,\n",
    "               weight_constraint,dropout_rate,activation_output,\n",
    "               loss,optimizer):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(36, activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "\n",
    "    model.add(Dense(24, activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h_(neurons,encoded_train_x,init_mode,activation_input,\n",
    "               dropout_rate,activation_output,\n",
    "               loss,lr):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "#                     kernel_constraint=maxnorm(weight_constraint)\n",
    "#                     kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(36, activation=\"relu\")) #rezvy\n",
    "\n",
    "    model.add(Dense(24, activation=\"relu\")) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "\n",
    "    optimizer = optimizers.Adam(lr=lr)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h__(neurons,encoded_train_x,activation_input,\n",
    "             activation_output,loss,optimizer):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "#                     kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "#                     kernel_constraint=maxnorm(weight_constraint)\n",
    "#                     kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(36, activation=\"relu\")) #rezvy\n",
    "\n",
    "    model.add(Dense(24, activation=\"relu\")) #rezvy\n",
    "#     model.add(BatchNormalization()) #commented for ex\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "\n",
    "#     optimizer = optimizers.Adam(lr=lr)\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_1h_36n(neurons,encoded_train_x,init_mode,activation_input,\n",
    "               weight_constraint,dropout_rate,activation_output,\n",
    "               loss,optimizer):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(36, activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_1h_24n(neurons,encoded_train_x,init_mode,activation_input,\n",
    "               weight_constraint,dropout_rate,activation_output,\n",
    "               loss,optimizer):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(24, activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_1h_24n_(neurons,encoded_train_x,activation_input,\n",
    "               activation_output,loss,optimizer):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "#                     kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "#                     kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(24, activation=\"relu\")) #rezvy\n",
    "    \n",
    "#     model.add(BatchNormalization()) #commented for ex\n",
    "#     model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_fit(checkpoint_file,ann,enc_train_x,train_y,epochs,shuffle,batch_size):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    cp = ModelCheckpoint(filepath=checkpoint_file,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=0)\n",
    "\n",
    "    tb = TensorBoard(log_dir='./logs',\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=True)\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(time.ctime(start_time))\n",
    "\n",
    "    history = ann.fit(enc_train_x,\n",
    "                      train_y,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[early_stopping],\n",
    "                      epochs=epochs,\n",
    "                      shuffle=shuffle,\n",
    "                      batch_size=batch_size,\n",
    "                      verbose=1)\n",
    "\n",
    "    elapsed_time = (time.time() - start_time)\n",
    "    print(\"--- ANN spent %s seconds ---\" % elapsed_time)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict(ann,enc_test_x):\n",
    "    pred_ann_prob = ann.predict(enc_test_x)\n",
    "    pred_ann_prob.shape\n",
    "    pred_ann_prob = pred_ann_prob[:,0]\n",
    "    pred_ann_01 = np.where(pred_ann_prob > 0.5, 1, 0)\n",
    "    \n",
    "    #Print accuracy\n",
    "    acc_ann = accuracy_score(test_y, pred_ann_01)\n",
    "    print('Overall accuracy of Neural Network model:', acc_ann)\n",
    "\n",
    "    classiBM = \"NN\"\n",
    "    preBM = (sm.precision_score(test_y, pred_ann_01)*100) \n",
    "    recallBM = (sm.recall_score(test_y, pred_ann_01)*100) \n",
    "    f1scoreBM = (sm.f1_score(test_y, pred_ann_01)*100)\n",
    "    print(sm.classification_report(test_y, pred_ann_01))\n",
    "    \n",
    "    return pred_ann_prob, pred_ann_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_cm(pred_ann_prob, pred_ann_01, roc_file, cm_file):\n",
    "    false_positive_rate, recall, thresholds = roc_curve(test_y, pred_ann_prob)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    plt.figure()\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Fall-out (1-Specificity)')\n",
    "    plt.savefig(roc_file)\n",
    "    plt.show()\n",
    "    \n",
    "    cm = confusion_matrix(test_y, pred_ann_01)\n",
    "    labels = ['Normal', 'Malicious']\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm,xticklabels=labels, yticklabels=labels, annot=True, fmt='d', cmap=\"RdYlGn\", vmin = 0.2);\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.savefig(cm_file)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: 2.7516e-05 - acc: 0.0407 \n",
    "\n",
    "val_loss: 2.7072e-05 - val_acc: 0.0399"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_sigmoid_adam_logcosh,enc_train_x_asal,enc_test_x_asal = ae(factor_enc_dim = 1.5,\n",
    "                                                              enc_activation = 'relu',\n",
    "                                                              dec_activation = 'sigmoid',\n",
    "                                                              optimizer='Adam',\n",
    "                                                              loss='logcosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_sigmoid_adam_logcosh = load_model('ae_sigmoid_adam_logcosh_redds10bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ae_sigmoid_adam_logcosh = fit_ae(checkpoint_file = \"ae_sigmoid_adam_logcosh_redds10bal.h5\",\n",
    "                                        autoencoder = ae_sigmoid_adam_logcosh, \n",
    "                                        epochs = 200, \n",
    "                                        batch_size = 48, \n",
    "                                        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ae_sigmoid_adam_logcosh = plot_hist_auto(hist_ae_sigmoid_adam_logcosh, './Figures/ae_sigmoid_adam_logcosh.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_siglin_adam_logcosh,enc_train_x_aslal,enc_test_x_aslal = ae(factor_enc_dim = 1.5,\n",
    "                                                              enc_activation = 'sigmoid',\n",
    "                                                              dec_activation = 'linear',\n",
    "                                                              optimizer='Adam',\n",
    "                                                              loss='logcosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_siglin_adam_logcosh = load_model('ae_siglin_adam_logcosh_redds10bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ae_siglin_adam_logcosh = fit_ae(checkpoint_file = \"ae_siglin_adam_logcosh_redds10bal.h5\",\n",
    "                                        autoencoder = ae_siglin_adam_logcosh, \n",
    "                                        epochs = 200, \n",
    "                                        batch_size = 48, \n",
    "                                        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ae_siglin_adam_logcosh = plot_hist_auto(hist_ae_siglin_adam_logcosh, './Figures/hist_ae_siglin_adam_logcosh.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_sigmoid_adam_mse,enc_train_x_asam,enc_test_x_asam = ae(factor_enc_dim = 1.5,\n",
    "                                                          enc_activation = 'relu',\n",
    "                                                          dec_activation = 'sigmoid',\n",
    "                                                          optimizer='Adam',\n",
    "                                                          loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_sigmoid_adam_mse = load_model('ae_sigmoid_adam_mse_redds10bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ae_sigmoid_adam_mse = fit_ae(checkpoint_file = \"ae_sigmoid_adam_mse_redds10bal.h5\",\n",
    "                                  autoencoder = ae_sigmoid_adam_mse, \n",
    "                                  epochs = 200, \n",
    "                                  batch_size = 48,\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ae_sigmoid_adam_mse  = plot_hist_auto(hist_ae_sigmoid_adam_mse, './Figures/hist_ae_sigmoid_adam_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_sigsig_adam_logcosh,enc_train_x_assal,enc_test_x_assal = ae(factor_enc_dim = 1.5,\n",
    "                                                          enc_activation = 'sigmoid',\n",
    "                                                          dec_activation = 'sigmoid',\n",
    "                                                          optimizer='Adam',\n",
    "                                                          loss='logcosh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_sigsig_adam_logcosh = load_model('ae_sigsig_adam_logcosh_redds10bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ae_sigsig_adam_logcosh = fit_ae(checkpoint_file = \"ae_sigsig_adam_logcosh_redds10bal.h5\",\n",
    "                                  autoencoder = ae_sigsig_adam_logcosh, \n",
    "                                  epochs = 200, \n",
    "                                  batch_size = 48,\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ae_sigsig_adam_logcosh  = plot_hist_auto(hist_ae_sigsig_adam_logcosh, './Figures/hist_ae_sigsig_adam_logcosh.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valueDict = {\n",
    "    'loss_value_ae_sigmoid_adam_logcosh': best_loss_value_ae_sigmoid_adam_logcosh,\n",
    "    'loss_value_ae_sigmoid_adam_mse': best_loss_value_ae_sigmoid_adam_mse,\n",
    "    'loss_value_ae_siglin_adam_logcosh': best_loss_value_ae_siglin_adam_logcosh,\n",
    "    'loss_value_ae_sigsig_adam_logcosh': best_loss_value_ae_sigsig_adam_logcosh\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_train_x_asal.shape)\n",
    "print(enc_test_x_asal.shape)\n",
    "\n",
    "print(enc_train_x_asam.shape)\n",
    "print(enc_test_x_asam.shape)\n",
    "\n",
    "print(enc_train_x_aslal.shape)\n",
    "print(enc_test_x_aslal.shape)\n",
    "\n",
    "print(enc_train_x_assal.shape)\n",
    "print(enc_test_x_assal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ====================== Fail ANN ======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann36n_unisoftsigbinlosadam = ann_1h_36n(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asal,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='softsign',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann36n_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"ann36n_unisoftsigbinlosadam_redds10bal.h5\",\n",
    "                                        ann = ann36n_unisoftsigbinlosadam,\n",
    "                                        enc_train_x = enc_train_x_asal,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann36n_unisoftsigbinlosadam = plot_hist_auto(hist_ann36n_unisoftsigbinlosadam, './Figures/ann36_unisoftsigbinlosadam.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann36n_prob_unisoftsigbinlosadam, pred_ann36n_01_unisoftsigbinlosadam = ann_predict(ann36n_unisoftsigbinlosadam,enc_test_x_asal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann36n_01_unisoftsigbinlosadam, pred_ann36n_01_unisoftsigbinlosadam, './Figures/ROC_ann36n_unisoftsigbinlosadam_redds10bal.png', './Figures/CM_ann36n_unisoftsigbinlosadam_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann36n_unisoftsigbinlosadam2 = ann_1h_36n(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='softsign',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann36n_unisoftsigbinlosadam2 = ann_fit(checkpoint_file = \"ann36n_unisoftsigbinlosadam2_redds10bal.h5\",\n",
    "                                        ann = ann36n_unisoftsigbinlosadam2,\n",
    "                                        enc_train_x = enc_train_x_asam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann36n_unisoftsigbinlosadam2 = plot_hist_auto(hist_ann36n_unisoftsigbinlosadam2, './Figures/ann36_unisoftsigbinlosadam2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann36n_prob_unisoftsigbinlosadam, pred_ann36n_01_unisoftsigbinlosadam2 = ann_predict(ann36n_unisoftsigbinlosadam2,enc_test_x_asam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann36n_01_unisoftsigbinlosadam, pred_ann36n_01_unisoftsigbinlosadam, './Figures/ROC_ann36n_unisoftsigbinlosadam_redds10bal.png', './Figures/CM_ann36n_unisoftsigbinlosadam_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann24n_unisoftsigbinlosadam = ann_1h_24n(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='softsign',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann24n_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"ann24n_unisoftsigbinlosadam_redds10bal.h5\",\n",
    "                                        ann = ann24n_unisoftsigbinlosadam,\n",
    "                                        enc_train_x = enc_train_x_asam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann24n_unisoftsigbinlosadam = plot_hist_auto(hist_ann24n_unisoftsigbinlosadam, './Figures/ann24_unisoftsigbinlosadam.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann24n_prob_unisoftsigbinlosadam, pred_ann24n_01_unisoftsigbinlosadam = ann_predict(ann24n_unisoftsigbinlosadam,enc_test_x_asam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann24n_01_unisoftsigbinlosadam, pred_ann24n_01_unisoftsigbinlosadam, './Figures/ROC_ann24n_unisoftsigbinlosadam_redds10bal.png', './Figures/CM_ann24n_unisoftsigbinlosadam_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_2h_unisoftsigbinlosadam = ann_2h(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='softsign',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"ann_2h_unisoftsigbinlosadam_redds10bal.h5\",\n",
    "                                        ann = ann_2h_unisoftsigbinlosadam,\n",
    "                                        enc_train_x = enc_train_x_asam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_ann_2h_unisoftsigbinlosadam, './Figures/ann_2h_unisoftsigbinlosadam.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_2h_prob_unisoftsigbinlosadam, pred_ann_2h_01_unisoftsigbinlosadam = ann_predict(ann_2h_unisoftsigbinlosadam,enc_test_x_asam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_2h_01_unisoftsigbinlosadam, pred_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_ann_2h_unisoftsigbinlosadam_redds10bal.png', './Figures/CM_ann_2h_unisoftsigbinlosadam_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_2h_unisoftsigbinlosadam2 = ann_2h_(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asal,\n",
    "#                                       init_mode='glorot_uniform',\n",
    "                                       init_mode='VarianceScaling',\n",
    "#                                       activation_input='softsign',\n",
    "                                      activation_input='relu',\n",
    "#                                       weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam2 = ann_fit(checkpoint_file = \"ann_2h_unisoftsigbinlosadam2_redds10bal.h5\",\n",
    "                                        ann = ann_2h_unisoftsigbinlosadam2,\n",
    "                                        enc_train_x = enc_train_x_asal,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_2h_unisoftsigbinlosadam2 = plot_hist_auto(hist_ann_2h_unisoftsigbinlosadam2, './Figures/ann_2h_unisoftsigbinlosadam2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_2h_prob_unisoftsigbinlosadam2, pred_ann_2h_01_unisoftsigbinlosadam2 = ann_predict(ann_2h_unisoftsigbinlosadam2,enc_test_x_asal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_2h_01_unisoftsigbinlosadam2, pred_ann_2h_01_unisoftsigbinlosadam2, './Figures/ROC_ann_2h_unisoftsigbinlosadam2_redds10bal.png', './Figures/CM_ann_2h_unisoftsigbinlosadam2_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_2h_unisoftsigbinlosadam3 = ann_2h(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam3 = ann_fit(checkpoint_file = \"ann_2h_unisoftsigbinlosadam3_redds10bal.h5\",\n",
    "                                        ann = ann_2h_unisoftsigbinlosadam3,\n",
    "                                        enc_train_x = enc_train_x_asam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_2h_unisoftsigbinlosadam3 = plot_hist_auto(hist_ann_2h_unisoftsigbinlosadam3, './Figures/ann_2h_unisoftsigbinlosadam3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_2h_prob_unisoftsigbinlosadam3, pred_ann_2h_01_unisoftsigbinlosadam3 = ann_predict(ann_2h_unisoftsigbinlosadam3,enc_test_x_asam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_2h_01_unisoftsigbinlosadam3, pred_ann_2h_01_unisoftsigbinlosadam3, './Figures/ROC_ann_2h_unisoftsigbinlosadam3_redds10bal.png', './Figures/CM_ann_2h_unisoftsigbinlosadam3_redds10bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### >>>>>>>>>>>>>>>>>>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_2h_unisoftsigbinlosadam4 = ann_2h(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asal,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam4 = ann_fit(checkpoint_file = \"ann_2h_unisoftsigbinlosadam4_redds10bal.h5\",\n",
    "                                        ann = ann_2h_unisoftsigbinlosadam4,\n",
    "                                        enc_train_x = enc_train_x_asal,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_2h_unisoftsigbinlosadam4 = plot_hist_auto(hist_ann_2h_unisoftsigbinlosadam4, './Figures/ann_2h_unisoftsigbinlosadam4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_2h_prob_unisoftsigbinlosadam4, pred_ann_2h_01_unisoftsigbinlosadam4 = ann_predict(ann_2h_unisoftsigbinlosadam4,enc_test_x_asal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_2h_01_unisoftsigbinlosadam4, pred_ann_2h_01_unisoftsigbinlosadam4, './Figures/ROC_ann_2h_unisoftsigbinlosadam4_redds10bal.png', './Figures/CM_ann_2h_unisoftsigbinlosadam4_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ann_2h__(neurons,encoded_train_x,activation_input,\n",
    "               dropout_rate,activation_output,\n",
    "               loss,optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_2h_unisoftsigbinlosadam5 = ann_2h__(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asal,\n",
    "                                      activation_input='relu',\n",
    "#                                       dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam5 = ann_fit(checkpoint_file = \"ann_2h_unisoftsigbinlosadam5_redds10bal.h5\",\n",
    "                                        ann = ann_2h_unisoftsigbinlosadam5,\n",
    "                                        enc_train_x = enc_train_x_asal,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_2h_unisoftsigbinlosadam5 = plot_hist_auto(hist_ann_2h_unisoftsigbinlosadam5, './Figures/ann_2h_unisoftsigbinlosadam5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_2h_prob_unisoftsigbinlosadam5, pred_ann_2h_01_unisoftsigbinlosadam5 = ann_predict(ann_2h_unisoftsigbinlosadam5,enc_test_x_asal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_2h_01_unisoftsigbinlosadam5, pred_ann_2h_01_unisoftsigbinlosadam5, './Figures/ROC_ann_2h_unisoftsigbinlosadam5_redds10bal.png', './Figures/CM_ann_2h_unisoftsigbinlosadam5_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_2h_unisoftsigbinlosadam6 = ann_2h__(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asam,\n",
    "                                      activation_input='relu',\n",
    "#                                       dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam6 = ann_fit(checkpoint_file = \"ann_2h_unisoftsigbinlosadam6_redds10bal.h5\",\n",
    "                                        ann = ann_2h_unisoftsigbinlosadam6,\n",
    "                                        enc_train_x = enc_train_x_asam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_2h_unisoftsigbinlosadam6 = plot_hist_auto(hist_ann_2h_unisoftsigbinlosadam6, './Figures/ann_2h_unisoftsigbinlosadam6.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_2h_prob_unisoftsigbinlosadam6, pred_ann_2h_01_unisoftsigbinlosadam6 = ann_predict(ann_2h_unisoftsigbinlosadam6,enc_test_x_asam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_2h_01_unisoftsigbinlosadam6, pred_ann_2h_01_unisoftsigbinlosadam6, './Figures/ROC_ann_2h_unisoftsigbinlosadam6_redds10bal.png', './Figures/CM_ann_2h_unisoftsigbinlosadam6_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x_assal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_2h_unisoftsigbinlosadam7 = ann_2h__(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asal,\n",
    "                                      activation_input='tanh',\n",
    "#                                       dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam7 = ann_fit(checkpoint_file = \"ann_2h_unisoftsigbinlosadam7_redds10bal.h5\",\n",
    "                                        ann = ann_2h_unisoftsigbinlosadam7,\n",
    "                                        enc_train_x = enc_train_x_asal,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_2h_unisoftsigbinlosadam7 = plot_hist_auto(hist_ann_2h_unisoftsigbinlosadam7, './Figures/ann_2h_unisoftsigbinlosadam7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_2h_prob_unisoftsigbinlosadam7, pred_ann_2h_01_unisoftsigbinlosadam7 = ann_predict(ann_2h_unisoftsigbinlosadam7,enc_test_x_asal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_2h_01_unisoftsigbinlosadam7, pred_ann_2h_01_unisoftsigbinlosadam7, './Figures/ROC_ann_2h_unisoftsigbinlosadam7_redds10bal.png', './Figures/CM_ann_2h_unisoftsigbinlosadam7_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "train_y_ = to_categorical(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_2h_unisoftsigbinlosadam8 = ann_2h__(neurons=48,\n",
    "                                      encoded_train_x=enc_train_x_asal,\n",
    "                                      activation_input='tanh',\n",
    "#                                       dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='mean_squared_error',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_2h_unisoftsigbinlosadam8 = ann_fit(checkpoint_file = \"ann_2h_unisoftsigbinlosadam8_redds10bal.h5\",\n",
    "                                        ann = ann_2h_unisoftsigbinlosadam8,\n",
    "                                        enc_train_x = enc_train_x_asal,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_2h_unisoftsigbinlosadam8 = plot_hist_auto(hist_ann_2h_unisoftsigbinlosadam8, './Figures/ann_2h_unisoftsigbinlosadam8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_2h_prob_unisoftsigbinlosadam8, pred_ann_2h_01_unisoftsigbinlosadam8 = ann_predict(ann_2h_unisoftsigbinlosadam8,enc_test_x_asal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_2h_01_unisoftsigbinlosadam8, pred_ann_2h_01_unisoftsigbinlosadam8, './Figures/ROC_ann_2h_unisoftsigbinlosadam8_redds10bal.png', './Figures/CM_ann_2h_unisoftsigbinlosadam8_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_24n_unisoftsigbinlosadam = ann_1h_24n(neurons=48,\n",
    "                                      encoded_train_x=train_x,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='softsign',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ann_24n_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"ann_24n_unisoftsigbinlosadam_redds10bal.h5\",\n",
    "                                        ann = ann_24n_unisoftsigbinlosadam,\n",
    "                                        enc_train_x = train_x,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ann_24n_unisoftsigbinlosadam = plot_hist_auto(hist_ann_24n_unisoftsigbinlosadam, './Figures/ann_24_unisoftsigbinlosadam.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ann_24n_prob_unisoftsigbinlosadam, pred_ann_24n_01_unisoftsigbinlosadam = ann_predict(ann_24n_unisoftsigbinlosadam,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ann_24n_01_unisoftsigbinlosadam, pred_ann_24n_01_unisoftsigbinlosadam, './Figures/ROC_ann_24n_unisoftsigbinlosadam_redds10bal.png', './Figures/CM_ann_24n_unisoftsigbinlosadam_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, \n",
    "                             criterion='gini', \n",
    "                             max_depth=16, \n",
    "#                              min_samples_split=2, \n",
    "                             #min_samples_leaf=1, \n",
    "                             max_features=0.3, \n",
    "                             #bootstrap=True,\n",
    "                             oob_score=True,\n",
    "                             random_state=23)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "print(time.ctime(start_time))\n",
    "\n",
    "clf.fit(enc_train_x_aslal, train_y)\n",
    "\n",
    "pred_y_RF = cross_val_predict(estimator=clf,\n",
    "                              X=np.array(enc_test_x_aslal),\n",
    "                              y=test_y,\n",
    "                              cv=KFold(n_splits=10, random_state=23),\n",
    "                              n_jobs=2)\n",
    "\n",
    "elapsed_time = (time.time() - start_time)\n",
    "print(\"--- %s seconds ---\" %elapsed_time)\n",
    "\n",
    "print(sm.classification_report(test_y, pred_y_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_y_RF, pred_y_RF, './Figures/ROC_rf_E100MaxfautoMaxdnoneBootT_redds10bal.png', './Figures/CM_rf_E100MaxfautoMaxdnoneBootT_redds10bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
