{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# TensorFlow wizardry\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Donâ€™t pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.05\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "from keras import optimizers, regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Activation, Dense, Dropout, Input\n",
    "from keras import backend as k\n",
    "\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "#k.tensorflow_backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Import modules------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(23)\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from datetime import datetime \n",
    "import os.path\n",
    "\n",
    "dsnum=50\n",
    "verbose_level=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user/01Code/00Datasets_final/00BalancedDS/FullCloneID50bal_stdscal.csv\n"
     ]
    }
   ],
   "source": [
    "pathds = os.path.abspath('/home/user/01Code/00Datasets_final/00BalancedDS')\n",
    "file_name = \"FullCloneID\"+str(dsnum)+\"bal_stdscal.csv\"\n",
    "full_path = os.path.join(pathds,file_name)\n",
    "print(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2131328, 121)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "neurons=df.shape[1]-1\n",
    "batch_size=df.shape[1]-1\n",
    "print(neurons)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Explaining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1065664\n",
      "Class 1: 1065664\n",
      "Proportion: 1.0 : 1\n"
     ]
    }
   ],
   "source": [
    "#if you don't have an intuitive sense of how imbalanced these two classes are, let's go visual\n",
    "count_classes = pd.value_counts(df['class'], sort = True)\n",
    "print('Class 0:', count_classes[0])\n",
    "print('Class 1:', count_classes[1])\n",
    "print('Proportion:', round(count_classes[0] / count_classes[1], 3), ': 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.xticks(range(2), ['Normal [0]','Malicious [1]'])\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed and percentage of test data\n",
    "RANDOM_SEED = 23 #used to help randomly select the data points\n",
    "TEST_PCT = 0.20 # 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df, test_size=TEST_PCT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ df -> original dataset \n",
    "+ train -> subset of 80% from original dataset \n",
    "+ test_df -> subset of 20% from original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df = train_test_split(train, test_size=TEST_PCT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train -> subset of 80% from original dataset \n",
    "+ train_df -> subset of 80% from train\n",
    "+ dev_df -> subset of 20% from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500630109328917\n",
      "0.4991070721644043\n",
      "0.4986979960869504\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of mal samples in train and test set\n",
    "print(train_df.iloc[:, batch_size].sum()/train_df.shape[0]) \n",
    "print(dev_df.iloc[:, batch_size].sum()/dev_df.shape[0]) \n",
    "print(test_df.iloc[:, batch_size].sum()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.iloc[:, :batch_size] \n",
    "dev_x = dev_df.iloc[:, :batch_size] \n",
    "test_x = test_df.iloc[:, :batch_size] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train_x -> features of train_df **Training subset for AE**\n",
    "+ dev_x -> features of dev_df **Validation subset for AE**\n",
    "+ test_x -> features of test_df **Testing subset for ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final train and test sets\n",
    "train_y = train_df.iloc[:,batch_size]\n",
    "dev_y = dev_df.iloc[:,batch_size]\n",
    "test_y = test_df.iloc[:,batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train_y -> **Labels for supervised training of ANN**\n",
    "+ dev_y -> labels of dev_df  *not used for AE neither ANN*\n",
    "+ test_y -> labels of test_df  **Ground Truth for predictions of supervised ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_x =np.array(train_x)\n",
    "dev_x =np.array(dev_x)\n",
    "test_x = np.array(test_x)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "dev_y = np.array(dev_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "print(train_x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae(factor_enc_dim, enc_activation, dec_activation, \n",
    "                optimizer, loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer #RELU\n",
    "    encoded = Dense(encoding_dim, activation=enc_activation, name='encoded_bottle_neck')(input_data)\n",
    "    ### Define decoding layer #SIMOID\n",
    "    decoded = Dense(train_x.shape[1], activation=dec_activation)(encoded)\n",
    "    ### Create the autoencoder model\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(autoencoder.summary())\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return autoencoder,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spae(factor_enc_dim,dec_activation,enc_activation,\n",
    "         optimizer,loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer\n",
    "    encoded = Dense(encoding_dim, activity_regularizer=regularizers.l1(1e-4), activation=enc_activation, name='encoded_bottle_neck')(input_data)\n",
    "    ### Define decoding layer\n",
    "    decoded = Dense(train_x.shape[1], activation=dec_activation)(encoded)\n",
    "    ### Create the autoencoder model\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(autoencoder.summary())\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return autoencoder,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pca(thr):\n",
    "    #train_x_pca,test_x_pca = to_pca(0.95)\n",
    "    pca = PCA(n_components = thr, svd_solver = 'full')\n",
    "    train_x_ = np.array(train_x)\n",
    "    print(type(train_x_))\n",
    "\n",
    "    test_x_ = np.array(test_x)\n",
    "    print(type(test_x_))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(time.ctime(start_time))\n",
    "\n",
    "    train_x_pca = pca.fit_transform(train_x_)\n",
    "    print(train_x_pca.shape)\n",
    "\n",
    "    test_x_pca = pca.fit_transform(test_x_)\n",
    "    print(test_x_pca.shape)\n",
    "\n",
    "    elapsed_time = (time.time() - start_time)\n",
    "\n",
    "    print(\"--- PCA spent %s seconds ---\" %elapsed_time )\n",
    "    \n",
    "    return  train_x_pca,test_x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ae(checkpoint_file, autoencoder,\n",
    "           epochs, batch_size, shuffle):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    cp = ModelCheckpoint(filepath=checkpoint_file,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=verbose_level)\n",
    "\n",
    "    tb = TensorBoard(log_dir='./logs',\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=True)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))\n",
    "\n",
    "    hist_auto = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    verbose=verbose_level,\n",
    "                    callbacks=[early_stopping, cp, tb],\n",
    "                    validation_data=(dev_x, dev_x))\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "    \n",
    "    return hist_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_auto(hist_auto, fig_file):\n",
    "    best_loss_value = hist_auto.history['loss'][-1]\n",
    "    print('Best loss value:', best_loss_value)\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.figure()\n",
    "    plt.plot(hist_auto.history['loss'])\n",
    "    plt.plot(hist_auto.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.savefig(fig_file)\n",
    "    plt.show()\n",
    "    \n",
    "    return best_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h(neurons,encoded_train_x,init_mode,activation_input,\n",
    "               weight_constraint,dropout_rate,activation_output,\n",
    "               loss,optimizer):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(int(neurons-int(neurons/4)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "\n",
    "    model.add(Dense(int(neurons-int((neurons/4)*2)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h_():\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=input_dim,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(int(neurons-int(neurons/4)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "\n",
    "    model.add(Dense(int(neurons-int((neurons/4)*2)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_fit(checkpoint_file,ann,enc_train_x,train_y,epochs,shuffle,batch_size):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    cp = ModelCheckpoint(filepath=checkpoint_file,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=verbose_level)\n",
    "\n",
    "    tb = TensorBoard(log_dir='./logs',\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=True)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))\n",
    "\n",
    "    history = ann.fit(enc_train_x,\n",
    "                      train_y,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[early_stopping, cp, tb],\n",
    "                      epochs=epochs,\n",
    "                      shuffle=shuffle,\n",
    "                      batch_size=batch_size,\n",
    "                      verbose=verbose_level)\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict(ann,enc_test_x):\n",
    "    pred_ann_prob = ann.predict(enc_test_x)\n",
    "    pred_ann_prob.shape\n",
    "    pred_ann_prob = pred_ann_prob[:,0]\n",
    "    pred_ann_01 = np.where(pred_ann_prob > 0.5, 1, 0)\n",
    "    \n",
    "    #Print accuracy\n",
    "    acc_ann = accuracy_score(test_y, pred_ann_01)\n",
    "    print('Overall accuracy of Neural Network model:', acc_ann)\n",
    "\n",
    "    classiBM = \"NN\"\n",
    "    preBM = (sm.precision_score(test_y, pred_ann_01)*100) \n",
    "    recallBM = (sm.recall_score(test_y, pred_ann_01)*100) \n",
    "    f1scoreBM = (sm.f1_score(test_y, pred_ann_01)*100)\n",
    "    print(sm.classification_report(test_y, pred_ann_01,digits=4))\n",
    "    \n",
    "    return pred_ann_prob, pred_ann_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict_():\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))  \n",
    "\n",
    "    modelk = KerasClassifier(build_fn=ann_2h_,\n",
    "                             epochs=epochs, \n",
    "                             batch_size=batch_size, \n",
    "                             verbose=verbose_level\n",
    "                            )\n",
    "\n",
    "    pred_ann_prob = cross_val_predict(modelk,\n",
    "                                      enc_test_x,\n",
    "                                      test_y,\n",
    "                                      cv=KFold(n_splits=5, random_state=23),\n",
    "                                      verbose=1)\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "    pred_ann_prob.shape\n",
    "    pred_ann_prob = pred_ann_prob[:,0]\n",
    "    pred_ann_01 = np.where(pred_ann_prob > 0.5, 1, 0)\n",
    "\n",
    "    #Print accuracy\n",
    "    acc_ann = accuracy_score(test_y, pred_ann_01)\n",
    "    print('Overall accuracy of Neural Network model:', acc_ann)\n",
    "\n",
    "    classiBM = \"NN\"\n",
    "    preBM = (sm.precision_score(test_y, pred_ann_01)*100) \n",
    "    recallBM = (sm.recall_score(test_y, pred_ann_01)*100) \n",
    "    f1scoreBM = (sm.f1_score(test_y, pred_ann_01)*100)\n",
    "    print(sm.classification_report(test_y, pred_ann_01,digits=4))\n",
    "    \n",
    "    return pred_ann_prob,pred_ann_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_cm(pred_ann_prob, pred_ann_01, roc_file, cm_file):\n",
    "    false_positive_rate, recall, thresholds = roc_curve(test_y, pred_ann_prob)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    plt.figure()\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Fall-out (1-Specificity)')\n",
    "    plt.savefig(roc_file)\n",
    "    plt.show()\n",
    "    \n",
    "    cm = confusion_matrix(test_y, pred_ann_01)\n",
    "    labels = ['Normal', 'Malicious']\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm,xticklabels=labels, yticklabels=labels, annot=True, fmt='d', cmap=\"RdYlGn\", vmin = 0.2);\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.savefig(cm_file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- PCA Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_pca,test_x_pca = to_pca(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- AE Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/user/anaconda3/envs/deepl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "encoded_bottle_neck (Dense)  (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               9720      \n",
      "=================================================================\n",
      "Total params: 19,400\n",
      "Trainable params: 19,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ae_sigmoid_adam_mse,enc_train_x_asam,enc_test_x_asam = ae(factor_enc_dim = 1.5,\n",
    "                                                          enc_activation = 'relu',\n",
    "                                                          dec_activation = 'sigmoid',\n",
    "                                                          optimizer='Adam',\n",
    "                                                          loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_sigmoid_adam_mse = load_model('ae_sigmoid_adam_mse_redds10bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  3 17:48:24 2019\n",
      "WARNING:tensorflow:From /home/user/anaconda3/envs/deepl/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1364049 samples, validate on 341013 samples\n",
      "Epoch 1/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0895 - acc: 0.2180 - val_loss: 0.0870 - val_acc: 0.1470\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08698, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 2/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0976 - val_loss: 0.0870 - val_acc: 0.0727\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08698 to 0.08697, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 3/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0686 - val_loss: 0.0870 - val_acc: 0.0630\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.08697 to 0.08697, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 4/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0602 - val_loss: 0.0870 - val_acc: 0.0565\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08697 to 0.08697, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 5/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0489 - val_loss: 0.0870 - val_acc: 0.0241\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08697 to 0.08697, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 6/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0290 - val_loss: 0.0870 - val_acc: 0.0284\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.08697 to 0.08697, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 7/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0485 - val_loss: 0.0870 - val_acc: 0.0518\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08697 to 0.08697, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 8/200\n",
      "1364049/1364049 [==============================] - 25s 18us/step - loss: 0.0861 - acc: 0.0549 - val_loss: 0.0870 - val_acc: 0.0425\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08697 to 0.08696, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 9/200\n",
      "1364049/1364049 [==============================] - 25s 19us/step - loss: 0.0861 - acc: 0.0413 - val_loss: 0.0870 - val_acc: 0.0357\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.08696 to 0.08696, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 10/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0384 - val_loss: 0.0870 - val_acc: 0.0399\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08696 to 0.08696, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 11/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0360 - val_loss: 0.0870 - val_acc: 0.0349\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08696 to 0.08696, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 12/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0360 - val_loss: 0.0870 - val_acc: 0.0300\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08696 to 0.08696, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 13/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0320 - val_loss: 0.0870 - val_acc: 0.0338\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08696 to 0.08696, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 14/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0357 - val_loss: 0.0870 - val_acc: 0.0372\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.08696 to 0.08696, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 15/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0406 - val_loss: 0.0870 - val_acc: 0.0511\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.08696 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 16/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0438 - val_loss: 0.0870 - val_acc: 0.0428\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 17/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0518 - val_loss: 0.0870 - val_acc: 0.0426\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 18/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0685 - val_loss: 0.0870 - val_acc: 0.0519\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 19/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0424 - val_loss: 0.0870 - val_acc: 0.0420\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.08695\n",
      "Epoch 20/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0419 - val_loss: 0.0870 - val_acc: 0.0252\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 21/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0414 - val_loss: 0.0870 - val_acc: 0.0411\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 22/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0462 - val_loss: 0.0870 - val_acc: 0.0415\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 23/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0459 - val_loss: 0.0869 - val_acc: 0.0498\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 24/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0610 - val_loss: 0.0870 - val_acc: 0.0578\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08695\n",
      "Epoch 25/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0555 - val_loss: 0.0869 - val_acc: 0.0437\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08695\n",
      "Epoch 26/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0518 - val_loss: 0.0869 - val_acc: 0.0531\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 27/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0662 - val_loss: 0.0869 - val_acc: 0.0643\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 28/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0660 - val_loss: 0.0869 - val_acc: 0.0626\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 29/200\n",
      "1364049/1364049 [==============================] - 25s 18us/step - loss: 0.0861 - acc: 0.0623 - val_loss: 0.0869 - val_acc: 0.0701\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 30/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0722 - val_loss: 0.0869 - val_acc: 0.0667\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.08695\n",
      "Epoch 31/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0616 - val_loss: 0.0869 - val_acc: 0.0650\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 32/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0682 - val_loss: 0.0869 - val_acc: 0.0737\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 33/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0764 - val_loss: 0.0869 - val_acc: 0.0729\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 34/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0760 - val_loss: 0.0869 - val_acc: 0.0820\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.08695 to 0.08695, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 35/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0732 - val_loss: 0.0869 - val_acc: 0.0799\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.08695 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 36/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0801 - val_loss: 0.0869 - val_acc: 0.0800\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 37/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0714 - val_loss: 0.0869 - val_acc: 0.0823\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 38/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0879 - val_loss: 0.0869 - val_acc: 0.0877\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 39/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0644 - val_loss: 0.0869 - val_acc: 0.0626\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.08694\n",
      "Epoch 40/200\n",
      "1364049/1364049 [==============================] - 24s 18us/step - loss: 0.0861 - acc: 0.0780 - val_loss: 0.0869 - val_acc: 0.0860\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 41/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0811 - val_loss: 0.0869 - val_acc: 0.0797\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.08694\n",
      "Epoch 42/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.1102 - val_loss: 0.0869 - val_acc: 0.0870\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.08694\n",
      "Epoch 43/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0984 - val_loss: 0.0869 - val_acc: 0.0939\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 44/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0918 - val_loss: 0.0869 - val_acc: 0.0853\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 45/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0887 - val_loss: 0.0869 - val_acc: 0.0863\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 46/200\n",
      "1364049/1364049 [==============================] - 24s 17us/step - loss: 0.0861 - acc: 0.0921 - val_loss: 0.0869 - val_acc: 0.0876\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 47/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.0901 - val_loss: 0.0869 - val_acc: 0.0853\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 48/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.1401 - val_loss: 0.0869 - val_acc: 0.1474\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.08694\n",
      "Epoch 49/200\n",
      "1364049/1364049 [==============================] - 23s 17us/step - loss: 0.0861 - acc: 0.1245 - val_loss: 0.0869 - val_acc: 0.1047\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.08694\n",
      "Epoch 50/200\n",
      "1364049/1364049 [==============================] - 22s 16us/step - loss: 0.0861 - acc: 0.1222 - val_loss: 0.0869 - val_acc: 0.1123\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 51/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1156 - val_loss: 0.0869 - val_acc: 0.1044\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.08694\n",
      "Epoch 52/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1004 - val_loss: 0.0869 - val_acc: 0.0887\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 53/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1088 - val_loss: 0.0869 - val_acc: 0.1028\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 54/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1040 - val_loss: 0.0869 - val_acc: 0.1035\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 55/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1080 - val_loss: 0.0869 - val_acc: 0.1063\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 56/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0907 - val_loss: 0.0869 - val_acc: 0.0821\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 57/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0972 - val_loss: 0.0869 - val_acc: 0.0983\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.08694\n",
      "Epoch 58/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1094 - val_loss: 0.0869 - val_acc: 0.1085\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 59/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1025 - val_loss: 0.0869 - val_acc: 0.1109\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.08694\n",
      "Epoch 60/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0981 - val_loss: 0.0869 - val_acc: 0.1002\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 61/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0999 - val_loss: 0.0869 - val_acc: 0.1085\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.08694\n",
      "Epoch 62/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1031 - val_loss: 0.0869 - val_acc: 0.1048\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 63/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0954 - val_loss: 0.0869 - val_acc: 0.0910\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.08694 to 0.08694, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 64/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0882 - val_loss: 0.0869 - val_acc: 0.0827\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.08694\n",
      "Epoch 65/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0822 - val_loss: 0.0869 - val_acc: 0.0753\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.08694\n",
      "Epoch 66/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1027 - val_loss: 0.0869 - val_acc: 0.0947\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.08694\n",
      "Epoch 67/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1168 - val_loss: 0.0869 - val_acc: 0.1123\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.08694\n",
      "Epoch 68/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.1022 - val_loss: 0.0869 - val_acc: 0.0959\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.08694 to 0.08693, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 69/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0762 - val_loss: 0.0869 - val_acc: 0.0857\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.08693\n",
      "Epoch 70/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0836 - val_loss: 0.0869 - val_acc: 0.0913\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.08693\n",
      "Epoch 71/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0823 - val_loss: 0.0869 - val_acc: 0.0816\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.08693 to 0.08693, saving model to ./H5files/ae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 72/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0766 - val_loss: 0.0869 - val_acc: 0.0679\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.08693\n",
      "Epoch 73/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0815 - val_loss: 0.0869 - val_acc: 0.0871\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.08693\n",
      "Epoch 74/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0702 - val_loss: 0.0869 - val_acc: 0.0803\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.08693\n",
      "Epoch 75/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0580 - val_loss: 0.0869 - val_acc: 0.0661\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.08693\n",
      "Epoch 76/200\n",
      "1364049/1364049 [==============================] - 19s 14us/step - loss: 0.0861 - acc: 0.0798 - val_loss: 0.0869 - val_acc: 0.0858\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.08693\n",
      "Time elapsed (hh:mm:ss.ms) 0:27:57.724717\n"
     ]
    }
   ],
   "source": [
    "hist_ae_sigmoid_adam_mse = fit_ae(checkpoint_file = \"./H5files/ae_sigmoid_adam_mse_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                  autoencoder = ae_sigmoid_adam_mse, \n",
    "                                  epochs = 200, \n",
    "                                  batch_size = batch_size,\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss value: 0.08610323263165316\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_loss_value_ae_sigmoid_adam_mse  = plot_hist_auto(hist_ae_sigmoid_adam_mse, './Figures/hist_ae_sigmoid_adam_mse.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- SPAE Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "encoded_bottle_neck (Dense)  (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               9720      \n",
      "=================================================================\n",
      "Total params: 19,400\n",
      "Trainable params: 19,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "spae_sigmoid_adam_mse,enc_train_x_spsam,enc_test_x_spsam = spae(factor_enc_dim = 1.5,\n",
    "                                                          enc_activation = 'relu',\n",
    "                                                          dec_activation = 'sigmoid',\n",
    "                                                          optimizer='Adam',\n",
    "                                                          loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spae_sigmoid_adam_mse = load_model('spae_sigmoid_adam_mse_redds20bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  3 18:16:39 2019\n",
      "Train on 1364049 samples, validate on 341013 samples\n",
      "Epoch 1/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1439 - acc: 0.0157 - val_loss: 0.1270 - val_acc: 0.0253\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12697, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 2/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1229 - acc: 0.0257 - val_loss: 0.1216 - val_acc: 0.0262\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12697 to 0.12160, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 3/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1197 - acc: 0.0268 - val_loss: 0.1197 - val_acc: 0.0320\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.12160 to 0.11971, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 4/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1183 - acc: 0.0404 - val_loss: 0.1187 - val_acc: 0.0530\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.11971 to 0.11869, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 5/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1175 - acc: 0.0601 - val_loss: 0.1180 - val_acc: 0.0658\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.11869 to 0.11798, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 6/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1169 - acc: 0.0793 - val_loss: 0.1175 - val_acc: 0.0877\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.11798 to 0.11754, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 7/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1165 - acc: 0.1033 - val_loss: 0.1172 - val_acc: 0.1211\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.11754 to 0.11719, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 8/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1161 - acc: 0.1130 - val_loss: 0.1167 - val_acc: 0.1177\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11719 to 0.11675, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 9/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1157 - acc: 0.1244 - val_loss: 0.1165 - val_acc: 0.1329\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11675 to 0.11650, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 10/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1154 - acc: 0.1385 - val_loss: 0.1162 - val_acc: 0.1450\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.11650 to 0.11621, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 11/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1152 - acc: 0.1473 - val_loss: 0.1160 - val_acc: 0.1502\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.11621 to 0.11601, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 12/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1150 - acc: 0.1549 - val_loss: 0.1158 - val_acc: 0.1589\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.11601 to 0.11583, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 13/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1148 - acc: 0.1614 - val_loss: 0.1157 - val_acc: 0.1644\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.11583 to 0.11567, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 14/200\n",
      "1364049/1364049 [==============================] - 22s 16us/step - loss: 0.1147 - acc: 0.1678 - val_loss: 0.1155 - val_acc: 0.1736\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.11567 to 0.11554, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 15/200\n",
      "1364049/1364049 [==============================] - 21s 16us/step - loss: 0.1146 - acc: 0.1739 - val_loss: 0.1154 - val_acc: 0.1777\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.11554 to 0.11541, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 16/200\n",
      "1364049/1364049 [==============================] - 22s 16us/step - loss: 0.1145 - acc: 0.1816 - val_loss: 0.1153 - val_acc: 0.1874\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.11541 to 0.11533, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 17/200\n",
      "1364049/1364049 [==============================] - 21s 16us/step - loss: 0.1144 - acc: 0.1877 - val_loss: 0.1152 - val_acc: 0.2029\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.11533 to 0.11523, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 18/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1143 - acc: 0.1917 - val_loss: 0.1151 - val_acc: 0.1906\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.11523 to 0.11514, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 19/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1142 - acc: 0.1951 - val_loss: 0.1150 - val_acc: 0.1954\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.11514 to 0.11505, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 20/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1142 - acc: 0.1967 - val_loss: 0.1150 - val_acc: 0.1927\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.11505 to 0.11496, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 21/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1141 - acc: 0.1960 - val_loss: 0.1149 - val_acc: 0.1862\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.11496 to 0.11486, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 22/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1140 - acc: 0.1978 - val_loss: 0.1148 - val_acc: 0.1923\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.11486 to 0.11479, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 23/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1140 - acc: 0.1976 - val_loss: 0.1148 - val_acc: 0.2077\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.11479\n",
      "Epoch 24/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1139 - acc: 0.1986 - val_loss: 0.1147 - val_acc: 0.1939\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.11479 to 0.11470, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 25/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1139 - acc: 0.1987 - val_loss: 0.1146 - val_acc: 0.1942\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.11470 to 0.11464, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 26/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1138 - acc: 0.1980 - val_loss: 0.1146 - val_acc: 0.1911\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.11464 to 0.11463, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 27/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1137 - acc: 0.1978 - val_loss: 0.1146 - val_acc: 0.1914\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.11463 to 0.11457, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 28/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1137 - acc: 0.1993 - val_loss: 0.1145 - val_acc: 0.1933\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.11457 to 0.11447, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 29/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1134 - acc: 0.1913 - val_loss: 0.1139 - val_acc: 0.1766\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.11447 to 0.11389, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 30/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1128 - acc: 0.1839 - val_loss: 0.1135 - val_acc: 0.1801\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.11389 to 0.11351, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 31/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1126 - acc: 0.1895 - val_loss: 0.1133 - val_acc: 0.1936\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.11351 to 0.11334, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 32/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1124 - acc: 0.1936 - val_loss: 0.1132 - val_acc: 0.1936\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.11334 to 0.11318, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 33/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1123 - acc: 0.1970 - val_loss: 0.1131 - val_acc: 0.1916\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.11318 to 0.11311, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 34/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 0.1122 - acc: 0.1998 - val_loss: 0.1130 - val_acc: 0.2014\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.11311 to 0.11299, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 35/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1122 - acc: 0.2039 - val_loss: 0.1129 - val_acc: 0.2040\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.11299 to 0.11287, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 36/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1121 - acc: 0.2052 - val_loss: 0.1128 - val_acc: 0.2043\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.11287 to 0.11285, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 37/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1121 - acc: 0.2076 - val_loss: 0.1128 - val_acc: 0.2073\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.11285 to 0.11282, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 38/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1120 - acc: 0.2096 - val_loss: 0.1127 - val_acc: 0.2080\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.11282 to 0.11275, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 39/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1120 - acc: 0.2117 - val_loss: 0.1128 - val_acc: 0.2095\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.11275\n",
      "Epoch 40/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1120 - acc: 0.2131 - val_loss: 0.1128 - val_acc: 0.2134\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.11275\n",
      "Epoch 41/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1119 - acc: 0.2143 - val_loss: 0.1128 - val_acc: 0.2100\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.11275\n",
      "Epoch 42/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1119 - acc: 0.2171 - val_loss: 0.1127 - val_acc: 0.2094\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.11275 to 0.11265, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 43/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1118 - acc: 0.2205 - val_loss: 0.1126 - val_acc: 0.2205\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.11265 to 0.11256, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 44/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1118 - acc: 0.2229 - val_loss: 0.1126 - val_acc: 0.2256\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.11256\n",
      "Epoch 45/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1118 - acc: 0.2254 - val_loss: 0.1126 - val_acc: 0.2143\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.11256 to 0.11256, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 46/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1117 - acc: 0.2270 - val_loss: 0.1125 - val_acc: 0.2299\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.11256 to 0.11251, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 47/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1117 - acc: 0.2286 - val_loss: 0.1125 - val_acc: 0.2285\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.11251 to 0.11246, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 48/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1117 - acc: 0.2300 - val_loss: 0.1124 - val_acc: 0.2306\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11246 to 0.11241, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 49/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1116 - acc: 0.2314 - val_loss: 0.1125 - val_acc: 0.2196\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.11241\n",
      "Epoch 50/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1116 - acc: 0.2321 - val_loss: 0.1123 - val_acc: 0.2346\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11241 to 0.11231, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 51/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1116 - acc: 0.2336 - val_loss: 0.1124 - val_acc: 0.2349\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.11231\n",
      "Epoch 52/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1116 - acc: 0.2340 - val_loss: 0.1123 - val_acc: 0.2378\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.11231 to 0.11230, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 53/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1116 - acc: 0.2357 - val_loss: 0.1124 - val_acc: 0.2375\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.11230\n",
      "Epoch 54/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1116 - acc: 0.2363 - val_loss: 0.1124 - val_acc: 0.2258\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.11230\n",
      "Epoch 55/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1115 - acc: 0.2369 - val_loss: 0.1123 - val_acc: 0.2369\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.11230 to 0.11226, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 56/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1115 - acc: 0.2384 - val_loss: 0.1123 - val_acc: 0.2400\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.11226\n",
      "Epoch 57/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1115 - acc: 0.2397 - val_loss: 0.1122 - val_acc: 0.2423\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.11226 to 0.11223, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 58/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1115 - acc: 0.2406 - val_loss: 0.1124 - val_acc: 0.2233\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.11223\n",
      "Epoch 59/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1115 - acc: 0.2413 - val_loss: 0.1123 - val_acc: 0.2419\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.11223\n",
      "Epoch 60/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1115 - acc: 0.2429 - val_loss: 0.1123 - val_acc: 0.2425\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.11223\n",
      "Epoch 61/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1115 - acc: 0.2427 - val_loss: 0.1122 - val_acc: 0.2397\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.11223 to 0.11222, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 62/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1115 - acc: 0.2447 - val_loss: 0.1122 - val_acc: 0.2459\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.11222 to 0.11220, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 63/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1114 - acc: 0.2445 - val_loss: 0.1121 - val_acc: 0.2442\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.11220 to 0.11207, saving model to ./H5files/spae_sigmoid_adam_mse_redds50bal.h5\n",
      "Epoch 64/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1114 - acc: 0.2458 - val_loss: 0.1123 - val_acc: 0.2343\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.11207\n",
      "Epoch 65/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1114 - acc: 0.2462 - val_loss: 0.1122 - val_acc: 0.2333\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.11207\n",
      "Epoch 66/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1114 - acc: 0.2457 - val_loss: 0.1121 - val_acc: 0.2471\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.11207\n",
      "Epoch 67/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1114 - acc: 0.2455 - val_loss: 0.1122 - val_acc: 0.2449\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.11207\n",
      "Epoch 68/200\n",
      "1364049/1364049 [==============================] - 20s 15us/step - loss: 0.1114 - acc: 0.2461 - val_loss: 0.1122 - val_acc: 0.2466\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.11207\n",
      "Time elapsed (hh:mm:ss.ms) 0:23:09.422871\n"
     ]
    }
   ],
   "source": [
    "hist_spae_sigmoid_adam_mse = fit_ae(checkpoint_file = \"./H5files/spae_sigmoid_adam_mse_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                  autoencoder = spae_sigmoid_adam_mse, \n",
    "                                  epochs = 200, \n",
    "                                  batch_size = batch_size,\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss value: 0.11135185435714676\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_loss_value_spae_sigmoid_adam_mse  = plot_hist_auto(hist_spae_sigmoid_adam_mse, './Figures/hist_spae_sigmoid_adam_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valueDict = {\n",
    "    'loss_value_ae_sigmoid_adam_mse': best_loss_value_ae_sigmoid_adam_mse,\n",
    "    'loss_value_spae_sigmoid_adam_mse': best_loss_value_spae_sigmoid_adam_mse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss_value_ae_sigmoid_adam_mse': 0.08610323263165316,\n",
       " 'loss_value_spae_sigmoid_adam_mse': 0.11135185435714676}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1364049, 80)\n",
      "(426266, 80)\n",
      "(1364049, 80)\n",
      "(426266, 80)\n"
     ]
    }
   ],
   "source": [
    "print(enc_train_x_asam.shape)\n",
    "print(enc_test_x_asam.shape)\n",
    "\n",
    "print(enc_train_x_spsam.shape)\n",
    "print(enc_test_x_spsam.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with ae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ae_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=enc_train_x_asam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  3 18:39:48 2019\n",
      "Train on 1091239 samples, validate on 272810 samples\n",
      "Epoch 1/200\n",
      "1091239/1091239 [==============================] - 29s 26us/step - loss: 0.1921 - acc: 0.9109 - val_loss: 0.0850 - val_acc: 0.9606\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08499, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 2/200\n",
      "1091239/1091239 [==============================] - 28s 26us/step - loss: 0.0837 - acc: 0.9607 - val_loss: 0.0672 - val_acc: 0.9672\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08499 to 0.06717, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 3/200\n",
      "1091239/1091239 [==============================] - 28s 26us/step - loss: 0.0673 - acc: 0.9682 - val_loss: 0.0502 - val_acc: 0.9767\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06717 to 0.05016, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 4/200\n",
      "1091239/1091239 [==============================] - 28s 26us/step - loss: 0.0574 - acc: 0.9732 - val_loss: 0.0459 - val_acc: 0.9789\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05016 to 0.04593, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 5/200\n",
      "1091239/1091239 [==============================] - 28s 26us/step - loss: 0.0508 - acc: 0.9764 - val_loss: 0.0432 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04593 to 0.04316, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 6/200\n",
      "1091239/1091239 [==============================] - 28s 25us/step - loss: 0.0466 - acc: 0.9784 - val_loss: 0.0456 - val_acc: 0.9798\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04316\n",
      "Epoch 7/200\n",
      "1091239/1091239 [==============================] - 28s 26us/step - loss: 0.0426 - acc: 0.9803 - val_loss: 0.0464 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.04316\n",
      "Epoch 8/200\n",
      "1091239/1091239 [==============================] - 28s 26us/step - loss: 0.0398 - acc: 0.9818 - val_loss: 0.0359 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04316 to 0.03593, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 9/200\n",
      "1091239/1091239 [==============================] - 29s 26us/step - loss: 0.0372 - acc: 0.9829 - val_loss: 0.0376 - val_acc: 0.9840\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03593\n",
      "Epoch 10/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0350 - acc: 0.9841 - val_loss: 0.0329 - val_acc: 0.9856\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03593 to 0.03290, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 11/200\n",
      "1091239/1091239 [==============================] - 31s 28us/step - loss: 0.0331 - acc: 0.9849 - val_loss: 0.0291 - val_acc: 0.9873\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03290 to 0.02912, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 12/200\n",
      "1091239/1091239 [==============================] - 30s 28us/step - loss: 0.0318 - acc: 0.9856 - val_loss: 0.0288 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02912 to 0.02878, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 13/200\n",
      "1091239/1091239 [==============================] - 30s 28us/step - loss: 0.0301 - acc: 0.9864 - val_loss: 0.0288 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02878 to 0.02876, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 14/200\n",
      "1091239/1091239 [==============================] - 30s 27us/step - loss: 0.0289 - acc: 0.9869 - val_loss: 0.0245 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02876 to 0.02451, saving model to ./H5files/ae_ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 15/200\n",
      "1091239/1091239 [==============================] - 30s 27us/step - loss: 0.0282 - acc: 0.9873 - val_loss: 0.0249 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.02451\n",
      "Epoch 16/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0268 - acc: 0.9877 - val_loss: 0.0253 - val_acc: 0.9891\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.02451\n",
      "Epoch 17/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0260 - acc: 0.9883 - val_loss: 0.0259 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02451\n",
      "Epoch 18/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0251 - acc: 0.9889 - val_loss: 0.0295 - val_acc: 0.9875\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02451\n",
      "Epoch 19/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0244 - acc: 0.9892 - val_loss: 0.0260 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.02451\n",
      "Time elapsed (hh:mm:ss.ms) 0:09:12.219695\n"
     ]
    }
   ],
   "source": [
    "hist_ae_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ae_ann_2h_unisoftsigbinlosadam_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                        ann = ae_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = enc_train_x_asam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ae_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_ae_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_ae_ann_2h_unisoftsigbinlosadam, './Figures/ae_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_ae_ann_2h_prob_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam = ann_predict(ae_ann_2h_unisoftsigbinlosadam,enc_test_x_asam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_ae_ann_2h_01_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_ae_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_ae_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=enc_train_x_asam\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=enc_test_x_asam\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  3 18:49:01 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341012/341012 [==============================] - 10s 30us/step - loss: 0.3318 - acc: 0.8397\n",
      "Epoch 2/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.1412 - acc: 0.9394\n",
      "Epoch 3/100\n",
      "341012/341012 [==============================] - 10s 29us/step - loss: 0.1108 - acc: 0.9506\n",
      "Epoch 4/100\n",
      "341012/341012 [==============================] - 10s 29us/step - loss: 0.0956 - acc: 0.9567\n",
      "Epoch 5/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0851 - acc: 0.9605\n",
      "Epoch 6/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0787 - acc: 0.9635\n",
      "Epoch 7/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0735 - acc: 0.9659\n",
      "Epoch 8/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0689 - acc: 0.9681\n",
      "Epoch 9/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0650 - acc: 0.9696\n",
      "Epoch 10/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0622 - acc: 0.9708\n",
      "Epoch 11/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0596 - acc: 0.9726\n",
      "Epoch 12/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0564 - acc: 0.9738\n",
      "Epoch 13/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0553 - acc: 0.9744\n",
      "Epoch 14/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0529 - acc: 0.9755\n",
      "Epoch 15/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0508 - acc: 0.9763\n",
      "Epoch 16/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0491 - acc: 0.9773\n",
      "Epoch 17/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0481 - acc: 0.9778\n",
      "Epoch 18/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0469 - acc: 0.9782\n",
      "Epoch 19/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0452 - acc: 0.9793\n",
      "Epoch 20/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0446 - acc: 0.9793\n",
      "Epoch 21/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0433 - acc: 0.9803\n",
      "Epoch 22/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0422 - acc: 0.9808\n",
      "Epoch 23/100\n",
      "341012/341012 [==============================] - 9s 28us/step - loss: 0.0413 - acc: 0.9812\n",
      "Epoch 24/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0403 - acc: 0.9816\n",
      "Epoch 25/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0397 - acc: 0.9818\n",
      "Epoch 26/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0383 - acc: 0.9826\n",
      "Epoch 27/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0371 - acc: 0.9832\n",
      "Epoch 28/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0368 - acc: 0.9833\n",
      "Epoch 29/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0367 - acc: 0.9831\n",
      "Epoch 30/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0351 - acc: 0.9841\n",
      "Epoch 31/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0348 - acc: 0.9843\n",
      "Epoch 32/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.0346 - acc: 0.9846\n",
      "Epoch 33/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0333 - acc: 0.9849\n",
      "Epoch 34/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0328 - acc: 0.9852\n",
      "Epoch 35/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0329 - acc: 0.9852\n",
      "Epoch 36/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0319 - acc: 0.9857\n",
      "Epoch 37/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0317 - acc: 0.9860\n",
      "Epoch 38/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0311 - acc: 0.9861\n",
      "Epoch 39/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0301 - acc: 0.9866\n",
      "Epoch 40/100\n",
      "341012/341012 [==============================] - 9s 26us/step - loss: 0.0299 - acc: 0.9867\n",
      "Epoch 41/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0294 - acc: 0.9869\n",
      "Epoch 42/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0286 - acc: 0.9875\n",
      "Epoch 43/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0292 - acc: 0.9870\n",
      "Epoch 44/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0276 - acc: 0.9876\n",
      "Epoch 45/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0277 - acc: 0.9877\n",
      "Epoch 46/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0277 - acc: 0.9878\n",
      "Epoch 47/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0272 - acc: 0.9880\n",
      "Epoch 48/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0274 - acc: 0.9879\n",
      "Epoch 49/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0266 - acc: 0.9883\n",
      "Epoch 50/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0270 - acc: 0.9882\n",
      "Epoch 51/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0261 - acc: 0.9885\n",
      "Epoch 52/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0255 - acc: 0.9890\n",
      "Epoch 53/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0254 - acc: 0.9891\n",
      "Epoch 54/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0251 - acc: 0.9891\n",
      "Epoch 55/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0249 - acc: 0.9889\n",
      "Epoch 56/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0251 - acc: 0.9891\n",
      "Epoch 57/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0244 - acc: 0.9893\n",
      "Epoch 58/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0239 - acc: 0.9895\n",
      "Epoch 59/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0242 - acc: 0.9895\n",
      "Epoch 60/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0235 - acc: 0.9898\n",
      "Epoch 61/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0235 - acc: 0.9898\n",
      "Epoch 62/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0238 - acc: 0.9897\n",
      "Epoch 63/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0230 - acc: 0.9901\n",
      "Epoch 64/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0228 - acc: 0.9901\n",
      "Epoch 65/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0227 - acc: 0.9902\n",
      "Epoch 66/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0224 - acc: 0.9905\n",
      "Epoch 67/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0222 - acc: 0.9904\n",
      "Epoch 68/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0222 - acc: 0.9904\n",
      "Epoch 69/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0217 - acc: 0.9907\n",
      "Epoch 70/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0219 - acc: 0.9906\n",
      "Epoch 71/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0213 - acc: 0.9908\n",
      "Epoch 72/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0219 - acc: 0.9908\n",
      "Epoch 73/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0216 - acc: 0.9908\n",
      "Epoch 74/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0214 - acc: 0.9910\n",
      "Epoch 75/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0207 - acc: 0.9910\n",
      "Epoch 76/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0208 - acc: 0.9912\n",
      "Epoch 77/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0212 - acc: 0.9910\n",
      "Epoch 78/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0209 - acc: 0.9911\n",
      "Epoch 79/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0212 - acc: 0.9908\n",
      "Epoch 80/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0205 - acc: 0.9910\n",
      "Epoch 81/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0209 - acc: 0.9910\n",
      "Epoch 82/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0202 - acc: 0.9912\n",
      "Epoch 83/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0200 - acc: 0.9914\n",
      "Epoch 84/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0199 - acc: 0.9917\n",
      "Epoch 85/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0204 - acc: 0.9914\n",
      "Epoch 86/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0203 - acc: 0.9915\n",
      "Epoch 87/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0197 - acc: 0.9916\n",
      "Epoch 88/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0193 - acc: 0.9916\n",
      "Epoch 89/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0196 - acc: 0.9916\n",
      "Epoch 90/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0197 - acc: 0.9919\n",
      "Epoch 91/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0197 - acc: 0.9916\n",
      "Epoch 92/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0193 - acc: 0.9918\n",
      "Epoch 93/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0198 - acc: 0.9916\n",
      "Epoch 94/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0188 - acc: 0.9921\n",
      "Epoch 95/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0193 - acc: 0.9918\n",
      "Epoch 96/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0190 - acc: 0.9919\n",
      "Epoch 97/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0189 - acc: 0.9920\n",
      "Epoch 98/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0186 - acc: 0.9922\n",
      "Epoch 99/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0191 - acc: 0.9919\n",
      "Epoch 100/100\n",
      "341012/341012 [==============================] - 8s 24us/step - loss: 0.0190 - acc: 0.9920\n",
      "85254/85254 [==============================] - 0s 5us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.3364 - acc: 0.8394\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.1410 - acc: 0.9381\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.1092 - acc: 0.9511\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0942 - acc: 0.9571\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0845 - acc: 0.9614\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0773 - acc: 0.9647\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0727 - acc: 0.9665\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0679 - acc: 0.9688\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0651 - acc: 0.9699\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0614 - acc: 0.9716\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0587 - acc: 0.9729\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0559 - acc: 0.9743\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0540 - acc: 0.9750\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0515 - acc: 0.9761\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0502 - acc: 0.9765\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0478 - acc: 0.9778\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0472 - acc: 0.9783\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0456 - acc: 0.9788\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0442 - acc: 0.9797\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0437 - acc: 0.9797\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0420 - acc: 0.9805\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0409 - acc: 0.9811\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0407 - acc: 0.9815\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0388 - acc: 0.9824\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0381 - acc: 0.9826\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0379 - acc: 0.9826\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0369 - acc: 0.9832\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0360 - acc: 0.9835\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0347 - acc: 0.9841\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0342 - acc: 0.9845\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0336 - acc: 0.9847\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0330 - acc: 0.9853\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0326 - acc: 0.9852\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0313 - acc: 0.9861\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0309 - acc: 0.9858\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0310 - acc: 0.9862\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0304 - acc: 0.9864\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0295 - acc: 0.9868\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0292 - acc: 0.9871\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0281 - acc: 0.9873\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0291 - acc: 0.9872\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0279 - acc: 0.9875\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0272 - acc: 0.9877\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0271 - acc: 0.9880\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0263 - acc: 0.9882\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0263 - acc: 0.9884\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0259 - acc: 0.9885\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0256 - acc: 0.9886\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0252 - acc: 0.9890\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0253 - acc: 0.9889\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0243 - acc: 0.9892\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0241 - acc: 0.9894\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0241 - acc: 0.9893\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0238 - acc: 0.9897\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0237 - acc: 0.9896\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0234 - acc: 0.9895\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0230 - acc: 0.9897\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0222 - acc: 0.9901\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0225 - acc: 0.9902\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0219 - acc: 0.9903\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0216 - acc: 0.9906\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0221 - acc: 0.9903\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0217 - acc: 0.9906\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0212 - acc: 0.9907\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0215 - acc: 0.9907\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0213 - acc: 0.9908\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0207 - acc: 0.9910\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0205 - acc: 0.9912\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0209 - acc: 0.9908\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0209 - acc: 0.9910\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0199 - acc: 0.9914\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0206 - acc: 0.9912\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0200 - acc: 0.9915\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0194 - acc: 0.9915\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0196 - acc: 0.9914\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0199 - acc: 0.9913\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0196 - acc: 0.9916\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0188 - acc: 0.9919\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0195 - acc: 0.9914\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0192 - acc: 0.9917\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0188 - acc: 0.9917\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0192 - acc: 0.9916\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0188 - acc: 0.9920\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0186 - acc: 0.9920\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0181 - acc: 0.9921\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0181 - acc: 0.9922\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0182 - acc: 0.9921\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0190 - acc: 0.9919\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0180 - acc: 0.9922\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0181 - acc: 0.9921\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0180 - acc: 0.9923\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0173 - acc: 0.9925\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0177 - acc: 0.9925\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0174 - acc: 0.9924\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0178 - acc: 0.9923\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0175 - acc: 0.9923\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0177 - acc: 0.9924\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0176 - acc: 0.9924\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0170 - acc: 0.9927\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0173 - acc: 0.9926\n",
      "85253/85253 [==============================] - 0s 6us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.3326 - acc: 0.8403\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.1425 - acc: 0.9385\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.1099 - acc: 0.9512\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0944 - acc: 0.9571\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0862 - acc: 0.9603\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0777 - acc: 0.9644\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0729 - acc: 0.9662\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0699 - acc: 0.9675\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0651 - acc: 0.9692\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0624 - acc: 0.9711\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0590 - acc: 0.9729\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0571 - acc: 0.9733\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0549 - acc: 0.9746\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0522 - acc: 0.9757\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0509 - acc: 0.9764\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0498 - acc: 0.9766\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0478 - acc: 0.9777\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0471 - acc: 0.9780\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0457 - acc: 0.9788\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0444 - acc: 0.9792\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0438 - acc: 0.9797\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0430 - acc: 0.9800\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0413 - acc: 0.9807\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0410 - acc: 0.9811\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0405 - acc: 0.9812\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0386 - acc: 0.9823\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0385 - acc: 0.9824\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0377 - acc: 0.9827\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0369 - acc: 0.9830\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0360 - acc: 0.9835\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0354 - acc: 0.9837\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0354 - acc: 0.9839\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0345 - acc: 0.9840\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0337 - acc: 0.9845\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0332 - acc: 0.9848\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0329 - acc: 0.9849\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0320 - acc: 0.9855\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0322 - acc: 0.9854\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0315 - acc: 0.9855\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0310 - acc: 0.9859\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0307 - acc: 0.9860\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0301 - acc: 0.9864\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0294 - acc: 0.9868\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0295 - acc: 0.9869\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0285 - acc: 0.9874\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0281 - acc: 0.9875\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0287 - acc: 0.9872\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0281 - acc: 0.9873\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0272 - acc: 0.9877\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0268 - acc: 0.9879\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0267 - acc: 0.9881\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0273 - acc: 0.9879\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0261 - acc: 0.9884\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0262 - acc: 0.9882\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 4136s 12ms/step - loss: 0.0255 - acc: 0.9887\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0257 - acc: 0.9886\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0255 - acc: 0.9888\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0248 - acc: 0.9889\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0245 - acc: 0.9892\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0245 - acc: 0.9891\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0238 - acc: 0.9893\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0239 - acc: 0.9896\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0236 - acc: 0.9895\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0238 - acc: 0.9896\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0234 - acc: 0.9898\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0234 - acc: 0.9897\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0229 - acc: 0.9899\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0226 - acc: 0.9900\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0231 - acc: 0.9897\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0226 - acc: 0.9900\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0227 - acc: 0.9901\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0220 - acc: 0.9902\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0221 - acc: 0.9904\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0216 - acc: 0.9906\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0216 - acc: 0.9905\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0218 - acc: 0.9903\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0218 - acc: 0.9904\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0219 - acc: 0.9904\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0211 - acc: 0.9907\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0215 - acc: 0.9907\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0212 - acc: 0.9909\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0205 - acc: 0.9911\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0206 - acc: 0.9910\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0209 - acc: 0.9912\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0209 - acc: 0.9909\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0209 - acc: 0.9910\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0207 - acc: 0.9911\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0206 - acc: 0.9911\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0201 - acc: 0.9913\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0202 - acc: 0.9913\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0205 - acc: 0.9911\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0203 - acc: 0.9913\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0202 - acc: 0.9913\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0195 - acc: 0.9914\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0196 - acc: 0.9917\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0204 - acc: 0.9913\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0196 - acc: 0.9916\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0190 - acc: 0.9918\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0195 - acc: 0.9916\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0198 - acc: 0.9916\n",
      "85253/85253 [==============================] - 1s 7us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.3392 - acc: 0.8380\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.1415 - acc: 0.9379\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.1071 - acc: 0.9517\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0918 - acc: 0.9576\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0830 - acc: 0.9616\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0751 - acc: 0.9650\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0707 - acc: 0.9667\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0662 - acc: 0.9687\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0628 - acc: 0.9703\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0596 - acc: 0.9719\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0573 - acc: 0.9732\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0553 - acc: 0.9741\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0526 - acc: 0.9754\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0513 - acc: 0.9760\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0489 - acc: 0.9772\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0480 - acc: 0.9778\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0465 - acc: 0.9781\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0444 - acc: 0.9792\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0438 - acc: 0.9795\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0420 - acc: 0.9804\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0408 - acc: 0.9810\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0402 - acc: 0.9813\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0393 - acc: 0.9818\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0386 - acc: 0.9825\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0379 - acc: 0.9826\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0367 - acc: 0.9833\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0366 - acc: 0.9832\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0360 - acc: 0.9835\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0351 - acc: 0.9840\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0338 - acc: 0.9845\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0337 - acc: 0.9848\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0336 - acc: 0.9847\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0324 - acc: 0.9851\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0315 - acc: 0.9857\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0319 - acc: 0.9856\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0308 - acc: 0.9860\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0306 - acc: 0.9862\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0300 - acc: 0.9865\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0285 - acc: 0.9871\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0290 - acc: 0.9868\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0287 - acc: 0.9870\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0285 - acc: 0.9872\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0276 - acc: 0.9875\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0269 - acc: 0.9879\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0268 - acc: 0.9881\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0265 - acc: 0.9879\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0263 - acc: 0.9883\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0255 - acc: 0.9887\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0262 - acc: 0.9883\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0253 - acc: 0.9888\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0248 - acc: 0.9890\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0249 - acc: 0.9888\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0242 - acc: 0.9894\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0238 - acc: 0.9894\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0244 - acc: 0.9891\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0237 - acc: 0.9895\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0233 - acc: 0.9899\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0229 - acc: 0.9899\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0232 - acc: 0.9897\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0228 - acc: 0.9899\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0223 - acc: 0.9901\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0224 - acc: 0.9901\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0222 - acc: 0.9902\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0219 - acc: 0.9903\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0215 - acc: 0.9907\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0216 - acc: 0.9906\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0209 - acc: 0.9908\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0213 - acc: 0.9906\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0212 - acc: 0.9907\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0207 - acc: 0.9909\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0206 - acc: 0.9909\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0204 - acc: 0.9910\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0204 - acc: 0.9911\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0199 - acc: 0.9914\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0198 - acc: 0.9913\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0203 - acc: 0.9911\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0197 - acc: 0.9914\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0200 - acc: 0.9911\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0195 - acc: 0.9914\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0194 - acc: 0.9916\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0193 - acc: 0.9917\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0193 - acc: 0.9916\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0190 - acc: 0.9918\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0191 - acc: 0.9917\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0189 - acc: 0.9919\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0189 - acc: 0.9919\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0190 - acc: 0.9917\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0186 - acc: 0.9919\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0188 - acc: 0.9918\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0183 - acc: 0.9921\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0185 - acc: 0.9920\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0189 - acc: 0.9918\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0188 - acc: 0.9920\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0187 - acc: 0.9919\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0180 - acc: 0.9923\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0184 - acc: 0.9921\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0176 - acc: 0.9922\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0177 - acc: 0.9924\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0181 - acc: 0.9922\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 8s 24us/step - loss: 0.0178 - acc: 0.9922\n",
      "85253/85253 [==============================] - 1s 7us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 9s 27us/step - loss: 0.3473 - acc: 0.8323\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.1479 - acc: 0.9366\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.1126 - acc: 0.9501\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0978 - acc: 0.9560\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0878 - acc: 0.9597\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0811 - acc: 0.9628\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0765 - acc: 0.9645\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0710 - acc: 0.9668\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0671 - acc: 0.9685\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0638 - acc: 0.9698\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0611 - acc: 0.9712\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0583 - acc: 0.9726\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0567 - acc: 0.9733\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0548 - acc: 0.9740\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0529 - acc: 0.9750\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0502 - acc: 0.9764\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0502 - acc: 0.9767\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0488 - acc: 0.9771\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0470 - acc: 0.9781\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0453 - acc: 0.9787\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0447 - acc: 0.9792\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0434 - acc: 0.9797\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0423 - acc: 0.9802\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0414 - acc: 0.9805\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0407 - acc: 0.9809\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0391 - acc: 0.9819\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0389 - acc: 0.9815\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0376 - acc: 0.9824\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0373 - acc: 0.9827\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0362 - acc: 0.9830\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0357 - acc: 0.9837\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0350 - acc: 0.9838\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0342 - acc: 0.9844\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0336 - acc: 0.9846\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0323 - acc: 0.9853\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0329 - acc: 0.9850\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0322 - acc: 0.9855\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0311 - acc: 0.9858\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0302 - acc: 0.9863\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0303 - acc: 0.9861\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0296 - acc: 0.9867\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0296 - acc: 0.9867\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0284 - acc: 0.9872\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0283 - acc: 0.9873\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0282 - acc: 0.9874\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0274 - acc: 0.9876\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0271 - acc: 0.9878\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0266 - acc: 0.9881\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0267 - acc: 0.9883\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0254 - acc: 0.9885\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0261 - acc: 0.9883\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0255 - acc: 0.9886\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0249 - acc: 0.9889\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0247 - acc: 0.9890\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0246 - acc: 0.9891\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0242 - acc: 0.9892\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0237 - acc: 0.9895\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0237 - acc: 0.9897\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0232 - acc: 0.9900\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0229 - acc: 0.9899\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0232 - acc: 0.9898\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0225 - acc: 0.9902\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0228 - acc: 0.9900\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0223 - acc: 0.9903\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0216 - acc: 0.9905\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0224 - acc: 0.9903\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0220 - acc: 0.9904\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0212 - acc: 0.9907\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0218 - acc: 0.9906\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0216 - acc: 0.9907\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0214 - acc: 0.9908\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0206 - acc: 0.9912\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0212 - acc: 0.9908\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0207 - acc: 0.9911\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0204 - acc: 0.9911\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0199 - acc: 0.9912\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0199 - acc: 0.9916\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0205 - acc: 0.9910\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0199 - acc: 0.9913\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0200 - acc: 0.9914\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0200 - acc: 0.9916\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0199 - acc: 0.9913\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0196 - acc: 0.9915\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0195 - acc: 0.9917\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0195 - acc: 0.9916\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0186 - acc: 0.9920\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0193 - acc: 0.9917\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0189 - acc: 0.9918\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0194 - acc: 0.9916\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0189 - acc: 0.9919\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0186 - acc: 0.9919\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0186 - acc: 0.9922\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0181 - acc: 0.9923\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0187 - acc: 0.9920\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0183 - acc: 0.9921\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0186 - acc: 0.9922\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0180 - acc: 0.9922\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0183 - acc: 0.9920\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0182 - acc: 0.9921\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 8s 25us/step - loss: 0.0180 - acc: 0.9923\n",
      "85253/85253 [==============================] - 1s 7us/step\n",
      "Time elapsed (hh:mm:ss.ms) 2:19:01.218738\n",
      "Overall accuracy of Neural Network model: 0.9917492833113596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 139.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9933    0.9902    0.9918    213688\n",
      "           1     0.9902    0.9933    0.9917    212578\n",
      "\n",
      "   micro avg     0.9917    0.9917    0.9917    426266\n",
      "   macro avg     0.9917    0.9918    0.9917    426266\n",
      "weighted avg     0.9918    0.9917    0.9917    426266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_ae_ann_2h_prob_unisoftsigbinlosadam,pred_ae_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XucVfP6wPHPFCmKUi6pJEceE1GK5E6KLhSFinRTbumgHOEchFwOIsetn0JuB7l2I9cUKhldqPFQdJlUqlNRmmpm9u+P79rNbszsvZuZvddes5/369Wr2XuvtfYza/b+Puv7/a71rIxQKIQxxhhTkkp+B2CMMSa1WaIwxhgTlSUKY4wxUVmiMMYYE5UlCmOMMVFZojDGGBOVJYoKTkQuE5EP/Y4jlYjIZhE53If3PUxEQiKyR7LfOxFEZKGInFmK9Ur9mRSRdiLybmnWLS0R2UtEfhCRA5P5vqkkw66jSB4RWQocBOQDm4EPgEGqutnHsMqViJwM3AucABQA04FbVHWRT/FMA15W1TFJer8jgRHAWcCewDLgBWAU0AD4BdhTVfOSEU9JRCQENFbVxQl+n8Mox99ZRL7BfWdmeY9DwJ9ACNgEvA7crKr5Eet0Au4AjgZycd+7W1Q1J2KZurjPbQegOrDS29a/VXWLiPwDOEhVh5T1dwgi61Ek3/mqWh1oBjQHbvU5nlIp7qhYRFoDHwLvAYcAjYD5wJeJOIJPtSNzEfkbMBtYATRV1f2Ai4GWQI1yfi/ffne/3ltETgD2CyeJCMd536kzgEuBfhHrdANexSXqOrhksQ34QkRqecvsD8wEqgGtVbUG0BaoCfzN29SrQG8R2StBv15KS6kvWjpR1dUiMhWXMADXxcUdjV4C7AW8A9yoqlu91zsDw4HDgbXAdar6gYjsB4zEHQ0VAM8Dd6pqvoj0Aa5U1VNF5Blgs6oOjXjP94DPVXWkiBwC/Ac4HdfjeVRVH/eWuws4BndEdgFwE1D0KP3fwIuqOiriuX+KSAvgLuAKb6jiZeApbxubgdtV9ZVY+yBi3f8ANwIfichg4CWgFe7z/CVwtarmiMgI4DTgJBF5DHhBVQdFHk2LyAvAFuAw7/deBPRU1SVePO289zsYeAXX0LxUQg9lOPCVqt4UfkJVFejpbaum9/RlInIPsLe3j0d4r5+Ia9Ayga3AW8BNqrrdez0EDAJu8H7XRiIyCrgI2A/4CbhBVWd4y1cGbgH6AwcCPwJdvN8DYL63zf6q+rp35H2vty8WeftxgbetpcDTwGXuoewDLMZ9tj72Yn8KONKL/RVvP0z33mujiIBrgMVb71Rv20cDjwEtgB3AKFW9r5j92x74vJjnw/t6sYh8ifedEpEM4BHg3vDnC9gqIlcCC3CfoTtwn8M/gMtVtcDb1grg7xHbzhGRDcBJ0WKoqKxH4RMRqY/74Ed2/R/EfdGaAUcA9XAf5HAj8iJwM+5I53RgqbfeOCDPW6c50A64spi3fRW41PsC4R1RtQNeE5FKwERcD6Ae0Aa4QUTOjVi/M/Cm9/6vRG5YRPYGTgbGF/O+b+AaiLCDcUd39YDewP+J14pE2wcR6+4PNAQG4j7Dz3uPD8U1Uk8AqOrtwAzcUEV1VR1UTGwAPXCNfC3c3yPccNfxft9bgdqAer9jSc7xlo/lVFxj2Qa4Q0QyvefzcY1XHaC19/q1RdbtgkuKTbzHc3D7an/c33e8iFT1XrvJ+906APvijrT/VNXTvdeP8/bL6yJyPPAccJX3u44GJhQ5gu4BdARqFjOMNArXwO+LOwp/w3s+/F41vfeaGbmSiNQAPsYNBx2C+5t/Uuxeg6a4v0GxROQo3IFB+DsluM/ELp9JLxm8ReFn8hzg7XCSiCIbOC7GMhWS9SiS713vKK468ClwJ+w8+hkAHKuq//Oeuw/35b8Vd1T4nKp+5G1npbfMQbiEU9PreWwRkUdxjejoIu89AzeWexruSK8bMFNVfxWRVsABqnq3t+zPIvIs0B2Y6j03U1XDE4lbi2x7f1yjvaqY33kVrvGL9C9V3QZ8LiKTgUtE5N4Y+wBcj+lOb91wHG+FN+r1Ij4rJoZo3lbVr731X8H1zsA1sAtV9W3vtceBocVvAnANbHG/f1HDvb/VfBGZj2t8slU1K2KZpSIyGjec8ljE8/eH9w2Aqr4c8dojIvJPXAM5H3ew8A+vV4P3XEkGAKNVdbb3eJyI3MauR9CPe0faxdkBHCEidVR1HVB0eKgknYDVqvqI9zgXN3xXnJq4I/+ivvV6T3sDr+F6NlD4mYv1mYz37/aHF0PasUSRfF28rvoZuAawDrAROAD3Qc8qPLgmA6js/dwAmFLM9hriJk1XRaxXCTdOvgtVDYnIa7gjw+m4IZGXI7ZziIhsjFilMi65hJXUSABswDXidYEfirxWF1gXuayqbol4vAx3NBlrHwCsVdXc8AOvJ/MocB6uRwBQQ0QqR05oxrA64uc/cUkcL6adv7O3/3Io2Xrc71qq9/Mmwkfi5jT2xn0/s4qsu8vfQESG4BLCIbiDgH0pbAAbAEviiAfc37+3iFwf8VwVb7vFvncR/YG7gR9E5BdcMpwUx/vuTowbKH6u53hvGxcDDwD74OYhwp+5urgJ9UiRn8l4/241cN/VtGOJwieq+rk3Pv4wbjhhHe7o+GhVXVnMKisonFgr+vw2oE6cZ5X8F/hQRB7ADWFcGLGdX1S1cZR1SzxFzjszZCbuy1r0iP4Sdh1OqCUi+0Qki0OB74m9D4qLYQjuCLqVN+/TDJiLSzBRY47DKqB++IHX66tf8uJ8DHTFDYWVxtO42Huo6h8icgOu1xdp5+8jIqfh5iDa4Ho+Bd44evh3D39mvo/jvVcAI8LzJSWI9vf/CejhDWFeBLwpIrWjrRPxvj3iiA/cvMKRJbx/CHjDm8e7AzePo0AO7jP57/CyXoxdgXDv+GPgQhEZHmP4KRM355F2LFH46zHcEEMzVZ3nDfU8KiKDVPU3EakHHKOqU4GxuAZ+Eq4hrgvUUNUfxJ2T/oiI/As3OdwIqK+qf5l0U9W5IrIWNxE9VVXDR0hfA7+LyC3A48B23BejmqrOifP3GQZMFZEfcI3lHriGvDXudNlIw72hjVa44Yc7vYYu2j4oTg1cctnonb1yZ5HX1+Am/0tjMvCEiHQBJgFX4+ZISnInMEdEHgIe8RLXEbiJ/JLmRyLVAH4HNnvj7dfgTlqItnyet8weIjIM16MIGwPcIyKLcOP2TYGVqrqewv0SHs9/FnhHRD7GfRb2Bs4EpqtqccM9uxCRy3Gfp7URvdJ8L7YC771+LGbVScBILyk+jevFNIkYAos0BTe0FM0DwGwRecDb/0OBZ72e4Du4Sf/7cPvpUW+dkcDluOG2f6rqMu9zNwR3AsQC7/H+xD+kVqHYZLaPVHUtboL6X95Tt+C+uLNE5HfckY54y34N9MV9uDfhxo0beutdgfuCLcJ1z98kelf6v7gJvFcjYskHzsdNjP6CO7ofg/tixfv7fAGcizuiXIUbUmoOnOodcYat9uL8FTcpfrWqhoerStwHJXgMd1pjeFz8gyKvjwK6icgGb44hbt5Ye/hodD1uAvkbXA+uuOWX4JLiYcBCEdmEmz/5huLH1osaihsO/APXcL8eY/mpwPu4BngZbnw/cnhoJG5S+UNcAhqL21fgktc4EdkoIpeo6je4eYoncH+bxUCfOGIOOw/3O2/G7fPuqpqrqn/iTg740nuvkyJX8pJQW9xnbzXuzK2zinsDVf0W2OTNpxVLVb/DfTdu9h6/DvTCnSSwDvcdqQac4iVMvDmfk3HzLLNF5A9cD3gThYm0JzAuYm4srdgFdyapxDvFVVWjDeGkJG/IIge4TFV3d8LclAPvdOVrVbVLEt9zL9yJAKer6m/Jet9UYkNPxkThnR48Gze8dTNu/D8thx9Sgap+iOshJfM9twFHJfM9U03CEoWIPIcbe/5NVY8p5vUMXBe1A+7Mjz5e19KYVNIaN0QXHtrr4p3aakzaSNjQk4iEr+59sYRE0QG4HpcoWuEu1ilx7NEYY4w/EjaZrarTgf9FWaQzLomE1NVuqSmuMJcxxpgU4uccRT12PUMjx3su6hWSWVlZoUqVyi+/Fe1QFdfBKstzuz6fUcxzpd9mKBQiIyPaNjPiiKn07x/Pe8W7fjx/h8LnM4p5LkSs/VvS87GfK5+/m1/7Mva6xe3P0r137Odiv5cpXw1ZRk02sqNJ43UtWrQ4oDTb8DNRZBTzXMyPTaVKlWjevDkzZsDFF8O2be7DVlAQbjyL/1fc66biyMhwSTMjg2L/VapU/PPxvF6Wdf3Y9pYtf1CjRo3AxZ2Iba9evYpDDqmb8nGXe1yE3P+VMqjxyjT2WP8bPzVpvKy03y8/E0UO7vL9sPq48+rjsmABrFkDAwbA3nun3h8vGR/IFSuW07DhoYGLOxGvZ2f/QGZmZuwPThrIzs6xfeHJzt5IZmaajWivXAnXXAOXXgqXXQa3XeOezypaDSZ+fiaKCcAgr/ZQK2CTqsZTmAuAPK9YxYMPQq1a0ZetqLKzt2DtgTEGcMMkY8bA0KGwYwd07Fhum07k6bH/xZUAqONdPn8nrngdqvoM7nL8DrgrH//EXXUct3Ci2MOuBDHGpLslS9zwymefwVlnwbPPwt+KKw1XOglrZlU1aqEvr4jXdaXdviUKY4zxfPedG1r6v/+DK69047HlKLDNrCUKY0xa+/57+PZbuOIK6NIFfv4ZatdOyFsFtihgOFFUrhx9OWOMqVC2b4e77oLjj4fbb4dc7/YsCUoSEOBEkZ9feCaMMcakhdmzXYIYPtyd1TR3LlStGnu9MgrswE1eng07GWPSyMqVcNppcNBBMGlSuZ7VFEtgj8ctURhj0sKP3v2e6tWD11+HhQuTmiTAEoUxxqSmjRth4EA46iiYPt09d+GFsO++0ddLgMA2tZYojDEV1oQJ7urq1avh5pvhhKJ3Ek6uwDa1liiMMRXSlVfC2LHQtCm89x60bOl3RJYojDHGd+EqpRkZLjE0bAi33AJVqvgblyewTa0lCmNMhbBiBVx9NXTvDr16uZ9TTGAns/Pz7WI7Y0yAFRTA00/D0UfDtGnungkpKrDH5NajMMYE1k8/ubmI6dPhnHNcjaZGjfyOqkSBbWotURhjAmvRIndTneeegz59yr2IX3kLbFNricIYEyjz58O8edC7N3Tu7Ir4BeRmOoGdo7BEYYwJhG3b4F//cmcz/etfhUX8ApIkwBKFMcYkzsyZ0Lw53Hsv9OyZtCJ+5S2wTa0lCmNMSlu5Es44Aw4+GKZMgfbt/Y6o1KxHYYwx5Sk72/1frx688YYr4hfgJAEBThR2HYUxJqVs2AD9+kGTJjBjhnuuSxeoUcPfuMpBYI/J8/ICOdRnjKmI3nkHrr0W1q6FW2/1vYhfeQt0orChJ2OM7/r1g+efh2bNYPJkdwe6CiawTa0lCmOMbyKL+J10EjRuDEOHwp57+htXggS2qbVEYYzxxbJlcNVV7nTXK65wNxeq4AI7mW2JwhiTVAUF8OSTcMwx8MUXsGOH3xElTWCbWksUxpikUXVF/L74Atq1g9Gj4bDD/I4qaQLb1FqiMMYkjaq7HuKFF9xwU4oX8StvgW1q7ToKY0xCzZ3rivj17QsXXOCK+NWs6XdUvrA5CmOMiZSbC7fd5q6FuOuuwiJ+aZokwBKFMcYU+vJLdz3E/fe7IaZ58+zKXgI89GSJwhhTrlauhLPOcjWapk51k9YGsB6FMSbdLVrk/q9XD956C777zpJEEZYojDHp6X//c7chPfpod+9qgPPPh+rVfQ0rFQW2qbVEYYwptbfeguuug/Xr4fbb4cQT/Y4opQW2qbVEYYwplT59YNw4V7zvgw/c5LWJKrBNrV1HYYyJW2QRv5NPhsxMGDLEjjbjlNC9JCLnAaOAysAYVX2gyOuHAuOAmt4yw1R1SqztFhS4v7v9jY0xMf3yiyvcd/nl0Lt3WhTxK28Jm8wWkcrAk0B7oAnQQ0SaFFnsn8Abqtoc6A48Fc+28/Lc/5YojDElys+n1ksvuSJ+s2YV9irMbktkU3sisFhVfwYQkdeAzsCiiGVCwL7ez/sBv8azYUsUxpiosrOhf38OnjnT3a/6mWfg0EP9jiqwEtnU1gNWRDzOAVoVWeYu4EMRuR7YBzgn1kYLCgpYuFABYf36NWRn/6+cwg2e3NxcssM3ck9zti8K2b6A6p99Rt1Fi8i55x62XnQRbNnikocplUQmiuLKKxbt+/UAXlDVR0SkNfCSiByjqgUlbbRSpUo0aiQA1Kt3EJmZB5VbwEGTnZ1NZmam32GkBNsXhdJ2X2Rlwfz57takmZlw+eVsXbkyPfdFMbKyskq9biIvuMsBGkQ8rs9fh5b6A28AqOpMoCpQJ9aGbejJGLPT1q0wbBi0agX33FNYxG/ffaOvZ+KWyEQxB2gsIo1EpApusnpCkWWWA20ARCQTlyjWxtqwJQpjDOCuqD7uOHjwQXd9xNy5VsQvARKWKFQ1DxgETAWycWc3LRSRu0XkAm+xIcAAEZkP/Bfoo6oxT03Iz3f/23UUxqSxlSuhTRt35PjxxzBmTFqXAk+khB6Te9dETCny3B0RPy8CTtnd7VqPwpg09t130LSpK+L3zjuu4us++/gdVYUWyKKAliiMSUPr1kGvXnDssYVF/Dp1siSRBIFsai1RGJNGQiEYPx4GDYING+DOO93EtUmaQDa1liiMSSO9e8NLL0HLlvDJJ27YySRVIJtaSxTGVHCRRfzOOMMNN91wg33pfWJzFMaY1PLzz3DOOfDCC+5x//4wdKh94X1kicIYkxry8+Gxx9zQ0pw5UCmQzVOFFMim1q6jMKaCWbTIld6YPRs6dnRF/OrX9zsq4wlkorAehTEVzC+/wJIl8Oqr0L27m5swKSOQTa0lCmMqgDlzYN48GDDA9SJ+/hlq1PA7KlOMQA4CWqIwJsD+/NNNTp90Etx/f2ERP0sSKcsShTEmeaZNc6e6PvKI60lYEb9ACGRTa4nCmADKyYG2baFhQ/j0U1ejyQSC9SiMMYk1f777v359eO89WLDAkkTAWKIwxiTG2rXQsyc0awaff+6e69AB9t7b37jMbgtkU2vXURiTwkIheO01GDwYNm2C4cOhdWu/ozJlEMhEYT0KY1JYr17wyiuuwuvYsXD00X5HZMookE2tJQpjUkxBgbtILiPDzT+0aOF6FNbtrxBsjsIYUzaLF7tbkj7/vHvcvz/ceKMliQrEEoUxpnTy8uDhh10Rv7lzoUoVvyMyCRLIptYShTE++/576NsXvvkGOneGp56CQw7xOyqTIIFsai1RGOOz5cth2TJ3dtMll1gRvwoukE2tJQpjfDB7trt4buBAdz3Ezz9D9ep+R2WSIJBzFHYdhTFJtGUL3HSTuxbi3/+Gbdvc85Yk0kYgE4X1KIxJkk8/dUX8Hn0Urr4avv0W9trL76hMkgWyqc3Lc0OidqdEYxIoJwfOPRcaNXIlOE4/3e+IjE8C2dTm5VlvwpiEmTvX/V+/Pkyc6OYlLEmkNUsUxhhnzRq49FI4/vjCIn7nnQfVqvkbl/GdJQpj0l0oBC+/DE2awLvvwr33wskn+x2VSSGBbG4tURhTjnr2dNdDtG7tivhlZvodkUkxgWxuLVEYU0aRRfzatXNJ4rrr7JxzU6xADj3l59vn2ZhS+/FHV+H1uefc4759rdKriSqQicJ6FMaUQl6eu2DuuOPc7UhtktrEKZDNrSUKY3bTggXQrx9kZcGFF8KTT0Ldun5HZQIikM2tJQpjdlNODqxYAePHQ9euVsTP7JaENrcich4wCqgMjFHVB4pZ5hLgLiAEzFfVnrG2a4nCmDh89ZXrSVx9dWERv3328TsqE0AJm6MQkcrAk0B7oAnQQ0SaFFmmMXArcIqqHg3cEM+2LVEYU7KMLVvg73+HU0+FRx4pLOJnScKUUiIns08EFqvqz6q6HXgN6FxkmQHAk6q6AUBVf4tnw5YojCnBhx9yeOfO8J//uNNdrYifKQeJbG7rASsiHucArYoscySAiHyJG566S1U/iLbRgoICNm7cTF5eZbKzl5ZjuMGTm5tLdna232GkBNsXsMeqVRzRsSMF9euz9MUX2dqihZubSGP2uSgfiUwUxc2WhYp5/8bAmUB9YIaIHKOqG0vaaKVKlahWrTr77AOZaX4FaXZ2dtrvg7C03hdZWdCihbuiesoUlh5wAEc1a+Z3VCkhrT8XRWRlZZV63UQOPeUADSIe1wd+LWaZ91R1h6r+AigucURlQ0/GAKtXw8UXQ8uWhUX82rYlZENNppwlMlHMARqLSCMRqQJ0ByYUWeZd4CwAEamDG4r6OdaGLVGYtBYKwbhxrojfxIlw331WxM8kVMISharmAYOAqUA28IaqLhSRu0XkAm+xqcB6EVkEfAbcrKrrY23bEoVJa927Q58+LlHMmwe33gp77ul3VKYCS2hzq6pTgClFnrsj4ucQcJP3L26WKEzaiSzi16EDnHYaXHut3ebRJEUgP2WWKExa+eEHd4e5sWPd4969YdAgSxImaQL5SbNEYdLCjh1u/uG442DRIqhe3e+ITJoKZHNricJUePPmufLf8+ZBt27uArqDD/Y7KpOmAtnc2v0oTIW3erX799ZbcNFFfkdj0lzURCEiUSeZVXVk+YYTH+tRmArpiy9cEb9rr4XzzoMlS2Dvvf2OypiYcxQ1YvzzhSUKU6H88YebnD7tNHjsscIifpYkTIqI2tyq6vBkBbI7LFGYCmPqVBg40N0r4u9/h3vvtSJ+JuXEGnp6PNrrqjq4fMOJjyUKUyGsWAGdOsERR7hhJ7u62qSoWM1t6atIJZAlChNYoRDMmQMnnggNGsD777v7RlSt6ndkxpQo1tDTuGQFsjssUZhAWrXK3SPinXdg2jQ44ww45xy/ozImpriaWxE5ALgFd6e6nYc+qnp2guKKyhKFCZRQCF54AW66CXJz4cEH4ZRT/I7KmLjFe2X2K7jCfo2A4cBSXHVYX9h1FCZQLrkE+vWDpk1h/nz4xz/sSMcESryJoraqjgV2qOrnqtoPOCmBcUVlPQqT8vLzXSE/gPPPh6eecsNNRx7pa1jGlEa8ze0O7/9VItIRdwOi+okJKTZLFCalZWdD//6uBMeAAXDFFX5HZEyZxNvc3isi+wFDgP8A+wI3JiyqKEIh988ShUk5O3a4+Yd77nEF/Pbbz++IjCkXcTW3qjrJ+3ET3h3p/BLy7rpticKklLlz3c2EFiyASy+Fxx+HAw/0OypjykVccxQiMk5EakY8riUizyUurNgsUZiUsmYNrFsH774Lr71mScJUKPFOZh+rqhvDD1R1A9A8MSFFZz0KkzKmT4cnn3Q/n3ceLF4MnTv7G5MxCRBvoqgkIrXCD0Rkf3wqUW6Jwvju999dhdczznBDTOEiftWq+RuXMQkSb3P7CPCViLwJhIBLgBEJiyoOdh2F8cWUKXDVVfDrr+4CurvvtiJ+psKLq0ehqi8CXYE1wFrgIlV9KZGBlcR6FMY3K1a4oaX99oOvvoJHHoF99vE7KmMSbnfumb0/sEVV/wOsFZFGCYopKksUJqlCIZg1y/3coAF8+CF8+y20auVvXMYkUbxnPd2Jq/V0q/fUnsDLiQoqugzAEoVJgl9/hS5doHVr+Pxz99xZZ0GVKv7GZUySxdujuBC4ANgCoKq/4tMd7qxHYRIuFIIxY6BJE9eDePhhK+Jn0lq8iWK7qoZwE9mIiG8Ds5YoTMJ16+ZKbzRrBt99B0OG2AfOpLV4P/1viMhooKaIDAD6AWMSF1Zs9r015So/HzIyoFIlN9zUrp1LFpV2ZxrPmIop3rOeHgbeBN4CBLhDVaPeJjVRrEdhyt3337uhpbFj3eNevdwpsJYkjAF246I5Vf0I+AhARCqLyGWq+krCIovBrqMwZbZ9O9x/P4wY4U55rVUr9jrGpKGoiUJE9gWuA+oBE3CJ4jrgZmAe7oZGSWU9ClMusrJcEb/vv4eePeGxx+CAA/yOypiUFKu5fQnYAMwErsQliCpAZ1Wdl+DYimWJwpSL9eth40aYOBE6dfI7GmNSWqzm9nBVbQogImOAdcChqvpHwiMrkV1HYUrps8/cWUyDB7vJ6p9+gqpVY69nTJqLNVsXvrMdqpoP/OJvkrAehSmFTZvc5PTZZ8PTTxcW8bMkYUxcYjW3x4nI797PGUA173EGEFLVfRMaXTEsUZjdMnEiXH01rF4NQ4fC8OFWxM+Y3RS1uVXVlD23yBKFiWnFCujaFY46yt1Q6IQT/I7ImEAK3Ini1qMwUYVCrrIrFBbx++YbSxLGlEFCE4WInCciKiKLRWRYlOW6iUhIRFrG2mY4Udh1FOYvcnLgggvcxXPhIn5nnmlF/Iwpo4QlChGpDDwJtAeaAD1EpEkxy9UABgOzd2f71qMwOxUUUPP1110Rv08+gZEj4dRT/Y7KmAojkT2KE4HFqvqzqm4HXgOKu6HwPcC/gdx4NmpDT+Yvunal7vDhbnjp++/hxhuty2lMOUpkc1sPWBHxOAfY5W4vItIcaKCqk0RkaDwbLShw/y9dupi8vB3RF67gcnNzyc7O9jsMf+TluVpMlSqx70knkd+0KVu6d3envqbrPvGk9eeiCNsX5SORiSKjmOdC4R9EpBLwKNBntzaa4TZ71FFH0KBBGaKrALKzs8nMzPQ7jORbsAD694crr3TXR2Rmpu++KIbti0K2LwplZWWVet1EDj3lAJFNeX3g14jHNYBjgGkishQ4CZgQa0Lbhp7S2LZtcOed0KIFLFtmtZmMSZJENrdzgMbevbVXAt2BnuEXVXUTUCf8WESmAUNV9ZtoG7VEkabmzHFF/BYtcmXAH30Uatf2Oypj0kLCehSqmgcMAqYC2cAbqrpQRO4WkQvKun1LFGlmwwbYvBmmTIEXX7QkYUwSJbS5VdUpwJQiz91RwrJnxrNNu44ijXz6qSvi9/e/uyJ+P/5o5TeM8YFdmW1Sz8aN7jakbdrA6NGFRfwsSRjji8AlijBLFBXUe++5C+eeew7+8Q93gyFLEMb4KnDNbShk96OosJYvh4svhsxMmDABWsas6GJ+lU8GAAAWz0lEQVSMSYLA9ShCIcjIsPveVxihEMyY4X4+9FD4+GN3hpMlCWNSRiCbW+tNVBDLl0PHjnD66YVF/E4/3Yr4GZNiApcoQiFLFIFXUABPPQVHHw3Tp8Pjj1sRP2NSWOCa3FDITo0NvIsucpPWbdvC//0fHHaY3xEZY6IIXKIA61EEUkQRPy69FDp3dldaZxRXEswYk0ps6Mkk3vz50KqV6z0A9OgBfftakjAmICxRmMTJzYV//tOdwZSTAwcf7HdExphSCGCTm2GJIgi+/hp694YffnD/jxwJ++/vd1TGmFIIXJNrPYqA+P132LoVPvgAzj3X72iMMWUQuCbXEkUK+/BDWLjQ3Yr0nHNA1cpvGFMBBG6OAixRpJwNG9zk9LnnwtixVsTPmAomcInCrqNIMW+/7Yr4vfQS3HorfPONJQhjKphAHptbjyJFLF8O3bvDMce4Gwo1b+53RMaYBAhkj8IShY9CocK6TIce6m4uNHu2JQljKjBLFCZ+y5ZB+/Zw5pmFyeLUU2HPPX0NyxiTWIFLFHYdhQ8KCuCJJ1wRvy++gP/8B047ze+ojDFJErgm13oUPujSBSZOdGc1jR4NDRv6HZExJokC1+RaokiSHTvc6WWVKrnaTN26Qa9eVp/JmDQUwKEnSxQJ9+23cOKJ8Mwz7nGPHnDFFZYkjElTgUsUdh1FAm3d6q6FOPFEWL0aGjTwOyJjTAoI3LG5DT0lyKxZrnjfjz9Cv37w8MNQq5bfURljUkAgm1xLFAmwZYubl/joI1enyRhjPIFrcq1HUY4++MAV8RsyBNq0cSXBq1TxOypjTIoJ4ByFXUdRZuvXu2Gm9u1h3DjYvt09b0nCGFOMwCUKsB5FqYVC8Oabrojfq6+6u8/NmWMJwhgTVeCaXBt6KoPly6FnTzj2WHfviOOO8zsiY0wABK5HYYliN4VCrnAfuCuqp01zZzhZkjDGxClwiQLsOoq4/fILtGvnJqrDRfxOPtkyrTFmtwQuUViPIg75+TBqlLtPxOzZ8PTTVsTPGFNqgWtyLVHEoXNnmDwZOnRwZTjsCmtjTBkEssm1RFGMyCJ+vXq5+kw9e1p9JmNMmSW0yRWR84BRQGVgjKo+UOT1m4ArgTxgLdBPVZdF26ZdR1GMb76B/v1h4EC47jq49FK/IzLGVCAJm6MQkcrAk0B7oAnQQ0SaFFlsLtBSVY8F3gT+HWu7NvRUKCM3F265BVq1grVr7T4RxpiESGSTeyKwWFV/BhCR14DOwKLwAqr6WcTys4DL49mwJQpg5kwa9ejhbk965ZXw0ENQs6bfURljKqBENrn1gBURj3OAVlGW7w+8H8+G//e/38jOXl+G0IJv7x9+4OD8fJaNHcufrVvDqlXuX5rKzc0lOzvb7zBSgu2LQrYvykciE0Vxs6ih4hYUkcuBlsAZ8Wy4bt0Dycw8sAyhBdSUKa6I3803Q2Ym2S1akHnssX5HlRKys7PJzMz0O4yUYPuikO2LQllZWaVeN5HXUeQAkedl1gd+LbqQiJwD3A5coKrb4tlw2g09rVsHl18OHTvCK68UFvHbc09/4zLGpIVEJoo5QGMRaSQiVYDuwITIBUSkOTAalyR+i3fDaZMoQiF47TXIzIQ33oA774Svv7YifsaYpEpYolDVPGAQMBXIBt5Q1YUicreIXOAt9hBQHRgvIvNEZEIJm9tF2iSK5ctdOfBGjSArC+66y5KEMSbpEtrkquoUYEqR5+6I+LlUt1Kr0IkiFIJPPnF3mWvY0NVoOuEEK3BljPFN4Go9QQVOFEuWuAJ+bdsWFvE76SRLEsYYX1miSAX5+TByJDRt6oaYRo+2In7GmJQRyCa3wiWK88+H99+HTp1cpdf69f2OyBhjdgpkk1shRmK2b3cZr1Il6NPHFfLr3t2K+BljUo4NPfnh66+hRQt46in3+JJLXLVXSxLGmBRkiSKZ/vwThgyB1q1hwwb429/8jsgYY2IKZJMbyETxxRfumoiff4arroIHH4T99vM7KmOMiSmITW4wE0X4xkKffQZnnul3NMYYE7cgNrnBSRQTJ0J2NvzjH3DWWbBoUYCCN8YYx+YoEmHtWncb0gsugP/+t7CIX8oHbowxf2WJojyFQvDqq66I35tvwt13w+zZVp/JGBNoqdrkRpWy11EsXw59+0Lz5jB2LBx9tN8RGWNMmVmPoqwKCmDqVPdzw4YwYwZ8+aUlCWNMhWGJoix++gnOPhvOOw+mT3fPnXhiCnd5jDFm91miKI28PHjoITj2WJg3zw0zWRE/Y0wF5XeTWyq+J4pOndxwU+fOrgzHIYf4HJAx/tqxYwc5OTnk5ub6HcouduzYQXZ2tt9hJFXVqlWpX78+e5bjrZL9bnJLxZdEsW2bu0d1pUpw5ZXQrx9cfLHVZzIGyMnJoUaNGhx22GFkpNB3YuvWrVSrVs3vMJImFAqxfv16cnJyaNSoUblt14ae4jFrFhx/PDz5pHvcrZsr5JdCXwhj/JSbm0vt2rVTKkmko4yMDGrXrl3uPTtLFNFs2QI33ggnnwx//AGNGyfpjY0JHksSqSERf4dADj0l5aSiGTNcEb9ffoFrr4X774d9903CGxtjTGqxHkVJ8vLcnMTnn7shJ0sSxqS8jz76CBFhyZIlO5+bPXs2V1111S7LDRs2jA8++ABwE94PP/ww7dq1o1OnTnTr1o3Pw/esL4PRo0fTtm1bzj33XGbMmFHsMjNnzuTCCy+kU6dO3HLLLeTl5QGwadMmrrvuOs4//3y6devGjz/+CMCqVavo1asX7du3p2PHjowbN67MccbDEkWkd991PQdwRfwWLoTTT0/QmxljytukSZNo0aIFU6ZMiXudUaNGsXbtWiZNmsSkSZN45pln2LJlS5niWLx4MZMnT2by5MmMGTOG4cOHk5+fv8syBQUFDBs2jJEjRzJp0iQOOeQQ3nnnHQCeeeYZMjMzmThxIg8++CAjRowAoHLlygwbNoz333+f119/nVdffZXFixeXKdZ4BHLoqdwTxZo1cP31MH68m7QeMsTVZ/L9PFxjgufFF+G558p3m/36wRVXRF9my5YtfPvtt7z44otcc801XH/99TG3u3XrVsaPH88nn3xCFa8mW506dejQoUOZ4v3kk0/o2LEjVapUoUGDBjRs2JAFCxbQvHnzncts3LiRKlWq7Dw76ZRTTmH06NFcfPHFLFmyhIEDBwLwt7/9jZUrV7Ju3ToOPPBADjzwQACqV6/O4Ycfzpo1azjiiCPKFG8sgWwJy639DoXg5Zfhhhtg82YYMQJuvtkNORljAuXjjz/mtNNOo1GjRtSsWZOFCxdy+OGHR11n2bJl1K1bl+rVq8fc/n333cfs2bP/8nzHjh13Nupha9as4bjjjtv5+KCDDmLNmjW7LFOrVi3y8vL47rvvaNq0KR988AGrV68G4KijjuKjjz6iZcuWLFiwgF9//ZXVq1dTp06dnevn5OSQnZ29y/skSnoniuXL3TURLVu6q6uPOqqcNmxM+rriithH/4kwefJkevfuDUCHDh2YNGkSgwcPLvEsoN09O+i2226Le9lQKBTz/TIyMhg5ciT3338/27dv55RTTqGyd6bOwIEDGTFiBJ07d+bII48kMzOTPSIavi1btjB48GBuu+22uJJcWaVfoggX8Wvf3hXx+/JLV+3V6jMZE1gbNmxg1qxZ/PTTT2RkZJCfn09GRgbXX389NWvWZNOmTbssv3HjRmrVqkXDhg1ZtWoVmzdvjtng7k6P4uCDD97ZOwDXwwgPGUVq3rw5r776KgBffPEFS5cuBdyw0v3efGkoFKJNmzbUr18fcJPvgwcP5vzzz6ddu3Yx9kz5CGSiqFTaKfgff3Q9iBkzYNo0OOMM15swxgTa1KlT6dKlC3fffffO5y6//HLmzp3LCSecwG+//caSJUt2jverKpmZmVSrVo2uXbsyYsQIhg8fTpUqVfjtt9+YOXMmnTt33uU9dqdHcfbZZzNkyBD69u3LmjVrWLp0Kccee+xfllu/fj21a9dm+/btPPvss1x99dUA/P7771StWpUqVaowfvx4WrZsSfXq1QmFQtx+++0cfvjh9O3bt5R7a/cFLlGU6lqSvDx45BG4806oVg2ef97OZjKmApk8eTIDBgzY5bl27drx/vvvc8opp/DQQw9x6623sm3bNvbYYw/uvfdeatSoAcANN9zAY489RseOHdlrr72oVq0agwcPLlM8jRs3pn379nTo0IHKlStzxx137BxWGjBgAPfeey8HHXQQY8aMYdq0aRQUFNCjRw9at24NwJIlS7jllluoVKkSRxxxxM6znrKysnjvvfc48sgjdyaym266iTPOOKNM8caSUdxYWip75ZVFocsua7J7K517Lnz4IVx0kbsm4uCDExNckmVnZ5OZmel3GCnB9kUhP/ZFqu7/dKv1FFbc3yMrKyurRYsWpRpCCVyPIm65ue7spcqVYeBA969rV7+jMsaYwAncBXdxDT19+SU0a1ZYxK9rV0sSxhhTShUrUWzeDIMHu5sI5eZCCnaFjamogjaMXVEl4u8QuERRos8/h2OOgSeegEGD4PvvoW1bv6MyJi1UrVqV9evXW7LwWfh+FFWrVi3X7QZujiJqj2Lvvd2pr6eckrR4jDFQv359cnJyWLt2rd+h7GLHjh3leqe3IAjf4a48BTtRvP02/PAD3Habuybiu+/swjljfLDnnnuW6x3Vykuqno0VNAlNFCJyHjAKqAyMUdUHiry+F/Ai0AJYD1yqqktjbnj1aje89NZb7oK5oUNdET9LEsYYU+4SNkchIpWBJ4H2QBOgh4gUvQCiP7BBVY8AHgUejLXd/QvWuUnqSZNcSfCvvnJJwhhjTEIkcjL7RGCxqv6sqtuB14DORZbpDITvvPEm0EZEop4Ae0jeCjdpPX8+DBtmlV6NMSbBEjn0VA9YEfE4B2hV0jKqmicim4DawLqSNprb5Kh1WY89tozNmyErq5xDDp4s2wc72b4oZPuikO2LnRqWdsVEJoriegZFz52LZ5ldtGjR4oBSR2SMMWa3JXLoKQdoEPG4PvBrScuIyB7AfsD/EhiTMcaY3ZTIHsUcoLGINAJWAt2BnkWWmQD0BmYC3YBPVdWu2DHGmBSSsB6FquYBg4CpQDbwhqouFJG7ReQCb7GxQG0RWQzcBAxLVDzGGGNKJ3Blxo0xxiRXxan1ZIwxJiEsURhjjIkqZWs9Jaz8RwDFsS9uAq4E8oC1QD9VXZb0QJMg1r6IWK4bMB44QVW/SWKISRPPvhCRS4C7cKedz1fVoieUVAhxfEcOxV3cW9NbZpiqTkl6oAkmIs8BnYDfVPWYYl7PwO2nDsCfQB9V/TbWdlOyR5Go8h9BFOe+mAu0VNVjcVe4/zu5USZHnPsCEakBDAZmJzfC5IlnX4hIY+BW4BRVPRq4IemBJkGcn4t/4k6oaY47A/Op5EaZNC8A50V5vT3Q2Ps3EHg6no2mZKIgQeU/AirmvlDVz1T1T+/hLNw1KxVRPJ8LgHtwyTI3mcElWTz7YgDwpKpuAFDV35IcY7LEsy9CwL7ez/vx12u6KgRVnU70a9E6Ay+qakhVZwE1RaRurO2maqIorvxHvZKW8U7FDZf/qGji2ReR+gPvJzQi/8TcFyLSHGigqpOSGZgP4vlcHAkcKSJfisgsb3imIopnX9wFXC4iOcAU4PrkhJZydrc9AVI3USSk/EdAxf17isjlQEvgoYRG5J+o+0JEKuGGIYckLSL/xPO52AM3xHAm0AMYIyI1ExyXH+LZFz2AF1S1Pm58/iXv85JuStVupuqOsvIfheLZF4jIOcDtwAWqui1JsSVbrH1RAzgGmCYiS4GTgAki0jJZASZRvN+R91R1h6r+AigucVQ08eyL/sAbAKo6E6gK1ElKdKklrvakqFQ968nKfxSKuS+84ZbRwHkVeBwaYuwLVd1ExJdfRKYBQyvoWU/xfEfexTuSFpE6uKGon5MaZXLEsy+WA21w+yITlyhS676tyTEBGCQir+GqeW9S1VWxVkrJHoWV/ygU5754CKgOjBeReSIywadwEyrOfZEW4twXU4H1IrII+Ay4WVXX+xNx4sS5L4YAA0RkPvBf3GmhFe7AUkT+izt4FhHJEZH+InK1iFztLTIFd7CwGHgWuDae7VoJD2OMMVGlZI/CGGNM6rBEYYwxJipLFMYYY6KyRGGMMSYqSxTGGGOiStXrKEwFJiL5wHcRT3UpqfKviBwGTFLVY0TkTNx1EZ3KIYYzge2q+lUJr3cBjlXVu0XkdOAx4Figu6q+WcI6gruepSawFzBDVQeWNdaI7V8ANFHVB0TkAGASUAVXAPFWoKeqbixh3auBP1X1RRHpA3yoqlEvtBKRj4GLw7WiTPqyRGH8sFVVm/kcw5nAZqDYRAH8Awifg78c6AMMjbHNx4FHVfU9ABFpWuYoI6jqBNwFU+AuHvtBVXt7j2fEWPeZiId9gO+JfUXuS7jz7EfsdrCmQrFEYVKC13N4CdjHe2pQSUf7JazfBngY95meA1yjqtu8Uh4tVXWdV8rjYVxDeTWQ79XHul5VZ0Rs60hgm6quAwj3dkSkIEYYdXElEvDW+85brw9wIa6X0Qh4VVWHe69djusRVMGVRb9WVfO9An734e6dsE5V23jbaQmMwVXHrSYi84DWuAvNwr/nFbikFgIWqGovEbkLlxiXett4RUS24sq+XKmqF3rxtPX23UW4pDQDSxRpz+YojB+qeVeQzxORd7znfgPaqurxwKW4o/O4iEhVXB3+S1W1KS5ZXFPS8l7D/wzu6L9ZZJLwnALEvJlLMR4FPhWR90XkxiIF+E4ELgOaAReLSEuvlMSluPtFNAPygcu8YaVnga6qehxwcZH45wF3AK978W8NvyYiR+Ma/7O9df9eZN03gW+Ay7z3nAJkeu8J0Bd43lt2A7CXiFTEqsxmN1iiMH7Y6jVwzcJHssCewLMi8h3uznR/uSFRFAL8oqo/eo/HAaeXIb66lKIOkKo+D2Ti4j8TmOXdiRHgI1Vd7zXqbwOn4oaPWgBzvJ5BG+BwXDHD6V4hP1R1d4pdng28GdEbirquV8biJVwJ7pq43klkmfrfgEN24/1NBWRDTyZV3AisAY7DHcBEvemQiEwFDsIdHT8RZdE8Cg+IqsYZy1ZcNeKoRGQE0BEgPOfiTRA/BzwnIt/jqtnCX0s5h3Aln8ep6q1FtntBMcvHK6MU6z4PTMTt8/Fe7aSwqrj9YdKY9ShMqtgPWKWqBUAv3Nh8iVT1XK9HciXwA3CYiBzhvdwL+Nz7eSnuqB2ga8Qm/sCVJS9ONnBECa9FxnB7uGcE7r7NIrKn9/PBuBtprfQWbysi+4tINaAL8CXwCdBNRA701tlfRBriirqd4VVDRUT2jxVLhE+AS8LDRSWsu8vv7iW3X3G3C30h/Lx3x8iDcfvQpDFLFCZVPAX0FpFZuHLYW+JdUVVzcWPr472hqwLcHATAcGCUiMzAzQGETQQu9OZJTiuyyelA8/CtdUXkBO/OaBcDo0VkYQmhtAO+9yqUTsVVa13tvfYFbohnHvCWqn6jqotwjfOHIrIA+Aioq6prcfczftvb1uu7sS8W4iafP/fWHVnMYi8Az3i/ezXvuVeAFV5MYS2AWUV6GCYNWfVYY4ohIqOAiar6cTlsqw/ujKRBZQ4sQUTkCWCuqo6NeG4UMEFVP/EvMpMKrEdhTPHuA/b2O4hkEJEs3MWELxd56XtLEgasR2GMMSYG61EYY4yJyhKFMcaYqCxRGGOMicoShTHGmKgsURhjjInq/wEoCSOGknQmLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_cm(pred_ae_ann_2h_01_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_ae_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_ae_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with spae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "sp_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=enc_train_x_spsam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  3 21:08:03 2019\n",
      "Train on 1091239 samples, validate on 272810 samples\n",
      "Epoch 1/200\n",
      "1091239/1091239 [==============================] - 30s 27us/step - loss: 0.1924 - acc: 0.9115 - val_loss: 0.0959 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09589, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 2/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0842 - acc: 0.9615 - val_loss: 0.1006 - val_acc: 0.9546\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.09589\n",
      "Epoch 3/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0679 - acc: 0.9682 - val_loss: 0.0553 - val_acc: 0.9733\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09589 to 0.05526, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 4/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0590 - acc: 0.9720 - val_loss: 0.0500 - val_acc: 0.9769\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.05526 to 0.05005, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 5/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0532 - acc: 0.9746 - val_loss: 0.0476 - val_acc: 0.9773\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05005 to 0.04756, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 6/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0493 - acc: 0.9762 - val_loss: 0.0479 - val_acc: 0.9771\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.04756\n",
      "Epoch 7/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0457 - acc: 0.9778 - val_loss: 0.0413 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04756 to 0.04132, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 8/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0429 - acc: 0.9794 - val_loss: 0.0379 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04132 to 0.03787, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 9/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0411 - acc: 0.9802 - val_loss: 0.0393 - val_acc: 0.9813\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03787\n",
      "Epoch 10/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0389 - acc: 0.9812 - val_loss: 0.0351 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03787 to 0.03511, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 11/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0368 - acc: 0.9824 - val_loss: 0.0350 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03511 to 0.03504, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 12/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0354 - acc: 0.9831 - val_loss: 0.0345 - val_acc: 0.9843\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03504 to 0.03448, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 13/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0340 - acc: 0.9839 - val_loss: 0.0405 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.03448\n",
      "Epoch 14/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0328 - acc: 0.9845 - val_loss: 0.0301 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03448 to 0.03005, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 15/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0314 - acc: 0.9852 - val_loss: 0.0348 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03005\n",
      "Epoch 16/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0305 - acc: 0.9857 - val_loss: 0.0301 - val_acc: 0.9871\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.03005\n",
      "Epoch 17/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0297 - acc: 0.9861 - val_loss: 0.0264 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03005 to 0.02637, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 18/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0285 - acc: 0.9867 - val_loss: 0.0286 - val_acc: 0.9877\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02637\n",
      "Epoch 19/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0277 - acc: 0.9871 - val_loss: 0.0250 - val_acc: 0.9885\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02637 to 0.02501, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 20/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0272 - acc: 0.9873 - val_loss: 0.0259 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.02501\n",
      "Epoch 21/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0267 - acc: 0.9877 - val_loss: 0.0279 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02501\n",
      "Epoch 22/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0259 - acc: 0.9881 - val_loss: 0.0224 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.02501 to 0.02238, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 23/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0255 - acc: 0.9882 - val_loss: 0.0262 - val_acc: 0.9884\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.02238\n",
      "Epoch 24/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0248 - acc: 0.9886 - val_loss: 0.0204 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.02238 to 0.02045, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 25/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0246 - acc: 0.9887 - val_loss: 0.0224 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.02045\n",
      "Epoch 26/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0241 - acc: 0.9888 - val_loss: 0.0249 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.02045\n",
      "Epoch 27/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0236 - acc: 0.9892 - val_loss: 0.0282 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.02045\n",
      "Epoch 28/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0232 - acc: 0.9893 - val_loss: 0.0232 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.02045\n",
      "Epoch 29/200\n",
      "1091239/1091239 [==============================] - 29s 27us/step - loss: 0.0233 - acc: 0.9894 - val_loss: 0.0224 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.02045\n",
      "Time elapsed (hh:mm:ss.ms) 0:14:06.826847\n"
     ]
    }
   ],
   "source": [
    "hist_sp_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ann_2h_unisoftsigbinlosadam_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                        ann = sp_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = enc_train_x_spsam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_sp_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_sp_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_sp_ann_2h_unisoftsigbinlosadam, './Figures/sp_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam = ann_predict(sp_ann_2h_unisoftsigbinlosadam,enc_test_x_spsam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_sp_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_sp_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=enc_train_x_asam\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=enc_test_x_spsam\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  3 21:22:10 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341012/341012 [==============================] - 9s 27us/step - loss: 0.3376 - acc: 0.8391\n",
      "Epoch 2/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.1428 - acc: 0.9386\n",
      "Epoch 3/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.1122 - acc: 0.9500\n",
      "Epoch 4/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0968 - acc: 0.9559\n",
      "Epoch 5/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0871 - acc: 0.9603\n",
      "Epoch 6/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0812 - acc: 0.9625\n",
      "Epoch 7/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0743 - acc: 0.9654\n",
      "Epoch 8/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0701 - acc: 0.9671\n",
      "Epoch 9/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0665 - acc: 0.9686\n",
      "Epoch 10/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0637 - acc: 0.9698\n",
      "Epoch 11/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0607 - acc: 0.9715\n",
      "Epoch 12/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0585 - acc: 0.9726\n",
      "Epoch 13/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0561 - acc: 0.9734\n",
      "Epoch 14/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0540 - acc: 0.9744\n",
      "Epoch 15/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0523 - acc: 0.9755\n",
      "Epoch 16/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0504 - acc: 0.9763\n",
      "Epoch 17/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0493 - acc: 0.9767\n",
      "Epoch 18/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0479 - acc: 0.9773\n",
      "Epoch 19/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0459 - acc: 0.9785\n",
      "Epoch 20/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0450 - acc: 0.9791\n",
      "Epoch 21/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0444 - acc: 0.9791\n",
      "Epoch 22/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0432 - acc: 0.9797\n",
      "Epoch 23/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0417 - acc: 0.9807\n",
      "Epoch 24/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0411 - acc: 0.9811\n",
      "Epoch 25/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0397 - acc: 0.9816\n",
      "Epoch 26/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0392 - acc: 0.9819\n",
      "Epoch 27/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0386 - acc: 0.9823\n",
      "Epoch 28/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0374 - acc: 0.9828\n",
      "Epoch 29/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0364 - acc: 0.9832\n",
      "Epoch 30/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0365 - acc: 0.9833\n",
      "Epoch 31/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0357 - acc: 0.9838\n",
      "Epoch 32/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0344 - acc: 0.9843\n",
      "Epoch 33/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0339 - acc: 0.9845\n",
      "Epoch 34/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0335 - acc: 0.9849\n",
      "Epoch 35/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0330 - acc: 0.9849\n",
      "Epoch 36/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0322 - acc: 0.9853\n",
      "Epoch 37/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0321 - acc: 0.9853\n",
      "Epoch 38/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0319 - acc: 0.9859\n",
      "Epoch 39/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0312 - acc: 0.9859\n",
      "Epoch 40/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0304 - acc: 0.9862\n",
      "Epoch 41/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0300 - acc: 0.9863\n",
      "Epoch 42/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0300 - acc: 0.9866\n",
      "Epoch 43/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0291 - acc: 0.9870\n",
      "Epoch 44/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0287 - acc: 0.9873\n",
      "Epoch 45/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0281 - acc: 0.9874\n",
      "Epoch 46/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0281 - acc: 0.9874\n",
      "Epoch 47/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0275 - acc: 0.9878\n",
      "Epoch 48/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0268 - acc: 0.9879\n",
      "Epoch 49/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0267 - acc: 0.9881\n",
      "Epoch 50/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0264 - acc: 0.9883\n",
      "Epoch 51/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0264 - acc: 0.9884\n",
      "Epoch 52/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0260 - acc: 0.9884\n",
      "Epoch 53/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0254 - acc: 0.9886\n",
      "Epoch 54/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0256 - acc: 0.9886\n",
      "Epoch 55/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0248 - acc: 0.9890\n",
      "Epoch 56/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0242 - acc: 0.9892\n",
      "Epoch 57/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0250 - acc: 0.9890\n",
      "Epoch 58/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0236 - acc: 0.9895\n",
      "Epoch 59/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0245 - acc: 0.9892\n",
      "Epoch 60/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0232 - acc: 0.9898\n",
      "Epoch 61/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0235 - acc: 0.9896\n",
      "Epoch 62/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0234 - acc: 0.9899\n",
      "Epoch 63/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0227 - acc: 0.9900\n",
      "Epoch 64/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0233 - acc: 0.9898\n",
      "Epoch 65/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0227 - acc: 0.9902\n",
      "Epoch 66/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0226 - acc: 0.9901\n",
      "Epoch 67/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0225 - acc: 0.9903\n",
      "Epoch 68/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0220 - acc: 0.9905\n",
      "Epoch 69/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0220 - acc: 0.9904\n",
      "Epoch 70/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0216 - acc: 0.9906\n",
      "Epoch 71/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0212 - acc: 0.9908\n",
      "Epoch 72/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0219 - acc: 0.9906\n",
      "Epoch 73/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0212 - acc: 0.9907\n",
      "Epoch 74/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0211 - acc: 0.9908\n",
      "Epoch 75/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0213 - acc: 0.9907\n",
      "Epoch 76/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0207 - acc: 0.9911\n",
      "Epoch 77/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0210 - acc: 0.9909\n",
      "Epoch 78/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0201 - acc: 0.9913\n",
      "Epoch 79/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0202 - acc: 0.9912\n",
      "Epoch 80/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0201 - acc: 0.9914\n",
      "Epoch 81/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0208 - acc: 0.9911\n",
      "Epoch 82/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0201 - acc: 0.9913\n",
      "Epoch 83/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0203 - acc: 0.9914\n",
      "Epoch 84/100\n",
      "341012/341012 [==============================] - 9s 25us/step - loss: 0.0204 - acc: 0.9913\n",
      "Epoch 85/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0195 - acc: 0.9915\n",
      "Epoch 86/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0203 - acc: 0.9915\n",
      "Epoch 87/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0194 - acc: 0.9916\n",
      "Epoch 88/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0200 - acc: 0.9914\n",
      "Epoch 89/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0193 - acc: 0.9916\n",
      "Epoch 90/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0191 - acc: 0.9918\n",
      "Epoch 91/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0199 - acc: 0.9916\n",
      "Epoch 92/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0189 - acc: 0.9920\n",
      "Epoch 93/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0195 - acc: 0.9917\n",
      "Epoch 94/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0186 - acc: 0.9920\n",
      "Epoch 95/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0194 - acc: 0.9918\n",
      "Epoch 96/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0188 - acc: 0.9920\n",
      "Epoch 97/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0187 - acc: 0.9920\n",
      "Epoch 98/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0188 - acc: 0.9920\n",
      "Epoch 99/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0190 - acc: 0.9919\n",
      "Epoch 100/100\n",
      "341012/341012 [==============================] - 8s 25us/step - loss: 0.0181 - acc: 0.9923\n",
      "85254/85254 [==============================] - 1s 8us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 10s 28us/step - loss: 0.3497 - acc: 0.8316\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.1429 - acc: 0.9379\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.1092 - acc: 0.9512\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0927 - acc: 0.9579\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0824 - acc: 0.9618\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0759 - acc: 0.9648\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0708 - acc: 0.9669\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0671 - acc: 0.9687\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0632 - acc: 0.9701\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0610 - acc: 0.9715\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0584 - acc: 0.9724\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0563 - acc: 0.9734\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0538 - acc: 0.9747\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0519 - acc: 0.9755\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0505 - acc: 0.9762\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0491 - acc: 0.9771\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0478 - acc: 0.9778\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0463 - acc: 0.9786\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0450 - acc: 0.9789\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0432 - acc: 0.9798\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0435 - acc: 0.9795\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0423 - acc: 0.9804\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0409 - acc: 0.9813\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0401 - acc: 0.9812\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0392 - acc: 0.9820\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0384 - acc: 0.9821\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0378 - acc: 0.9829\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0366 - acc: 0.9832\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0364 - acc: 0.9834\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0351 - acc: 0.9838\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0349 - acc: 0.9840\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0340 - acc: 0.9843\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0336 - acc: 0.9849\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0330 - acc: 0.9851\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0320 - acc: 0.9854\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0316 - acc: 0.9857\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0315 - acc: 0.9859\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0300 - acc: 0.9868\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0299 - acc: 0.9865\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0295 - acc: 0.9868\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0294 - acc: 0.9868\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0285 - acc: 0.9871\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0281 - acc: 0.9873\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0277 - acc: 0.9877\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0276 - acc: 0.9879\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0267 - acc: 0.9882\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0270 - acc: 0.9881\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0263 - acc: 0.9883\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0261 - acc: 0.9884\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0255 - acc: 0.9888\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0259 - acc: 0.9885\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0252 - acc: 0.9891\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0251 - acc: 0.9890\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0246 - acc: 0.9894\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0241 - acc: 0.9894\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0244 - acc: 0.9893\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0239 - acc: 0.9895\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0238 - acc: 0.9898\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0232 - acc: 0.9898\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0231 - acc: 0.9900\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0234 - acc: 0.9899\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0222 - acc: 0.9903\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0224 - acc: 0.9903\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0223 - acc: 0.9904\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0226 - acc: 0.9902\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0212 - acc: 0.9908\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0213 - acc: 0.9908\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0214 - acc: 0.9908\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0213 - acc: 0.9908\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0210 - acc: 0.9911\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0208 - acc: 0.9910\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0207 - acc: 0.9910\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0206 - acc: 0.9910\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0203 - acc: 0.9912\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0203 - acc: 0.9913\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0199 - acc: 0.9914\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0201 - acc: 0.9914\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0205 - acc: 0.9912\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0195 - acc: 0.9917\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0202 - acc: 0.9914\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0194 - acc: 0.9915\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0201 - acc: 0.9914\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0194 - acc: 0.9917\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0194 - acc: 0.9916\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0193 - acc: 0.9917\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0194 - acc: 0.9918\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0193 - acc: 0.9918\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0186 - acc: 0.9919\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0197 - acc: 0.9917\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0185 - acc: 0.9922\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0187 - acc: 0.9921\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0185 - acc: 0.9921\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0184 - acc: 0.9921\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0186 - acc: 0.9920\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0185 - acc: 0.9921\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0183 - acc: 0.9922\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0189 - acc: 0.9921\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0182 - acc: 0.9923\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0184 - acc: 0.9921\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0174 - acc: 0.9925\n",
      "85253/85253 [==============================] - 1s 9us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 10s 28us/step - loss: 0.3455 - acc: 0.8323\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.1431 - acc: 0.9372\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.1101 - acc: 0.9505\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0954 - acc: 0.9562\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0852 - acc: 0.9602\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0782 - acc: 0.9635\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0733 - acc: 0.9661\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0689 - acc: 0.9675\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0655 - acc: 0.9693\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0615 - acc: 0.9711\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0592 - acc: 0.9721\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0572 - acc: 0.9733\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0548 - acc: 0.9744\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0523 - acc: 0.9754\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0516 - acc: 0.9756\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0496 - acc: 0.9767\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0493 - acc: 0.9772\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0466 - acc: 0.9781\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0463 - acc: 0.9782\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0443 - acc: 0.9794\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0434 - acc: 0.9800\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0426 - acc: 0.9800\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0422 - acc: 0.9805\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0408 - acc: 0.9814\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0408 - acc: 0.9811\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0393 - acc: 0.9819\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0386 - acc: 0.9822\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0375 - acc: 0.9826\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0367 - acc: 0.9832\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0357 - acc: 0.9834\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0355 - acc: 0.9838\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0350 - acc: 0.9841\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0336 - acc: 0.9846\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0338 - acc: 0.9845\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0331 - acc: 0.9850\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0327 - acc: 0.9853\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0315 - acc: 0.9857\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0316 - acc: 0.9855\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0308 - acc: 0.9863\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0308 - acc: 0.9860\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0296 - acc: 0.9866\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0302 - acc: 0.9866\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0289 - acc: 0.9871\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0290 - acc: 0.9871\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0282 - acc: 0.9873\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0283 - acc: 0.9875\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0278 - acc: 0.9877\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0275 - acc: 0.9879\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0269 - acc: 0.9879\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0266 - acc: 0.9880\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0266 - acc: 0.9884\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0263 - acc: 0.9885\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0259 - acc: 0.9885\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0257 - acc: 0.9889\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0250 - acc: 0.9890\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0250 - acc: 0.9889\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0251 - acc: 0.9888\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0249 - acc: 0.9890\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0240 - acc: 0.9895\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0243 - acc: 0.9894\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0237 - acc: 0.9895\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0243 - acc: 0.9897\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0241 - acc: 0.9894\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0228 - acc: 0.9900\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0234 - acc: 0.9898\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0238 - acc: 0.9897\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0234 - acc: 0.9899\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0234 - acc: 0.9899\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0223 - acc: 0.9901\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0227 - acc: 0.9903\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0230 - acc: 0.9900\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0218 - acc: 0.9903\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0223 - acc: 0.9905\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0225 - acc: 0.9902\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0223 - acc: 0.9904\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0215 - acc: 0.9905\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0215 - acc: 0.9906\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0212 - acc: 0.9907\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0218 - acc: 0.9905\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0218 - acc: 0.9906\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0210 - acc: 0.9911\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0213 - acc: 0.9908\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0210 - acc: 0.9909\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0207 - acc: 0.9911\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0212 - acc: 0.9908\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0209 - acc: 0.9910\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0205 - acc: 0.9910\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0204 - acc: 0.9911\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0205 - acc: 0.9911\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0208 - acc: 0.9911\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0204 - acc: 0.9912\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0199 - acc: 0.9913\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0205 - acc: 0.9911\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0198 - acc: 0.9915\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0199 - acc: 0.9915\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0202 - acc: 0.9913\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0201 - acc: 0.9915\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0197 - acc: 0.9917\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0198 - acc: 0.9914\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0193 - acc: 0.9918\n",
      "85253/85253 [==============================] - 1s 10us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_43 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.3549 - acc: 0.8279\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.1457 - acc: 0.9363\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.1105 - acc: 0.9504\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0943 - acc: 0.9571\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0850 - acc: 0.9607\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0768 - acc: 0.9643\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0714 - acc: 0.9663\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0674 - acc: 0.9683\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0649 - acc: 0.9693\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0614 - acc: 0.9709\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0589 - acc: 0.9722\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0565 - acc: 0.9730\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0538 - acc: 0.9746\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0522 - acc: 0.9751\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0511 - acc: 0.9758\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0491 - acc: 0.9767\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0476 - acc: 0.9776\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0465 - acc: 0.9783\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0451 - acc: 0.9791\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0441 - acc: 0.9796\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0432 - acc: 0.9799\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0409 - acc: 0.9811\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0411 - acc: 0.9811\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0400 - acc: 0.9818\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0388 - acc: 0.9822\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0379 - acc: 0.9827\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0372 - acc: 0.9831\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0362 - acc: 0.9835\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0356 - acc: 0.9835\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0347 - acc: 0.9845\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0346 - acc: 0.9845\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0336 - acc: 0.9847\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0333 - acc: 0.9850\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0326 - acc: 0.9854\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0319 - acc: 0.9858\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0316 - acc: 0.9859\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0310 - acc: 0.9861\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0308 - acc: 0.9865\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0297 - acc: 0.9869\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0295 - acc: 0.9868\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0293 - acc: 0.9872\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0289 - acc: 0.9870\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0284 - acc: 0.9875\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0281 - acc: 0.9876\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0278 - acc: 0.9877\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0274 - acc: 0.9881\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0273 - acc: 0.9880\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0266 - acc: 0.9885\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0267 - acc: 0.9884\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0266 - acc: 0.9885\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0260 - acc: 0.9887\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0258 - acc: 0.9889\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0254 - acc: 0.9889\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0249 - acc: 0.9891\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0252 - acc: 0.9890\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0239 - acc: 0.9896\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0245 - acc: 0.9891\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0240 - acc: 0.9895\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0240 - acc: 0.9895\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0236 - acc: 0.9897\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0234 - acc: 0.9899\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0229 - acc: 0.9902\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0231 - acc: 0.9902\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0228 - acc: 0.9901\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0226 - acc: 0.9903\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0233 - acc: 0.9899\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0219 - acc: 0.9905\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0223 - acc: 0.9905\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0213 - acc: 0.9908\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0218 - acc: 0.9907\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0222 - acc: 0.9905\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0215 - acc: 0.9908\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0213 - acc: 0.9908\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0215 - acc: 0.9907\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0210 - acc: 0.9911\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0208 - acc: 0.9911\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0211 - acc: 0.9911\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0214 - acc: 0.9908\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0205 - acc: 0.9912\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0208 - acc: 0.9910\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0201 - acc: 0.9913\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0207 - acc: 0.9912\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0206 - acc: 0.9912\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0201 - acc: 0.9914\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0200 - acc: 0.9914\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0202 - acc: 0.9914\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0199 - acc: 0.9916\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0201 - acc: 0.9914\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0197 - acc: 0.9916\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0197 - acc: 0.9915\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0194 - acc: 0.9917\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0194 - acc: 0.9917\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0189 - acc: 0.9918\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0194 - acc: 0.9917\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0191 - acc: 0.9919\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0193 - acc: 0.9918\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0190 - acc: 0.9919\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0182 - acc: 0.9922\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0192 - acc: 0.9919\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0183 - acc: 0.9922\n",
      "85253/85253 [==============================] - 1s 10us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_47 (Dense)             (None, 120)               9720      \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 26,371\n",
      "Trainable params: 26,251\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.3568 - acc: 0.8282\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.1535 - acc: 0.9338\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.1170 - acc: 0.9475\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.1003 - acc: 0.9542\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0902 - acc: 0.9583\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0832 - acc: 0.9611\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0782 - acc: 0.9635\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0725 - acc: 0.9660\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0687 - acc: 0.9676\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0654 - acc: 0.9694\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0624 - acc: 0.9709\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0602 - acc: 0.9715\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0578 - acc: 0.9729\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0559 - acc: 0.9736\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0540 - acc: 0.9745\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0522 - acc: 0.9753\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0517 - acc: 0.9756\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0500 - acc: 0.9764\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0484 - acc: 0.9769\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0472 - acc: 0.9779\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0461 - acc: 0.9782\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0451 - acc: 0.9786\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0440 - acc: 0.9795\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0434 - acc: 0.9798\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0416 - acc: 0.9806\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0416 - acc: 0.9809\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0404 - acc: 0.9810\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0388 - acc: 0.9819\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0387 - acc: 0.9822\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0386 - acc: 0.9823\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0372 - acc: 0.9829\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0372 - acc: 0.9827\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0364 - acc: 0.9832\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0357 - acc: 0.9836\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0347 - acc: 0.9841\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0348 - acc: 0.9841\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0339 - acc: 0.9844\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0337 - acc: 0.9847\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0337 - acc: 0.9847\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0337 - acc: 0.9848\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0319 - acc: 0.9855\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0318 - acc: 0.9857\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0317 - acc: 0.9857\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0310 - acc: 0.9860\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0309 - acc: 0.9861\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0302 - acc: 0.9862\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0298 - acc: 0.9866\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0302 - acc: 0.9864\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0294 - acc: 0.9867\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0293 - acc: 0.9870\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0291 - acc: 0.9870\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0286 - acc: 0.9871\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0283 - acc: 0.9871\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0283 - acc: 0.9874\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0277 - acc: 0.9877\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0278 - acc: 0.9878\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0271 - acc: 0.9878\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0276 - acc: 0.9876\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0266 - acc: 0.9881\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0265 - acc: 0.9883\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0263 - acc: 0.9883\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0258 - acc: 0.9885\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0262 - acc: 0.9885\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0255 - acc: 0.9888\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0255 - acc: 0.9888\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0254 - acc: 0.9888\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0253 - acc: 0.9889\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0253 - acc: 0.9889\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0252 - acc: 0.9890\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0244 - acc: 0.9893\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0243 - acc: 0.9892\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0236 - acc: 0.9898\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0241 - acc: 0.9896\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0239 - acc: 0.9896\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0237 - acc: 0.9895\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0230 - acc: 0.9898\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0239 - acc: 0.9896\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0230 - acc: 0.9900\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0229 - acc: 0.9902\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0229 - acc: 0.9900\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0226 - acc: 0.9901\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0233 - acc: 0.9899\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0227 - acc: 0.9898\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0225 - acc: 0.9904\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0222 - acc: 0.9904\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0219 - acc: 0.9906\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0214 - acc: 0.9907\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0224 - acc: 0.9904\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0215 - acc: 0.9905\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0220 - acc: 0.9905\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0216 - acc: 0.9907\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0217 - acc: 0.9909\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0217 - acc: 0.9907\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0215 - acc: 0.9907\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0207 - acc: 0.9910\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0214 - acc: 0.9907\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0211 - acc: 0.9909\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0208 - acc: 0.9909\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 9s 25us/step - loss: 0.0211 - acc: 0.9909\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 9s 26us/step - loss: 0.0210 - acc: 0.9910\n",
      "85253/85253 [==============================] - 1s 11us/step\n",
      "Time elapsed (hh:mm:ss.ms) 1:12:17.601648\n",
      "Overall accuracy of Neural Network model: 0.9912519412761046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 72.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9909    0.9916    0.9913    213688\n",
      "           1     0.9916    0.9909    0.9912    212578\n",
      "\n",
      "   micro avg     0.9913    0.9913    0.9913    426266\n",
      "   macro avg     0.9913    0.9913    0.9913    426266\n",
      "weighted avg     0.9913    0.9913    0.9913    426266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_sp_ann_2h_prob_unisoftsigbinlosadam,pred_sp_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_cm(pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_sp_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_sp_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with no encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 31,171\n",
      "Trainable params: 31,051\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nodr_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=train_x,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  3 22:34:29 2019\n",
      "Train on 1091239 samples, validate on 272810 samples\n",
      "Epoch 1/200\n",
      "1091239/1091239 [==============================] - 39s 36us/step - loss: 0.1085 - acc: 0.9494 - val_loss: 0.0594 - val_acc: 0.9722\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.05936, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 2/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0526 - acc: 0.9749 - val_loss: 0.0420 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.05936 to 0.04202, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 3/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0407 - acc: 0.9807 - val_loss: 0.0307 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04202 to 0.03071, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 4/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0338 - acc: 0.9842 - val_loss: 0.0278 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03071 to 0.02778, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 5/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0286 - acc: 0.9870 - val_loss: 0.0237 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02778 to 0.02370, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 6/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0251 - acc: 0.9888 - val_loss: 0.0200 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02370 to 0.02002, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 7/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0226 - acc: 0.9899 - val_loss: 0.0178 - val_acc: 0.9927\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02002 to 0.01782, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 8/200\n",
      "1091239/1091239 [==============================] - 39s 35us/step - loss: 0.0199 - acc: 0.9912 - val_loss: 0.0227 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01782\n",
      "Epoch 9/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0182 - acc: 0.9920 - val_loss: 0.0143 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.01782 to 0.01431, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 10/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0168 - acc: 0.9928 - val_loss: 0.0149 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01431\n",
      "Epoch 11/200\n",
      "1091239/1091239 [==============================] - 39s 35us/step - loss: 0.0158 - acc: 0.9932 - val_loss: 0.0132 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01431 to 0.01318, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 12/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0147 - acc: 0.9936 - val_loss: 0.0135 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01318\n",
      "Epoch 13/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0142 - acc: 0.9940 - val_loss: 0.0132 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01318 to 0.01316, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 14/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0136 - acc: 0.9942 - val_loss: 0.0143 - val_acc: 0.9943\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01316\n",
      "Epoch 15/200\n",
      "1091239/1091239 [==============================] - 39s 35us/step - loss: 0.0131 - acc: 0.9945 - val_loss: 0.0134 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01316\n",
      "Epoch 16/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0127 - acc: 0.9947 - val_loss: 0.0136 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01316\n",
      "Epoch 17/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0122 - acc: 0.9949 - val_loss: 0.0105 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01316 to 0.01054, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 18/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0120 - acc: 0.9950 - val_loss: 0.0115 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01054\n",
      "Epoch 19/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0115 - acc: 0.9952 - val_loss: 0.0090 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01054 to 0.00897, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 20/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0113 - acc: 0.9954 - val_loss: 0.0112 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00897\n",
      "Epoch 21/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0107 - acc: 0.9955 - val_loss: 0.0085 - val_acc: 0.9964\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.00897 to 0.00852, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 22/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0105 - acc: 0.9956 - val_loss: 0.0091 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00852\n",
      "Epoch 23/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0105 - acc: 0.9956 - val_loss: 0.0080 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00852 to 0.00805, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 24/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0101 - acc: 0.9959 - val_loss: 0.0091 - val_acc: 0.9963\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00805\n",
      "Epoch 25/200\n",
      "1091239/1091239 [==============================] - 39s 35us/step - loss: 0.0102 - acc: 0.9959 - val_loss: 0.0094 - val_acc: 0.9961\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00805\n",
      "Epoch 26/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0100 - acc: 0.9959 - val_loss: 0.0086 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.00805\n",
      "Epoch 27/200\n",
      "1091239/1091239 [==============================] - 38s 35us/step - loss: 0.0096 - acc: 0.9961 - val_loss: 0.0077 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00805 to 0.00769, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 28/200\n",
      "1091239/1091239 [==============================] - 39s 36us/step - loss: 0.0094 - acc: 0.9961 - val_loss: 0.0075 - val_acc: 0.9969\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00769 to 0.00752, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 29/200\n",
      "1091239/1091239 [==============================] - 40s 36us/step - loss: 0.0094 - acc: 0.9962 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00752 to 0.00700, saving model to ./H5files/ann_2h_unisoftsigbinlosadam_redds50bal.h5\n",
      "Epoch 30/200\n",
      "1091239/1091239 [==============================] - 39s 36us/step - loss: 0.0093 - acc: 0.9962 - val_loss: 0.0080 - val_acc: 0.9968\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00700\n",
      "Epoch 31/200\n",
      "1091239/1091239 [==============================] - 39s 36us/step - loss: 0.0092 - acc: 0.9963 - val_loss: 0.0078 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00700\n",
      "Epoch 32/200\n",
      "1091239/1091239 [==============================] - 39s 36us/step - loss: 0.0090 - acc: 0.9963 - val_loss: 0.0079 - val_acc: 0.9966\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00700\n",
      "Epoch 33/200\n",
      "1091239/1091239 [==============================] - 39s 36us/step - loss: 0.0090 - acc: 0.9963 - val_loss: 0.0070 - val_acc: 0.9971\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00700\n",
      "Epoch 34/200\n",
      "1091239/1091239 [==============================] - 39s 36us/step - loss: 0.0089 - acc: 0.9963 - val_loss: 0.0116 - val_acc: 0.9960\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00700\n",
      "Time elapsed (hh:mm:ss.ms) 0:21:57.121525\n"
     ]
    }
   ],
   "source": [
    "hist_nodr_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ann_2h_unisoftsigbinlosadam_redds\"+str(dsnum)+\"bal.h5\",\n",
    "                                        ann = nodr_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = train_x,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_nodr_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_nodr_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_nodr_ann_2h_unisoftsigbinlosadam, './Figures/nodr_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_nodr_ann_2h_prob_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam = ann_predict(nodr_ann_2h_unisoftsigbinlosadam,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_nodr_ann_2h_01_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_nodr_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_nodr_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=train_x\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=test_x\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jul  4 13:25:12 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 31,171\n",
      "Trainable params: 31,051\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341012/341012 [==============================] - 15s 45us/step - loss: 0.1852 - acc: 0.9145\n",
      "Epoch 2/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0837 - acc: 0.9609\n",
      "Epoch 3/100\n",
      "341012/341012 [==============================] - 12s 37us/step - loss: 0.0682 - acc: 0.9680\n",
      "Epoch 4/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0571 - acc: 0.9729\n",
      "Epoch 5/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0501 - acc: 0.9766\n",
      "Epoch 6/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0443 - acc: 0.9793\n",
      "Epoch 7/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0400 - acc: 0.9815\n",
      "Epoch 8/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0365 - acc: 0.9836\n",
      "Epoch 9/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0332 - acc: 0.9850\n",
      "Epoch 10/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0313 - acc: 0.9860\n",
      "Epoch 11/100\n",
      "341012/341012 [==============================] - 13s 39us/step - loss: 0.0295 - acc: 0.9871\n",
      "Epoch 12/100\n",
      "341012/341012 [==============================] - 13s 38us/step - loss: 0.0268 - acc: 0.9881\n",
      "Epoch 13/100\n",
      "341012/341012 [==============================] - 12s 37us/step - loss: 0.0261 - acc: 0.9887\n",
      "Epoch 14/100\n",
      "341012/341012 [==============================] - 12s 37us/step - loss: 0.0244 - acc: 0.9893\n",
      "Epoch 15/100\n",
      "341012/341012 [==============================] - 12s 37us/step - loss: 0.0233 - acc: 0.9899\n",
      "Epoch 16/100\n",
      "341012/341012 [==============================] - 13s 37us/step - loss: 0.0223 - acc: 0.9904\n",
      "Epoch 17/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0212 - acc: 0.9909\n",
      "Epoch 18/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0212 - acc: 0.9908\n",
      "Epoch 19/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0192 - acc: 0.9917\n",
      "Epoch 20/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0191 - acc: 0.9918\n",
      "Epoch 21/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0187 - acc: 0.9919\n",
      "Epoch 22/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0180 - acc: 0.9922\n",
      "Epoch 23/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0170 - acc: 0.9926\n",
      "Epoch 24/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0165 - acc: 0.9927\n",
      "Epoch 25/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0162 - acc: 0.9931\n",
      "Epoch 26/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0160 - acc: 0.9932\n",
      "Epoch 27/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0158 - acc: 0.9934\n",
      "Epoch 28/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0149 - acc: 0.9937\n",
      "Epoch 29/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0152 - acc: 0.9937\n",
      "Epoch 30/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0141 - acc: 0.9940\n",
      "Epoch 31/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0145 - acc: 0.9939\n",
      "Epoch 32/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0139 - acc: 0.9943\n",
      "Epoch 33/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0135 - acc: 0.9943\n",
      "Epoch 34/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0137 - acc: 0.9943\n",
      "Epoch 35/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0125 - acc: 0.9948\n",
      "Epoch 36/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0130 - acc: 0.9946\n",
      "Epoch 37/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0132 - acc: 0.9947\n",
      "Epoch 38/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0122 - acc: 0.9949\n",
      "Epoch 39/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0119 - acc: 0.9949\n",
      "Epoch 40/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0122 - acc: 0.9950\n",
      "Epoch 41/100\n",
      "341012/341012 [==============================] - 12s 34us/step - loss: 0.0116 - acc: 0.9950\n",
      "Epoch 42/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0117 - acc: 0.9951\n",
      "Epoch 43/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0117 - acc: 0.9951\n",
      "Epoch 44/100\n",
      "341012/341012 [==============================] - 12s 34us/step - loss: 0.0115 - acc: 0.9952\n",
      "Epoch 45/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0114 - acc: 0.9954\n",
      "Epoch 46/100\n",
      "341012/341012 [==============================] - 12s 34us/step - loss: 0.0112 - acc: 0.9954\n",
      "Epoch 47/100\n",
      "341012/341012 [==============================] - 12s 34us/step - loss: 0.0115 - acc: 0.9953\n",
      "Epoch 48/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0111 - acc: 0.9954\n",
      "Epoch 49/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0108 - acc: 0.9956\n",
      "Epoch 50/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0104 - acc: 0.9957\n",
      "Epoch 51/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0112 - acc: 0.9953\n",
      "Epoch 52/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0106 - acc: 0.9956\n",
      "Epoch 53/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0106 - acc: 0.9957\n",
      "Epoch 54/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0102 - acc: 0.9959\n",
      "Epoch 55/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0100 - acc: 0.9958\n",
      "Epoch 56/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0103 - acc: 0.9958\n",
      "Epoch 57/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0104 - acc: 0.9957\n",
      "Epoch 58/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0097 - acc: 0.9960\n",
      "Epoch 59/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0097 - acc: 0.9960\n",
      "Epoch 60/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0096 - acc: 0.9961\n",
      "Epoch 61/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0096 - acc: 0.9959\n",
      "Epoch 62/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0101 - acc: 0.9959\n",
      "Epoch 63/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0099 - acc: 0.9959\n",
      "Epoch 64/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0091 - acc: 0.9961\n",
      "Epoch 65/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0095 - acc: 0.9961\n",
      "Epoch 66/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0092 - acc: 0.9962\n",
      "Epoch 67/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0098 - acc: 0.9960\n",
      "Epoch 68/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0089 - acc: 0.9964\n",
      "Epoch 69/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0092 - acc: 0.9962\n",
      "Epoch 70/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0090 - acc: 0.9962\n",
      "Epoch 71/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0093 - acc: 0.9961\n",
      "Epoch 72/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0087 - acc: 0.9964\n",
      "Epoch 73/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0085 - acc: 0.9965\n",
      "Epoch 74/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0088 - acc: 0.9963\n",
      "Epoch 75/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0087 - acc: 0.9964\n",
      "Epoch 76/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0087 - acc: 0.9965\n",
      "Epoch 77/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0081 - acc: 0.9966\n",
      "Epoch 78/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0084 - acc: 0.9966\n",
      "Epoch 79/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0087 - acc: 0.9964\n",
      "Epoch 80/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0084 - acc: 0.9966\n",
      "Epoch 81/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0091 - acc: 0.9964\n",
      "Epoch 82/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0083 - acc: 0.9966\n",
      "Epoch 83/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0084 - acc: 0.9966\n",
      "Epoch 84/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0085 - acc: 0.9966\n",
      "Epoch 85/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0076 - acc: 0.9970\n",
      "Epoch 86/100\n",
      "341012/341012 [==============================] - 12s 36us/step - loss: 0.0089 - acc: 0.9964\n",
      "Epoch 87/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0085 - acc: 0.9967\n",
      "Epoch 88/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0087 - acc: 0.9965\n",
      "Epoch 89/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0085 - acc: 0.9967\n",
      "Epoch 90/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0080 - acc: 0.9966\n",
      "Epoch 91/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0085 - acc: 0.9965\n",
      "Epoch 92/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0079 - acc: 0.9967\n",
      "Epoch 93/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0081 - acc: 0.9967\n",
      "Epoch 94/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0083 - acc: 0.9967\n",
      "Epoch 95/100\n",
      "341012/341012 [==============================] - 12s 35us/step - loss: 0.0077 - acc: 0.9967\n",
      "Epoch 96/100\n",
      "341012/341012 [==============================] - 13s 38us/step - loss: 0.0081 - acc: 0.9967\n",
      "Epoch 97/100\n",
      "341012/341012 [==============================] - 11s 32us/step - loss: 0.0080 - acc: 0.9968\n",
      "Epoch 98/100\n",
      "341012/341012 [==============================] - 10s 29us/step - loss: 0.0075 - acc: 0.9969\n",
      "Epoch 99/100\n",
      "341012/341012 [==============================] - 10s 29us/step - loss: 0.0084 - acc: 0.9967\n",
      "Epoch 100/100\n",
      "341012/341012 [==============================] - 10s 28us/step - loss: 0.0080 - acc: 0.9969\n",
      "85254/85254 [==============================] - 1s 15us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_79 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 31,171\n",
      "Trainable params: 31,051\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.1820 - acc: 0.9157\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0802 - acc: 0.9628\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0655 - acc: 0.9693\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 10s 28us/step - loss: 0.0566 - acc: 0.9733\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 10s 28us/step - loss: 0.0502 - acc: 0.9764\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0456 - acc: 0.9784\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0424 - acc: 0.9801\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0391 - acc: 0.9818\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0363 - acc: 0.9830\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0340 - acc: 0.9843\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 10s 28us/step - loss: 0.0321 - acc: 0.9856\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 10s 28us/step - loss: 0.0295 - acc: 0.9867\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0280 - acc: 0.9873\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0267 - acc: 0.9881\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0253 - acc: 0.9887\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0241 - acc: 0.9894\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0234 - acc: 0.9897\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0224 - acc: 0.9902\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0216 - acc: 0.9903\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0207 - acc: 0.9908\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0198 - acc: 0.9914\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0196 - acc: 0.9916\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0193 - acc: 0.9915\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0180 - acc: 0.9922\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 10s 28us/step - loss: 0.0179 - acc: 0.9923\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0171 - acc: 0.9926\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 11s 31us/step - loss: 0.0174 - acc: 0.9925\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 13s 38us/step - loss: 0.0159 - acc: 0.9932\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 13s 38us/step - loss: 0.0158 - acc: 0.9933\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0155 - acc: 0.9934\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0155 - acc: 0.9935\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0149 - acc: 0.9936\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0145 - acc: 0.9939\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0145 - acc: 0.9936\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0137 - acc: 0.9941\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0138 - acc: 0.9941\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0141 - acc: 0.9944\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0132 - acc: 0.9944\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0132 - acc: 0.9945\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0125 - acc: 0.9948\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0127 - acc: 0.9946\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0124 - acc: 0.9948\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0125 - acc: 0.9948\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0117 - acc: 0.9950\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0120 - acc: 0.9950\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0119 - acc: 0.9950\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0118 - acc: 0.9950\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0118 - acc: 0.9950\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0115 - acc: 0.9952\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0112 - acc: 0.9952\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0112 - acc: 0.9954\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0106 - acc: 0.9955\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0110 - acc: 0.9955\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0104 - acc: 0.9956\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0109 - acc: 0.9955\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0106 - acc: 0.9956\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0100 - acc: 0.9960\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0102 - acc: 0.9959\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0109 - acc: 0.9956\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0105 - acc: 0.9957\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0099 - acc: 0.9960\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0104 - acc: 0.9958\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0100 - acc: 0.9959\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0097 - acc: 0.9961\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0099 - acc: 0.9961\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0092 - acc: 0.9961\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0100 - acc: 0.9961\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0096 - acc: 0.9961\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0097 - acc: 0.9960\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0094 - acc: 0.9962\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0095 - acc: 0.9960\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0095 - acc: 0.9962\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0094 - acc: 0.9961\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0090 - acc: 0.9963\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0095 - acc: 0.9962\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0089 - acc: 0.9964\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0092 - acc: 0.9965\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0092 - acc: 0.9964\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0088 - acc: 0.9964\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0084 - acc: 0.9966\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0093 - acc: 0.9963\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0084 - acc: 0.9965\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0087 - acc: 0.9964\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0089 - acc: 0.9965\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0084 - acc: 0.9966\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0091 - acc: 0.9963\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0083 - acc: 0.9967\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0084 - acc: 0.9966\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0085 - acc: 0.9965\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0086 - acc: 0.9964\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0086 - acc: 0.9965\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0085 - acc: 0.9966\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0082 - acc: 0.9967\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0091 - acc: 0.9964\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0085 - acc: 0.9966\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 12s 34us/step - loss: 0.0082 - acc: 0.9968\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0084 - acc: 0.9967\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0087 - acc: 0.9965\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0083 - acc: 0.9967\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0077 - acc: 0.9968\n",
      "85253/85253 [==============================] - 1s 17us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_83 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 31,171\n",
      "Trainable params: 31,051\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 14s 42us/step - loss: 0.1843 - acc: 0.9148\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0828 - acc: 0.9610\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0678 - acc: 0.9679\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0584 - acc: 0.9719\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 13s 38us/step - loss: 0.0519 - acc: 0.9750\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 13s 38us/step - loss: 0.0473 - acc: 0.9774\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0447 - acc: 0.9787\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 10s 30us/step - loss: 0.0406 - acc: 0.9807\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0379 - acc: 0.9819\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 10s 30us/step - loss: 0.0359 - acc: 0.9833\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0337 - acc: 0.9844\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0314 - acc: 0.9856\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0293 - acc: 0.9867\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0278 - acc: 0.9875\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0260 - acc: 0.9884\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 10s 30us/step - loss: 0.0247 - acc: 0.9891\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0232 - acc: 0.9898\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0220 - acc: 0.9905\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0215 - acc: 0.9907\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0207 - acc: 0.9911\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0200 - acc: 0.9913\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0191 - acc: 0.9918\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0185 - acc: 0.9921\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0178 - acc: 0.9925\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0177 - acc: 0.9925\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0169 - acc: 0.9929\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0165 - acc: 0.9929\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0160 - acc: 0.9932\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0157 - acc: 0.9934\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0151 - acc: 0.9937\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0146 - acc: 0.9938\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0149 - acc: 0.9938\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0140 - acc: 0.9941\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0135 - acc: 0.9943\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0132 - acc: 0.9946\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0133 - acc: 0.9945\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0126 - acc: 0.9948\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0125 - acc: 0.9947\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0125 - acc: 0.9950\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0125 - acc: 0.9949\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0119 - acc: 0.9950\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0121 - acc: 0.9950\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0118 - acc: 0.9952\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0114 - acc: 0.9954\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0118 - acc: 0.9953\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 11s 31us/step - loss: 0.0111 - acc: 0.9955\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 10s 30us/step - loss: 0.0118 - acc: 0.9953\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0109 - acc: 0.9958\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0118 - acc: 0.9954\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0105 - acc: 0.9957\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0103 - acc: 0.9959\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0106 - acc: 0.9957\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0100 - acc: 0.9960\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0105 - acc: 0.9958\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0100 - acc: 0.9961\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0101 - acc: 0.9959\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0101 - acc: 0.9959\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0096 - acc: 0.9961\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0102 - acc: 0.9960\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0098 - acc: 0.9959\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0094 - acc: 0.9963\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0098 - acc: 0.9960\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0097 - acc: 0.9961\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0096 - acc: 0.9962\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0092 - acc: 0.9964\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0093 - acc: 0.9963\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0094 - acc: 0.9962\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0094 - acc: 0.9963\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0089 - acc: 0.9964\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0087 - acc: 0.9966\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0091 - acc: 0.9963\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0092 - acc: 0.9964\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0091 - acc: 0.9965\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0093 - acc: 0.9964\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0093 - acc: 0.9964\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0093 - acc: 0.9964\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0089 - acc: 0.9966\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0087 - acc: 0.9966\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0094 - acc: 0.9965\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0085 - acc: 0.9968\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0084 - acc: 0.9968\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0091 - acc: 0.9964\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0090 - acc: 0.9965\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0084 - acc: 0.9967\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0092 - acc: 0.9966\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0086 - acc: 0.9966\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0081 - acc: 0.9968\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0088 - acc: 0.9965\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 12s 37us/step - loss: 0.0086 - acc: 0.9967\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0085 - acc: 0.9967\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 13s 39us/step - loss: 0.0082 - acc: 0.9967\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0085 - acc: 0.9967\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0085 - acc: 0.9967\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0084 - acc: 0.9967\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0084 - acc: 0.9966\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0080 - acc: 0.9968\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0079 - acc: 0.9968\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0080 - acc: 0.9968\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0085 - acc: 0.9966\n",
      "85253/85253 [==============================] - 2s 18us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 31,171\n",
      "Trainable params: 31,051\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 14s 41us/step - loss: 0.1836 - acc: 0.9146\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0834 - acc: 0.9611\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0679 - acc: 0.9680\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0585 - acc: 0.9720\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0518 - acc: 0.9750\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0471 - acc: 0.9776\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0428 - acc: 0.9798\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0393 - acc: 0.9815\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0366 - acc: 0.9830\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0349 - acc: 0.9840\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0323 - acc: 0.9852\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0307 - acc: 0.9858\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0291 - acc: 0.9867\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0278 - acc: 0.9874\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0267 - acc: 0.9879\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0254 - acc: 0.9885\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0238 - acc: 0.9894\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0230 - acc: 0.9900\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0221 - acc: 0.9903\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0211 - acc: 0.9906\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0205 - acc: 0.9911\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0195 - acc: 0.9916\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0194 - acc: 0.9915\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0190 - acc: 0.9917\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0179 - acc: 0.9923\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0173 - acc: 0.9925\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0170 - acc: 0.9926\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0169 - acc: 0.9927\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0164 - acc: 0.9929\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0159 - acc: 0.9933\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0154 - acc: 0.9935\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0147 - acc: 0.9939\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0148 - acc: 0.9937\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0141 - acc: 0.9939\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0141 - acc: 0.9941\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0138 - acc: 0.9941\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0131 - acc: 0.9946\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0134 - acc: 0.9945\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0132 - acc: 0.9945\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0132 - acc: 0.9946\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0125 - acc: 0.9948\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0125 - acc: 0.9950\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0119 - acc: 0.9950\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0128 - acc: 0.9948\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0116 - acc: 0.9953\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0121 - acc: 0.9950\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0117 - acc: 0.9951\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0117 - acc: 0.9952\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0109 - acc: 0.9955\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0109 - acc: 0.9955\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0112 - acc: 0.9954\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0112 - acc: 0.9955\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0114 - acc: 0.9954\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0110 - acc: 0.9955\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0105 - acc: 0.9957\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0106 - acc: 0.9957\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0102 - acc: 0.9958\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0105 - acc: 0.9957\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0105 - acc: 0.9957\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0100 - acc: 0.9958\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0104 - acc: 0.9958\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0100 - acc: 0.9959\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0100 - acc: 0.9960\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0101 - acc: 0.9959\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0099 - acc: 0.9960\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0101 - acc: 0.9958\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0101 - acc: 0.9959\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0095 - acc: 0.9962\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0096 - acc: 0.9962\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0098 - acc: 0.9962\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0091 - acc: 0.9962\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0097 - acc: 0.9961\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0093 - acc: 0.9962\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0091 - acc: 0.9963\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0096 - acc: 0.9962\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0094 - acc: 0.9961\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0091 - acc: 0.9963\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0094 - acc: 0.9962\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0093 - acc: 0.9962\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0091 - acc: 0.9963\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0094 - acc: 0.9963\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0088 - acc: 0.9965\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0091 - acc: 0.9964\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0088 - acc: 0.9964\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0089 - acc: 0.9964\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0085 - acc: 0.9965\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0092 - acc: 0.9963\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0092 - acc: 0.9963\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0088 - acc: 0.9964\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0086 - acc: 0.9966\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0090 - acc: 0.9966\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0086 - acc: 0.9965\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0090 - acc: 0.9964\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0088 - acc: 0.9965\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0080 - acc: 0.9967\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0089 - acc: 0.9965\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0082 - acc: 0.9969\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0087 - acc: 0.9967\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0095 - acc: 0.9965\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0078 - acc: 0.9969\n",
      "85253/85253 [==============================] - 1s 16us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_91 (Dense)             (None, 120)               14520     \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 90)                10890     \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 60)                5460      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 60)                240       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 1)                 61        \n",
      "=================================================================\n",
      "Total params: 31,171\n",
      "Trainable params: 31,051\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.1847 - acc: 0.9141\n",
      "Epoch 2/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0829 - acc: 0.9611\n",
      "Epoch 3/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0691 - acc: 0.9673\n",
      "Epoch 4/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0599 - acc: 0.9719\n",
      "Epoch 5/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0519 - acc: 0.9755\n",
      "Epoch 6/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0471 - acc: 0.9778\n",
      "Epoch 7/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0434 - acc: 0.9796\n",
      "Epoch 8/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0398 - acc: 0.9813\n",
      "Epoch 9/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0361 - acc: 0.9834\n",
      "Epoch 10/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0333 - acc: 0.9847\n",
      "Epoch 11/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0311 - acc: 0.9859\n",
      "Epoch 12/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0299 - acc: 0.9865\n",
      "Epoch 13/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0279 - acc: 0.9874\n",
      "Epoch 14/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0269 - acc: 0.9881\n",
      "Epoch 15/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0250 - acc: 0.9889\n",
      "Epoch 16/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0240 - acc: 0.9894\n",
      "Epoch 17/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0228 - acc: 0.9900\n",
      "Epoch 18/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0212 - acc: 0.9906\n",
      "Epoch 19/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0209 - acc: 0.9910\n",
      "Epoch 20/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0202 - acc: 0.9913\n",
      "Epoch 21/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0189 - acc: 0.9920\n",
      "Epoch 22/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0182 - acc: 0.9924\n",
      "Epoch 23/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0181 - acc: 0.9923\n",
      "Epoch 24/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0174 - acc: 0.9927\n",
      "Epoch 25/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0170 - acc: 0.9929\n",
      "Epoch 26/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0158 - acc: 0.9934\n",
      "Epoch 27/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0155 - acc: 0.9935\n",
      "Epoch 28/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0151 - acc: 0.9936\n",
      "Epoch 29/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0146 - acc: 0.9937\n",
      "Epoch 30/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0147 - acc: 0.9939\n",
      "Epoch 31/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0141 - acc: 0.9942\n",
      "Epoch 32/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0138 - acc: 0.9944\n",
      "Epoch 33/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0133 - acc: 0.9944\n",
      "Epoch 34/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0133 - acc: 0.9944\n",
      "Epoch 35/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0129 - acc: 0.9947\n",
      "Epoch 36/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0130 - acc: 0.9946\n",
      "Epoch 37/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0125 - acc: 0.9948\n",
      "Epoch 38/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0123 - acc: 0.9949\n",
      "Epoch 39/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0119 - acc: 0.9951\n",
      "Epoch 40/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0121 - acc: 0.9950\n",
      "Epoch 41/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0116 - acc: 0.9952\n",
      "Epoch 42/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0113 - acc: 0.9954\n",
      "Epoch 43/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0116 - acc: 0.9952\n",
      "Epoch 44/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0113 - acc: 0.9952\n",
      "Epoch 45/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0108 - acc: 0.9955\n",
      "Epoch 46/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0108 - acc: 0.9956\n",
      "Epoch 47/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0110 - acc: 0.9956\n",
      "Epoch 48/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0106 - acc: 0.9957\n",
      "Epoch 49/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0102 - acc: 0.9958\n",
      "Epoch 50/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0104 - acc: 0.9957\n",
      "Epoch 51/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0107 - acc: 0.9958\n",
      "Epoch 52/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0103 - acc: 0.9958\n",
      "Epoch 53/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0103 - acc: 0.9957\n",
      "Epoch 54/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0094 - acc: 0.9962\n",
      "Epoch 55/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0102 - acc: 0.9958\n",
      "Epoch 56/100\n",
      "341013/341013 [==============================] - 10s 29us/step - loss: 0.0098 - acc: 0.9961\n",
      "Epoch 57/100\n",
      "341013/341013 [==============================] - 10s 30us/step - loss: 0.0095 - acc: 0.9962\n",
      "Epoch 58/100\n",
      "341013/341013 [==============================] - 13s 38us/step - loss: 0.0093 - acc: 0.9961\n",
      "Epoch 59/100\n",
      "341013/341013 [==============================] - 13s 37us/step - loss: 0.0098 - acc: 0.9962\n",
      "Epoch 60/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0098 - acc: 0.9961\n",
      "Epoch 61/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0092 - acc: 0.9964\n",
      "Epoch 62/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0089 - acc: 0.9963\n",
      "Epoch 63/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0096 - acc: 0.9963\n",
      "Epoch 64/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0093 - acc: 0.9963\n",
      "Epoch 65/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0088 - acc: 0.9965\n",
      "Epoch 66/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0089 - acc: 0.9965\n",
      "Epoch 67/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0087 - acc: 0.9965\n",
      "Epoch 68/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0092 - acc: 0.9963\n",
      "Epoch 69/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0086 - acc: 0.9966\n",
      "Epoch 70/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0090 - acc: 0.9964\n",
      "Epoch 71/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0083 - acc: 0.9966\n",
      "Epoch 72/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0087 - acc: 0.9963\n",
      "Epoch 73/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0087 - acc: 0.9966\n",
      "Epoch 74/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0085 - acc: 0.9966\n",
      "Epoch 75/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0086 - acc: 0.9966\n",
      "Epoch 76/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0089 - acc: 0.9964\n",
      "Epoch 77/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0086 - acc: 0.9965\n",
      "Epoch 78/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0085 - acc: 0.9966\n",
      "Epoch 79/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0085 - acc: 0.9966\n",
      "Epoch 80/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0079 - acc: 0.9968\n",
      "Epoch 81/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0090 - acc: 0.9966\n",
      "Epoch 82/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0080 - acc: 0.9967\n",
      "Epoch 83/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0084 - acc: 0.9965\n",
      "Epoch 84/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0084 - acc: 0.9966\n",
      "Epoch 85/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 86/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0076 - acc: 0.9971\n",
      "Epoch 87/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0079 - acc: 0.9968\n",
      "Epoch 88/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0081 - acc: 0.9968\n",
      "Epoch 89/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0077 - acc: 0.9969\n",
      "Epoch 90/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0079 - acc: 0.9969\n",
      "Epoch 91/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0080 - acc: 0.9969\n",
      "Epoch 92/100\n",
      "341013/341013 [==============================] - 12s 35us/step - loss: 0.0083 - acc: 0.9968\n",
      "Epoch 93/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0075 - acc: 0.9971\n",
      "Epoch 94/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0082 - acc: 0.9969\n",
      "Epoch 95/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0078 - acc: 0.9970\n",
      "Epoch 96/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0075 - acc: 0.9970\n",
      "Epoch 97/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0079 - acc: 0.9968\n",
      "Epoch 98/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0075 - acc: 0.9970\n",
      "Epoch 99/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0079 - acc: 0.9970\n",
      "Epoch 100/100\n",
      "341013/341013 [==============================] - 12s 36us/step - loss: 0.0076 - acc: 0.9969\n",
      "85253/85253 [==============================] - 2s 20us/step\n",
      "Time elapsed (hh:mm:ss.ms) 1:35:23.530084\n",
      "Overall accuracy of Neural Network model: 0.9968306175017477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 95.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9972    0.9965    0.9968    213688\n",
      "           1     0.9965    0.9972    0.9968    212578\n",
      "\n",
      "   micro avg     0.9968    0.9968    0.9968    426266\n",
      "   macro avg     0.9968    0.9968    0.9968    426266\n",
      "weighted avg     0.9968    0.9968    0.9968    426266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_nodr_ann_2h_prob_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_nodr_ann_2h_01_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_nodr_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png', './Figures/CM_nodr_ann_2h_unisoftsigbinlosadam_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with ae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_ = PCA(n_components = 0.95, svd_solver = 'full').fit(train_x)\n",
    "\n",
    "# plt.figure(figsize=(8,5))\n",
    "# n_coml = [pca_.n_components_]\n",
    "\n",
    "# plt.plot(np.cumsum(pca_.explained_variance_ratio_))\n",
    "# plt.xlabel('Number of Components', fontsize=14)\n",
    "# plt.ylabel('Variance (%)', fontsize=14) #for each component\n",
    "# plt.title('Pulsar Dataset Explained Variance '+str(dsnum)+' node DS', fontsize=14)\n",
    "\n",
    "# n_coml = [*n_coml]\n",
    "\n",
    "# for i, v in enumerate(n_coml):\n",
    "#     plt.text(v-0.8, i+0.94, '{:.0f}'.format(v), color='navy', fontsize=14)\n",
    "\n",
    "# plt.savefig('./Figures/PCA_components_ds'+str(dsnum)+'bal.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_estimators=300, \n",
    "#                              criterion='gini', \n",
    "#                              max_depth=16, \n",
    "#                              #min_samples_split=2, \n",
    "#                              #min_samples_leaf=1, \n",
    "#                              max_features=0.3, \n",
    "#                              #bootstrap=True,\n",
    "#                              oob_score=True,\n",
    "#                              random_state=23)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# print(datetime.ctime(start_time))\n",
    "\n",
    "# clf.fit(enc_train_x_asam, train_y)\n",
    "\n",
    "# pred_y_ae_RF = cross_val_predict(estimator=clf,\n",
    "#                               X=np.array(enc_test_x_asam),\n",
    "#                               y=test_y,\n",
    "#                               cv=KFold(n_splits=5, random_state=23),\n",
    "#                               n_jobs=2)\n",
    "\n",
    "# time_elapsed = datetime.now() - start_time \n",
    "# print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "# print(sm.classification_report(test_y, pred_y_ae_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_y_ae_RF, pred_y_ae_RF, './Figures/ROC_ae_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png', './Figures/CM_ae_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with spae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# print(datetime.ctime(start_time))\n",
    "\n",
    "# clf.fit(enc_train_x_spsam, train_y)\n",
    "\n",
    "# pred_y_spae_RF = cross_val_predict(estimator=clf,\n",
    "#                               X=np.array(enc_test_x_spsam),\n",
    "#                               y=test_y,\n",
    "#                               cv=KFold(n_splits=5, random_state=23),\n",
    "#                               n_jobs=2)\n",
    "\n",
    "# time_elapsed = datetime.now() - start_time \n",
    "# print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "# print(sm.classification_report(test_y, pred_y_spae_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_y_spae_RF, pred_y_spae_RF, './Figures/ROC_spae_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png', './Figures/CM_spae_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with pca DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# print(datetime.ctime(start_time))\n",
    "\n",
    "# clf.fit(train_x_pca, train_y)\n",
    "\n",
    "# pred_y_pca_RF = cross_val_predict(estimator=clf,\n",
    "#                               X=np.array(test_x_pca),\n",
    "#                               y=test_y,\n",
    "#                               cv=KFold(n_splits=5, random_state=23),\n",
    "#                               n_jobs=2)\n",
    "\n",
    "# time_elapsed = datetime.now() - start_time \n",
    "# print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "# print(sm.classification_report(test_y, pred_y_pca_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_y_pca_RF, pred_y_pca_RF, './Figures/ROC_pca_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png', './Figures/CM_pca_rf_E100MaxfautoMaxdnoneBootT_redds'+str(dsnum)+'bal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426266,)\n",
      "(426266,)\n",
      "(426266,)\n",
      "(426266,)\n",
      "(426266,)\n",
      "(426266,)\n"
     ]
    }
   ],
   "source": [
    "print(pred_ae_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_ae_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "print(pred_sp_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_sp_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "print(pred_nodr_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_nodr_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "# print(pred_y_ae_RF.shape)\n",
    "# print(pred_y_spae_RF.shape)\n",
    "# print(pred_y_pca_RF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "false_positive_rate_ae_ann, recall_ae_ann, thresholds_ae_ann = roc_curve(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_ae_ann = auc(false_positive_rate_ae_ann, recall_ae_ann)\n",
    "false_positive_rate_sp_ann, recall_sp_ann, thresholds_sp_ann = roc_curve(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_sp_ann = auc(false_positive_rate_sp_ann, recall_sp_ann)\n",
    "false_positive_rate_nodr_ann, recall_nodr_ann, thresholds_nodr_ann = roc_curve(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_nodr_ann = auc(false_positive_rate_nodr_ann, recall_nodr_ann)\n",
    "\n",
    "# false_positive_rate_ae_RF, recall_ae_RF, thresholds_ae_RF = roc_curve(test_y, pred_y_ae_RF)\n",
    "# roc_auc_ae_RF = auc(false_positive_rate_ae_RF, recall_ae_RF)\n",
    "# false_positive_rate_spae_RF, recall_spae_RF, thresholds_spae_RF = roc_curve(test_y, pred_y_spae_RF)\n",
    "# roc_auc_spae_RF = auc(false_positive_rate_spae_RF, recall_spae_RF)\n",
    "# false_positive_rate_pca_RF, recall_pca_RF, thresholds_pca_RF = roc_curve(test_y, pred_y_pca_RF)\n",
    "# roc_auc_pca_RF = auc(false_positive_rate_pca_RF, recall_pca_RF)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.title('Receiver Operating Characteristic (ROC)', fontsize=16)\n",
    "\n",
    "plt.plot(false_positive_rate_ae_ann, recall_ae_ann, 'b', label = 'AUC AE + DNN = %0.3f' %roc_auc_ae_ann)\n",
    "plt.plot(false_positive_rate_sp_ann, recall_sp_ann, 'g', label = 'AUC SAE + DNN = %0.3f' %roc_auc_sp_ann)\n",
    "plt.plot(false_positive_rate_nodr_ann, recall_nodr_ann, 'r', label = 'AUC DNN = %0.3f' %roc_auc_nodr_ann)\n",
    "# plt.plot(false_positive_rate_ae_RF, recall_ae_RF, 'c', label = 'AUC AE + RF = %0.3f' %roc_auc_ae_RF)\n",
    "# plt.plot(false_positive_rate_spae_RF, recall_spae_RF, 'm', label = 'AUC SAE + RF = %0.3f' %roc_auc_spae_RF)\n",
    "# plt.plot(false_positive_rate_pca_RF, recall_pca_RF, 'black', label = 'AUC PCA + RF = %0.3f' %roc_auc_pca_RF)\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "# plt.ylim([0.97,1.0])\n",
    "\n",
    "plt.ylabel('Recall - TPR', fontsize=14)\n",
    "plt.xlabel('Fall-out (1-Specificity) - FPR', fontsize=14)\n",
    "plt.savefig('./Figures/ROC_allmodels'+str(dsnum)+'bal.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title('Receiver Operating Characteristic (ROC) Zoom in', fontsize=16)\n",
    "\n",
    "plt.plot(false_positive_rate_ae_ann, recall_ae_ann, 'b', label = 'AUC AE + DNN = %0.3f' %roc_auc_ae_ann)\n",
    "plt.plot(false_positive_rate_sp_ann, recall_sp_ann, 'g', label = 'AUC SAE + DNN = %0.3f' %roc_auc_sp_ann)\n",
    "plt.plot(false_positive_rate_nodr_ann, recall_nodr_ann, 'r', label = 'AUC DNN = %0.3f' %roc_auc_nodr_ann)\n",
    "# plt.plot(false_positive_rate_ae_RF, recall_ae_RF, 'c', label = 'AUC AE + RF = %0.3f' %roc_auc_ae_RF)\n",
    "# plt.plot(false_positive_rate_spae_RF, recall_spae_RF, 'm', label = 'AUC SAE + RF = %0.3f' %roc_auc_spae_RF)\n",
    "# plt.plot(false_positive_rate_pca_RF, recall_pca_RF, 'black', label = 'AUC PCA + RF = %0.3f' %roc_auc_pca_RF)\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "# plt.ylim([0.0,1.0])\n",
    "plt.ylim([0.955,1.0])\n",
    "\n",
    "plt.ylabel('Recall - TPR', fontsize=14)\n",
    "plt.xlabel('Fall-out (1-Specificity) - FPR', fontsize=14)\n",
    "plt.savefig('./Figures/ROC_allmodels'+str(dsnum)+'bal_zoom.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier\tAcc\tPreci\tRecall\tF1Score\n",
      "AE+DNN\t\t99.17\t99.02\t99.33\t99.17\n",
      "SAE+DNN\t\t99.13\t99.16\t99.09\t99.12\n",
      "DNN\t\t99.68\t99.65\t99.72\t99.68\n"
     ]
    }
   ],
   "source": [
    "classi_ae_ann = \"AE+DNN\"\n",
    "acc_ae_ann = (sm.accuracy_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_ae_ann = (sm.precision_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_ae_ann = (sm.recall_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_ae_ann = (sm.f1_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "classi_sp_ann = \"SAE+DNN\"\n",
    "acc_sp_ann = (sm.accuracy_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_sp_ann = (sm.precision_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_sp_ann = (sm.recall_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_sp_ann = (sm.f1_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "classi_nodr_ann = \"DNN\"\n",
    "acc_nodr_ann = (sm.accuracy_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_nodr_ann = (sm.precision_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_nodr_ann = (sm.recall_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_nodr_ann = (sm.f1_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "# classi_ae_RF = \"AE+RF\"\n",
    "# acc_ae_RF = (sm.accuracy_score(test_y, pred_y_ae_RF)*100) \n",
    "# pre_ae_RF = (sm.precision_score(test_y, pred_y_ae_RF)*100) \n",
    "# recall_ae_RF = (sm.recall_score(test_y, pred_y_ae_RF)*100) \n",
    "# f1score_ae_RF = (sm.f1_score(test_y, pred_y_ae_RF)*100)\n",
    "\n",
    "# classi_spae_RF = \"SAE+RF\"\n",
    "# acc_spae_RF = (sm.accuracy_score(test_y, pred_y_spae_RF)*100) \n",
    "# pre_spae_RF = (sm.precision_score(test_y, pred_y_spae_RF)*100) \n",
    "# recall_spae_RF = (sm.recall_score(test_y, pred_y_spae_RF)*100) \n",
    "# f1score_spae_RF = (sm.f1_score(test_y, pred_y_spae_RF)*100)\n",
    "\n",
    "# classi_pca_RF = \"PCA+RF\"\n",
    "# acc_pca_RF = (sm.accuracy_score(test_y, pred_y_pca_RF)*100) \n",
    "# pre_pca_RF = (sm.precision_score(test_y, pred_y_pca_RF)*100) \n",
    "# recall_pca_RF = (sm.recall_score(test_y, pred_y_pca_RF)*100) \n",
    "# f1score_pca_RF = (sm.f1_score(test_y, pred_y_pca_RF)*100)\n",
    "\n",
    "\n",
    "print('Classifier\\tAcc\\tPreci\\tRecall\\tF1Score')\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_ae_ann, acc_ae_ann, pre_ae_ann, recall_ae_ann, f1score_ae_ann))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_sp_ann, acc_sp_ann, pre_sp_ann, recall_sp_ann, f1score_sp_ann))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_nodr_ann, acc_nodr_ann, pre_nodr_ann, recall_nodr_ann, f1score_nodr_ann))\n",
    "# print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_ae_RF, acc_ae_RF, pre_ae_RF, recall_ae_RF, f1score_ae_RF))\n",
    "# print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_spae_RF, acc_spae_RF, pre_spae_RF, recall_spae_RF, f1score_spae_RF))\n",
    "# print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_pca_RF, acc_pca_RF, pre_pca_RF, recall_pca_RF, f1score_pca_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1list = [[\"AE+DNN\",f1score_ae_ann],[\"SAE+DNN\",f1score_sp_ann],[\"DNN\",f1score_nodr_ann]]#,\n",
    "#           [\"AE+RF\",f1score_ae_RF],[\"SAE+RF\",f1score_spae_RF],[\"PCA+RF\",f1score_pca_RF]]\n",
    "\n",
    "xs, ys = [*zip(*f1list)]\n",
    "\n",
    "'{:.2f}'.format(f1score_ae_ann)\n",
    "\n",
    "plt.figure(figsize=(8,6), )\n",
    "plt.barh(xs, ys, color = \"purple\")\n",
    "plt.title(\"F1 score vs Classifier\", fontsize=16)\n",
    "plt.xlabel(\"Classifier\", fontsize=14)\n",
    "plt.ylabel(\"F1 score\", fontsize=14)\n",
    "plt.xticks(np.arange(0, 101, 10), fontsize=12)\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "for i, v in enumerate(ys):\n",
    "    plt.text(v+1, i+0.1, '{:.2f}'.format(v), color='purple', fontsize=14)\n",
    "\n",
    "plt.savefig('./Figures/F1scoreplot_allmodels'+str(dsnum)+'bal.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
