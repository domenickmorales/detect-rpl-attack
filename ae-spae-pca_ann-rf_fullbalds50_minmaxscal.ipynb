{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# TensorFlow wizardry\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Donâ€™t pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.05\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "from keras import optimizers, regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras import optimizers\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Activation, Dense, Dropout, Input\n",
    "from keras import backend as k\n",
    "\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "#k.tensorflow_backend.set_session(tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------Import modules------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_curve, auc\n",
    "from sklearn import preprocessing\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(23)\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from datetime import datetime \n",
    "\n",
    "import multiprocessing\n",
    "# njobscpu = multiprocessing.cpu_count() - 2\n",
    "njobscpu = 7\n",
    "\n",
    "\n",
    "dsnum=50\n",
    "verbose_level=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathds = '/home/user/01Code/00Datasets_final/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_chunk = pd.read_csv(pathds+'SubsetAllSamples/ThirdCloneID10bal_minmax.csv', chunksize=1000)\n",
    "#df = df_chunk.get_chunk(300000)\n",
    "df = pd.read_csv(pathds+\"00BalancedDS/FullCloneID\"+str(dsnum)+\"bal_minmax.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2131328, 121)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "neurons=df.shape[1]-1\n",
    "batch_size=df.shape[1]-1\n",
    "print(neurons)\n",
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Explaining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 1065664\n",
      "Class 1: 1065664\n",
      "Proportion: 1.0 : 1\n"
     ]
    }
   ],
   "source": [
    "#if you don't have an intuitive sense of how imbalanced these two classes are, let's go visual\n",
    "count_classes = pd.value_counts(df['class'], sort = True)\n",
    "print('Class 0:', count_classes[0])\n",
    "print('Class 1:', count_classes[1])\n",
    "print('Proportion:', round(count_classes[0] / count_classes[1], 3), ': 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "plt.xticks(range(2), ['Normal [0]','Malicious [1]'])\n",
    "plt.title(\"Frequency by observation number\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Observations\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random seed and percentage of test data\n",
    "RANDOM_SEED = 23 #used to help randomly select the data points\n",
    "TEST_PCT = 0.20 # 20% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_df = train_test_split(df, test_size=TEST_PCT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ df -> original dataset \n",
    "+ train -> subset of 80% from original dataset \n",
    "+ test_df -> subset of 20% from original dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, dev_df = train_test_split(train, test_size=TEST_PCT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train -> subset of 80% from original dataset \n",
    "+ train_df -> subset of 80% from train\n",
    "+ dev_df -> subset of 20% from train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500630109328917\n",
      "0.4991070721644043\n",
      "0.4986979960869504\n"
     ]
    }
   ],
   "source": [
    "# Check distribution of mal samples in train and test set/\n",
    "print(train_df.iloc[:, batch_size].sum()/train_df.shape[0]) \n",
    "print(dev_df.iloc[:, batch_size].sum()/dev_df.shape[0]) \n",
    "print(test_df.iloc[:, batch_size].sum()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.iloc[:, :batch_size] \n",
    "dev_x = dev_df.iloc[:, :batch_size] \n",
    "test_x = test_df.iloc[:, :batch_size] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train_x -> features of train_df **Training subset for AE**\n",
    "+ dev_x -> features of dev_df **Validation subset for AE**\n",
    "+ test_x -> features of test_df **Testing subset for ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the final train and test sets\n",
    "train_y = train_df.iloc[:,batch_size]\n",
    "dev_y = dev_df.iloc[:,batch_size]\n",
    "test_y = test_df.iloc[:,batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ train_y -> **Labels for supervised training of ANN**\n",
    "+ dev_y -> labels of dev_df  *not used for AE neither ANN*\n",
    "+ test_y -> labels of test_df  **Ground Truth for predictions of supervised ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_x =np.array(train_x)\n",
    "dev_x =np.array(dev_x)\n",
    "test_x = np.array(test_x)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "dev_y = np.array(dev_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "print(train_x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae(factor_enc_dim, enc_activation, dec_activation, \n",
    "                optimizer, loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer #RELU\n",
    "    encoded = Dense(encoding_dim, activation=enc_activation, name='encoded_bottle_neck')(input_data)\n",
    "    ### Define decoding layer #SIMOID\n",
    "    decoded = Dense(train_x.shape[1], activation=dec_activation)(encoded)\n",
    "    ### Create the autoencoder model\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(autoencoder.summary())\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return autoencoder,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spae(factor_enc_dim,dec_activation,enc_activation,\n",
    "         optimizer,loss):\n",
    "\n",
    "    encoding_dim = int(int(train_x.shape[1])/factor_enc_dim)\n",
    "    ### Define input layer\n",
    "    input_data = Input(shape=(train_x.shape[1],))\n",
    "    ### Define encoding layer\n",
    "    encoded = Dense(encoding_dim, activity_regularizer=regularizers.l1(1e-4), activation=enc_activation, name='encoded_bottle_neck')(input_data)\n",
    "    ### Define decoding layer\n",
    "    decoded = Dense(train_x.shape[1], activation=dec_activation)(encoded)\n",
    "    ### Create the autoencoder model\n",
    "    autoencoder = Model(input_data, decoded)\n",
    "    autoencoder.compile(optimizer=optimizer,\n",
    "                        loss=loss,\n",
    "                        metrics=['accuracy'])\n",
    "    \n",
    "    print(autoencoder.summary())\n",
    "    \n",
    "    encoder = Model(input_data, encoded)\n",
    "    encoded_train_x = encoder.predict(train_x)\n",
    "    encoded_test_x = encoder.predict(test_x)\n",
    "    \n",
    "    return autoencoder,encoded_train_x,encoded_test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pca(thr):\n",
    "    #train_x_pca,test_x_pca = to_pca(0.95)\n",
    "    pca = PCA(n_components = thr, svd_solver = 'full')\n",
    "    train_x_ = np.array(train_x)\n",
    "    print(type(train_x_))\n",
    "\n",
    "    test_x_ = np.array(test_x)\n",
    "    print(type(test_x_))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(time.ctime(start_time))\n",
    "\n",
    "    train_x_pca = pca.fit_transform(train_x_)\n",
    "    print(train_x_pca.shape)\n",
    "\n",
    "    test_x_pca = pca.fit_transform(test_x_)\n",
    "    print(test_x_pca.shape)\n",
    "\n",
    "    elapsed_time = (time.time() - start_time)\n",
    "\n",
    "    print(\"--- PCA spent %s seconds ---\" %elapsed_time )\n",
    "    \n",
    "    return  train_x_pca,test_x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ae(checkpoint_file, autoencoder,\n",
    "           epochs, batch_size, shuffle):\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    cp = ModelCheckpoint(filepath=checkpoint_file,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=verbose_level)\n",
    "\n",
    "    tb = TensorBoard(log_dir='./logs',\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=True)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))\n",
    "\n",
    "    hist_auto = autoencoder.fit(train_x, train_x,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=shuffle,\n",
    "                    verbose=verbose_level,\n",
    "                    callbacks=[early_stopping, cp, tb],\n",
    "                    validation_data=(dev_x, dev_x))\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "    \n",
    "    return hist_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist_auto(hist_auto, fig_file):\n",
    "    best_loss_value = hist_auto.history['loss'][-1]\n",
    "    print('Best loss value:', best_loss_value)\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.figure()\n",
    "    plt.plot(hist_auto.history['loss'])\n",
    "    plt.plot(hist_auto.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper right')\n",
    "    plt.savefig(fig_file)\n",
    "    plt.show()\n",
    "    \n",
    "    return best_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h(neurons,encoded_train_x,init_mode,activation_input,\n",
    "               weight_constraint,dropout_rate,activation_output,\n",
    "               loss,optimizer):\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=encoded_train_x.shape[1],\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(int(neurons-int(neurons/4)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "\n",
    "    model.add(Dense(int(neurons-int((neurons/4)*2)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_2h_():\n",
    "\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons, input_dim=input_dim,\n",
    "                    kernel_initializer=init_mode,\n",
    "                    #kernel_regularizer=regularizers.l2(0.02), #from example\n",
    "                    activation=activation_input,\n",
    "                    kernel_constraint=maxnorm(weight_constraint)\n",
    "                    )\n",
    "              )\n",
    "\n",
    "#     #Hidden Layer\n",
    "    model.add(Dense(int(neurons-int(neurons/4)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "\n",
    "    model.add(Dense(int(neurons-int((neurons/4)*2)), activation=\"relu\", kernel_initializer=init_mode)) #rezvy\n",
    "    model.add(BatchNormalization()) #commented for ex\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense(1, activation=activation_output)) #example\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss=loss, \n",
    "                  optimizer=optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_fit(checkpoint_file,ann,enc_train_x,train_y,epochs,shuffle,batch_size):\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "    cp = ModelCheckpoint(filepath=checkpoint_file,\n",
    "                                   save_best_only=True,\n",
    "                                   verbose=verbose_level)\n",
    "\n",
    "    tb = TensorBoard(log_dir='./logs',\n",
    "                    histogram_freq=0,\n",
    "                    write_graph=True,\n",
    "                    write_images=True)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))\n",
    "\n",
    "    history = ann.fit(enc_train_x,\n",
    "                      train_y,\n",
    "                      validation_split=0.2,\n",
    "                      callbacks=[early_stopping, cp, tb],\n",
    "                      epochs=epochs,\n",
    "                      shuffle=shuffle,\n",
    "                      batch_size=batch_size,\n",
    "                      verbose=verbose_level)\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict(ann,enc_test_x):\n",
    "    pred_ann_prob = ann.predict(enc_test_x)\n",
    "    pred_ann_prob.shape\n",
    "    pred_ann_prob = pred_ann_prob[:,0]\n",
    "    pred_ann_01 = np.where(pred_ann_prob > 0.5, 1, 0)\n",
    "    \n",
    "    #Print accuracy\n",
    "    acc_ann = accuracy_score(test_y, pred_ann_01)\n",
    "    print('Overall accuracy of Neural Network model:', acc_ann)\n",
    "\n",
    "    classiBM = \"NN\"\n",
    "    preBM = (sm.precision_score(test_y, pred_ann_01)*100) \n",
    "    recallBM = (sm.recall_score(test_y, pred_ann_01)*100) \n",
    "    f1scoreBM = (sm.f1_score(test_y, pred_ann_01)*100)\n",
    "    print(sm.classification_report(test_y, pred_ann_01,digits=4))\n",
    "    \n",
    "    return pred_ann_prob, pred_ann_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann_predict_():\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=10)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(datetime.ctime(start_time))  \n",
    "\n",
    "    modelk = KerasClassifier(build_fn=ann_2h_,\n",
    "                             epochs=epochs, \n",
    "                             batch_size=batch_size, \n",
    "                             verbose=verbose_level\n",
    "                            )\n",
    "\n",
    "    pred_ann_prob = cross_val_predict(modelk,\n",
    "                                      enc_test_x,\n",
    "                                      test_y,\n",
    "                                      cv=KFold(n_splits=5, random_state=23),\n",
    "                                      verbose=1,\n",
    "                                      n_jobs=njobscpu)\n",
    "\n",
    "    time_elapsed = datetime.now() - start_time \n",
    "    print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "    pred_ann_prob.shape\n",
    "    pred_ann_prob = pred_ann_prob[:,0]\n",
    "    pred_ann_01 = np.where(pred_ann_prob > 0.5, 1, 0)\n",
    "\n",
    "    #Print accuracy\n",
    "    acc_ann = accuracy_score(test_y, pred_ann_01)\n",
    "    print('Overall accuracy of Neural Network model:', acc_ann)\n",
    "\n",
    "    classiBM = \"NN\"\n",
    "    preBM = (sm.precision_score(test_y, pred_ann_01)*100) \n",
    "    recallBM = (sm.recall_score(test_y, pred_ann_01)*100) \n",
    "    f1scoreBM = (sm.f1_score(test_y, pred_ann_01)*100)\n",
    "    print(sm.classification_report(test_y, pred_ann_01,digits=4))\n",
    "    \n",
    "    return pred_ann_prob,pred_ann_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_cm(pred_ann_prob, pred_ann_01, roc_file, cm_file):\n",
    "    false_positive_rate, recall, thresholds = roc_curve(test_y, pred_ann_prob)\n",
    "    roc_auc = auc(false_positive_rate, recall)\n",
    "    plt.figure()\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.plot(false_positive_rate, recall, 'b', label = 'AUC = %0.3f' %roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1], [0,1], 'r--')\n",
    "    plt.xlim([0.0,1.0])\n",
    "    plt.ylim([0.0,1.0])\n",
    "    plt.ylabel('Recall')\n",
    "    plt.xlabel('Fall-out (1-Specificity)')\n",
    "    plt.savefig(roc_file)\n",
    "    plt.show()\n",
    "    \n",
    "    cm = confusion_matrix(test_y, pred_ann_01)\n",
    "    labels = ['Normal', 'Malicious']\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(cm,xticklabels=labels, yticklabels=labels, annot=True, fmt='d', cmap=\"RdYlGn\", vmin = 0.2);\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.savefig(cm_file)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- PCA Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Sat Sep  7 14:54:02 2019\n",
      "(1364049, 78)\n",
      "(426266, 78)\n",
      "--- PCA spent 9.533066749572754 seconds ---\n"
     ]
    }
   ],
   "source": [
    "train_x_pca,test_x_pca = to_pca(0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- AE Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0907 14:54:11.936458 139935054169920 deprecation_wrapper.py:119] From /home/user/anaconda3/envs/deepl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0907 14:54:11.937179 139935054169920 deprecation_wrapper.py:119] From /home/user/anaconda3/envs/deepl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0907 14:54:12.046323 139935054169920 deprecation_wrapper.py:119] From /home/user/anaconda3/envs/deepl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0907 14:54:12.168854 139935054169920 deprecation_wrapper.py:119] From /home/user/anaconda3/envs/deepl/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0907 14:54:12.217802 139935054169920 deprecation_wrapper.py:119] From /home/user/anaconda3/envs/deepl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0907 14:54:12.246516 139935054169920 deprecation_wrapper.py:119] From /home/user/anaconda3/envs/deepl/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "encoded_bottle_neck (Dense)  (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               9720      \n",
      "=================================================================\n",
      "Total params: 19,400\n",
      "Trainable params: 19,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ae_sigmoid_adam_mse,enc_train_x_asam,enc_test_x_asam = ae(factor_enc_dim = 1.5,\n",
    "                                                          enc_activation = 'relu',\n",
    "                                                          dec_activation = 'sigmoid',\n",
    "                                                          optimizer='Adam',\n",
    "                                                          loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ae_sigmoid_adam_mse = load_model('ae_sigmoid_adam_mse_ds10bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Sep  7 14:54:44 2019\n",
      "Train on 1364049 samples, validate on 341013 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0907 14:54:45.031625 139935054169920 deprecation_wrapper.py:119] From /home/user/anaconda3/envs/deepl/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0907 14:54:45.032352 139935054169920 deprecation_wrapper.py:119] From /home/user/anaconda3/envs/deepl/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1364049/1364049 [==============================] - 22s 16us/step - loss: 0.0045 - acc: 0.0055 - val_loss: 5.9657e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00006, saving model to ./H5files/ae_sigmoid_adam_mse_ds50bal_minmax.h5\n",
      "Epoch 2/200\n",
      "1364049/1364049 [==============================] - 21s 16us/step - loss: 3.4767e-05 - acc: 0.0000e+00 - val_loss: 3.1075e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00006 to 0.00003, saving model to ./H5files/ae_sigmoid_adam_mse_ds50bal_minmax.h5\n",
      "Epoch 3/200\n",
      "1364049/1364049 [==============================] - 21s 16us/step - loss: 3.0132e-05 - acc: 0.0000e+00 - val_loss: 3.0367e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00003 to 0.00003, saving model to ./H5files/ae_sigmoid_adam_mse_ds50bal_minmax.h5\n",
      "Epoch 4/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 2.9774e-05 - acc: 0.0000e+00 - val_loss: 3.0257e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00003 to 0.00003, saving model to ./H5files/ae_sigmoid_adam_mse_ds50bal_minmax.h5\n",
      "Epoch 5/200\n",
      "1364049/1364049 [==============================] - 21s 15us/step - loss: 2.9646e-05 - acc: 0.0000e+00 - val_loss: 3.0261e-05 - val_acc: 0.0000e+00\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00003\n",
      "Epoch 6/200\n",
      " 101280/1364049 [=>............................] - ETA: 19s - loss: 2.9719e-05 - acc: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "hist_ae_sigmoid_adam_mse = fit_ae(checkpoint_file = \"./H5files/ae_sigmoid_adam_mse_ds\"+str(dsnum)+\"bal_minmax.h5\",\n",
    "                                  autoencoder = ae_sigmoid_adam_mse, \n",
    "                                  epochs = 200, \n",
    "                                  batch_size = batch_size*2,\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_ae_sigmoid_adam_mse  = plot_hist_auto(hist_ae_sigmoid_adam_mse, './Figures/hist_ae_sigmoid_adam_mse.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- SPAE Dimensionality reduction ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spae_sigmoid_adam_mse,enc_train_x_spsam,enc_test_x_spsam = spae(factor_enc_dim = 1.5,\n",
    "                                                          enc_activation = 'relu',\n",
    "                                                          dec_activation = 'sigmoid',\n",
    "                                                          optimizer='Adam',\n",
    "                                                          loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spae_sigmoid_adam_mse = load_model('spae_sigmoid_adam_mse_ds20bal.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_spae_sigmoid_adam_mse = fit_ae(checkpoint_file = \"./H5files/spae_sigmoid_adam_mse_ds\"+str(dsnum)+\"bal_minmax.h5\",\n",
    "                                  autoencoder = spae_sigmoid_adam_mse, \n",
    "                                  epochs = 200, \n",
    "                                  batch_size = batch_size*2,\n",
    "                                  shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss_value_spae_sigmoid_adam_mse  = plot_hist_auto(hist_spae_sigmoid_adam_mse, './Figures/hist_spae_sigmoid_adam_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valueDict = {\n",
    "    'loss_value_ae_sigmoid_adam_mse': best_loss_value_ae_sigmoid_adam_mse,\n",
    "    'loss_value_spae_sigmoid_adam_mse': best_loss_value_spae_sigmoid_adam_mse\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_valueDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enc_train_x_asam.shape)\n",
    "print(enc_test_x_asam.shape)\n",
    "\n",
    "print(enc_train_x_spsam.shape)\n",
    "print(enc_test_x_spsam.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with ae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=enc_train_x_asam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_ae_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ae_ann_2h_unisoftsigbinlosadam_ds\"+str(dsnum)+\"bal_minmax.h5\",\n",
    "                                        ann = ae_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = enc_train_x_asam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_ae_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_ae_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_ae_ann_2h_unisoftsigbinlosadam, './Figures/ae_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_ae_ann_2h_prob_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam = ann_predict(ae_ann_2h_unisoftsigbinlosadam,enc_test_x_asam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_ae_ann_2h_01_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_ae_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_ae_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=enc_train_x_asam\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=enc_test_x_asam\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "njobscpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ae_ann_2h_prob_unisoftsigbinlosadam,pred_ae_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_ae_ann_2h_01_unisoftsigbinlosadam, pred_ae_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_ae_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_ae_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with spae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=enc_train_x_spsam,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_sp_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ann_2h_unisoftsigbinlosadam_ds\"+str(dsnum)+\"bal_minmax.h5\",\n",
    "                                        ann = sp_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = enc_train_x_spsam,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_sp_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_sp_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_sp_ann_2h_unisoftsigbinlosadam, './Figures/sp_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam = ann_predict(sp_ann_2h_unisoftsigbinlosadam,enc_test_x_spsam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_sp_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_sp_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=enc_train_x_asam\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=enc_test_x_spsam\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sp_ann_2h_prob_unisoftsigbinlosadam,pred_sp_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_sp_ann_2h_prob_unisoftsigbinlosadam, pred_sp_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_sp_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_sp_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- ANN with no encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodr_ann_2h_unisoftsigbinlosadam1 = ann_2h(neurons=neurons,\n",
    "                                      encoded_train_x=train_x,\n",
    "                                      init_mode='uniform',\n",
    "                                      activation_input='relu',\n",
    "                                      weight_constraint=5,\n",
    "                                      dropout_rate=0.0,\n",
    "                                      activation_output='sigmoid',\n",
    "                                      loss='binary_crossentropy',\n",
    "                                      optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_nodr_ann_2h_unisoftsigbinlosadam = ann_fit(checkpoint_file = \"./H5files/ann_2h_unisoftsigbinlosadam_ds\"+str(dsnum)+\"bal_minmax.h5\",\n",
    "                                        ann = nodr_ann_2h_unisoftsigbinlosadam1,\n",
    "                                        enc_train_x = train_x,\n",
    "                                        train_y = train_y,\n",
    "                                        epochs = 200,\n",
    "                                        shuffle = True,\n",
    "                                        batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist_nodr_ann_2h_unisoftsigbinlosadam.model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_loss_value_nodr_ann_2h_unisoftsigbinlosadam = plot_hist_auto(hist_nodr_ann_2h_unisoftsigbinlosadam, './Figures/nodr_ann_2h_unisoftsigbinlosadam'+str(dsnum)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_nodr_ann_2h_prob_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam = ann_predict(nodr_ann_2h_unisoftsigbinlosadam,test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_cm(pred_nodr_ann_2h_01_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_nodr_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_nodr_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_train_x=train_x\n",
    "input_dim=enc_train_x.shape[1]\n",
    "enc_test_x=test_x\n",
    "test_y=test_y\n",
    "train_y=train_y\n",
    "init_mode='uniform'\n",
    "activation_input='relu'\n",
    "weight_constraint=5\n",
    "dropout_rate=0.0\n",
    "activation_output='sigmoid'\n",
    "loss='binary_crossentropy'\n",
    "optimizer='Adam'\n",
    "\n",
    "epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_nodr_ann_2h_prob_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam = ann_predict_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_nodr_ann_2h_01_unisoftsigbinlosadam, pred_nodr_ann_2h_01_unisoftsigbinlosadam, './Figures/ROC_nodr_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_nodr_ann_2h_unisoftsigbinlosadam_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with ae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the PCA algorithm with our Data\n",
    "# pca = PCA().fit(data_rescaled)\n",
    "pca_ = PCA(n_components = 0.95, svd_solver = 'full').fit(train_x)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "n_coml = [pca_.n_components_]\n",
    "\n",
    "plt.plot(np.cumsum(pca_.explained_variance_ratio_))\n",
    "plt.xlabel('Number of Components', fontsize=14)\n",
    "plt.ylabel('Variance (%)', fontsize=14) #for each component\n",
    "plt.title('Pulsar Dataset Explained Variance '+str(dsnum)+' node DS', fontsize=14)\n",
    "\n",
    "n_coml = [*n_coml]\n",
    "\n",
    "for i, v in enumerate(n_coml):\n",
    "    plt.text(v-0.8, i+0.94, '{:.0f}'.format(v), color='navy', fontsize=14)\n",
    "\n",
    "plt.savefig('./Figures/PCA_components_ds'+str(dsnum)+'bal_minmax.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300, \n",
    "                             criterion='gini', \n",
    "                             max_depth=16, \n",
    "#                              min_samples_split=2, \n",
    "                             #min_samples_leaf=1, \n",
    "                             max_features=0.3, \n",
    "                             #bootstrap=True,\n",
    "                             oob_score=True,\n",
    "                             random_state=23)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print(datetime.ctime(start_time))\n",
    "\n",
    "clf.fit(enc_train_x_asam, train_y)\n",
    "\n",
    "pred_y_ae_RF = cross_val_predict(estimator=clf,\n",
    "                              X=np.array(enc_test_x_asam),\n",
    "                              y=test_y,\n",
    "                              cv=KFold(n_splits=5, random_state=23),\n",
    "                              n_jobs=njobscpu)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "print(sm.classification_report(test_y, pred_y_ae_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_y_ae_RF, pred_y_ae_RF, './Figures/ROC_ae_rf_E100MaxfautoMaxdnoneBootT_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_ae_rf_E100MaxfautoMaxdnoneBootT_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with spae encoded DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print(datetime.ctime(start_time))\n",
    "\n",
    "clf.fit(enc_train_x_spsam, train_y)\n",
    "\n",
    "pred_y_spae_RF = cross_val_predict(estimator=clf,\n",
    "                              X=np.array(enc_test_x_spsam),\n",
    "                              y=test_y,\n",
    "                              cv=KFold(n_splits=5, random_state=23),\n",
    "                              n_jobs=njobscpu)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "print(sm.classification_report(test_y, pred_y_spae_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_y_spae_RF, pred_y_spae_RF, './Figures/ROC_spae_rf_E100MaxfautoMaxdnoneBootT_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_spae_rf_E100MaxfautoMaxdnoneBootT_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **---------- RF with pca DS ----------**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "print(datetime.ctime(start_time))\n",
    "\n",
    "clf.fit(train_x_pca, train_y)\n",
    "\n",
    "pred_y_pca_RF = cross_val_predict(estimator=clf,\n",
    "                              X=np.array(test_x_pca),\n",
    "                              y=test_y,\n",
    "                              cv=KFold(n_splits=5, random_state=23),\n",
    "                              n_jobs=njobscpu)\n",
    "\n",
    "time_elapsed = datetime.now() - start_time \n",
    "print(\"Time elapsed (hh:mm:ss.ms) {}\".format(time_elapsed))\n",
    "\n",
    "print(sm.classification_report(test_y, pred_y_pca_RF,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_cm(pred_y_pca_RF, pred_y_pca_RF, './Figures/ROC_pca_rf_E100MaxfautoMaxdnoneBootT_ds'+str(dsnum)+'bal_minmax.png', './Figures/CM_pca_rf_E100MaxfautoMaxdnoneBootT_ds'+str(dsnum)+'bal_minmax.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_ae_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_ae_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "print(pred_sp_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_sp_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "print(pred_nodr_ann_2h_01_unisoftsigbinlosadam.shape)\n",
    "print(pred_nodr_ann_2h_prob_unisoftsigbinlosadam.shape)\n",
    "print(pred_y_ae_RF.shape)\n",
    "print(pred_y_spae_RF.shape)\n",
    "print(pred_y_pca_RF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positive_rate_ae_ann, recall_ae_ann, thresholds_ae_ann = roc_curve(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_ae_ann = auc(false_positive_rate_ae_ann, recall_ae_ann)\n",
    "false_positive_rate_sp_ann, recall_sp_ann, thresholds_sp_ann = roc_curve(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_sp_ann = auc(false_positive_rate_sp_ann, recall_sp_ann)\n",
    "false_positive_rate_nodr_ann, recall_nodr_ann, thresholds_nodr_ann = roc_curve(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)\n",
    "roc_auc_nodr_ann = auc(false_positive_rate_nodr_ann, recall_nodr_ann)\n",
    "\n",
    "false_positive_rate_ae_RF, recall_ae_RF, thresholds_ae_RF = roc_curve(test_y, pred_y_ae_RF)\n",
    "roc_auc_ae_RF = auc(false_positive_rate_ae_RF, recall_ae_RF)\n",
    "false_positive_rate_spae_RF, recall_spae_RF, thresholds_spae_RF = roc_curve(test_y, pred_y_spae_RF)\n",
    "roc_auc_spae_RF = auc(false_positive_rate_spae_RF, recall_spae_RF)\n",
    "false_positive_rate_pca_RF, recall_pca_RF, thresholds_pca_RF = roc_curve(test_y, pred_y_pca_RF)\n",
    "roc_auc_pca_RF = auc(false_positive_rate_pca_RF, recall_pca_RF)\n",
    "\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.title('Receiver Operating Characteristic (ROC)', fontsize=16)\n",
    "\n",
    "plt.plot(false_positive_rate_ae_ann, recall_ae_ann, 'b', label = 'AUC AE + DNN = %0.3f' %roc_auc_ae_ann)\n",
    "plt.plot(false_positive_rate_sp_ann, recall_sp_ann, 'g', label = 'AUC SAE + DNN = %0.3f' %roc_auc_sp_ann)\n",
    "plt.plot(false_positive_rate_nodr_ann, recall_nodr_ann, 'r', label = 'AUC DNN = %0.3f' %roc_auc_nodr_ann)\n",
    "plt.plot(false_positive_rate_ae_RF, recall_ae_RF, 'c', label = 'AUC AE + RF = %0.3f' %roc_auc_ae_RF)\n",
    "plt.plot(false_positive_rate_spae_RF, recall_spae_RF, 'm', label = 'AUC SAE + RF = %0.3f' %roc_auc_spae_RF)\n",
    "plt.plot(false_positive_rate_pca_RF, recall_pca_RF, 'black', label = 'AUC PCA + RF = %0.3f' %roc_auc_pca_RF)\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "# plt.ylim([0.97,1.0])\n",
    "\n",
    "plt.ylabel('Recall - TPR', fontsize=14)\n",
    "plt.xlabel('Fall-out (1-Specificity) - FPR', fontsize=14)\n",
    "plt.savefig('./Figures/ROC_allmodels'+str(dsnum)+'bal_minmax.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.title('Receiver Operating Characteristic (ROC) Zoom in', fontsize=16)\n",
    "\n",
    "plt.plot(false_positive_rate_ae_ann, recall_ae_ann, 'b', label = 'AUC AE + DNN = %0.3f' %roc_auc_ae_ann)\n",
    "plt.plot(false_positive_rate_sp_ann, recall_sp_ann, 'g', label = 'AUC SAE + DNN = %0.3f' %roc_auc_sp_ann)\n",
    "plt.plot(false_positive_rate_nodr_ann, recall_nodr_ann, 'r', label = 'AUC DNN = %0.3f' %roc_auc_nodr_ann)\n",
    "plt.plot(false_positive_rate_ae_RF, recall_ae_RF, 'c', label = 'AUC AE + RF = %0.3f' %roc_auc_ae_RF)\n",
    "plt.plot(false_positive_rate_spae_RF, recall_spae_RF, 'm', label = 'AUC SAE + RF = %0.3f' %roc_auc_spae_RF)\n",
    "plt.plot(false_positive_rate_pca_RF, recall_pca_RF, 'black', label = 'AUC PCA + RF = %0.3f' %roc_auc_pca_RF)\n",
    "\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.plot([0,1], [0,1], 'r--')\n",
    "plt.xlim([0.0,1.0])\n",
    "# plt.ylim([0.0,1.0])\n",
    "plt.ylim([0.955,1.0])\n",
    "\n",
    "plt.ylabel('Recall - TPR', fontsize=14)\n",
    "plt.xlabel('Fall-out (1-Specificity) - FPR', fontsize=14)\n",
    "plt.savefig('./Figures/ROC_allmodels'+str(dsnum)+'bal_zoom.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)\n",
    "# labels = ['Normal', 'Malicious']\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.heatmap(cm,xticklabels=labels, yticklabels=labels, annot=True, fmt='d', cmap=sns.light_palette(\"purple\"), vmin = 0.2);\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('True Class')\n",
    "# plt.xlabel('Predicted Class')\n",
    "# plt.savefig('./Figures/CM_ae_ann_thirdds'+str(dsnum)+'bal_TEST.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_ae_ann = \"AE+DNN\"\n",
    "acc_ae_ann = (sm.accuracy_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_ae_ann = (sm.precision_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_ae_ann = (sm.recall_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_ae_ann = (sm.f1_score(test_y, pred_ae_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "classi_sp_ann = \"SAE+DNN\"\n",
    "acc_sp_ann = (sm.accuracy_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_sp_ann = (sm.precision_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_sp_ann = (sm.recall_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_sp_ann = (sm.f1_score(test_y, pred_sp_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "classi_nodr_ann = \"DNN\"\n",
    "acc_nodr_ann = (sm.accuracy_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "pre_nodr_ann = (sm.precision_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "recall_nodr_ann = (sm.recall_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100) \n",
    "f1score_nodr_ann = (sm.f1_score(test_y, pred_nodr_ann_2h_01_unisoftsigbinlosadam)*100)\n",
    "\n",
    "classi_ae_RF = \"AE+RF\"\n",
    "acc_ae_RF = (sm.accuracy_score(test_y, pred_y_ae_RF)*100) \n",
    "pre_ae_RF = (sm.precision_score(test_y, pred_y_ae_RF)*100) \n",
    "recall_ae_RF = (sm.recall_score(test_y, pred_y_ae_RF)*100) \n",
    "f1score_ae_RF = (sm.f1_score(test_y, pred_y_ae_RF)*100)\n",
    "\n",
    "classi_spae_RF = \"SAE+RF\"\n",
    "acc_spae_RF = (sm.accuracy_score(test_y, pred_y_spae_RF)*100) \n",
    "pre_spae_RF = (sm.precision_score(test_y, pred_y_spae_RF)*100) \n",
    "recall_spae_RF = (sm.recall_score(test_y, pred_y_spae_RF)*100) \n",
    "f1score_spae_RF = (sm.f1_score(test_y, pred_y_spae_RF)*100)\n",
    "\n",
    "classi_pca_RF = \"PCA+RF\"\n",
    "acc_pca_RF = (sm.accuracy_score(test_y, pred_y_pca_RF)*100) \n",
    "pre_pca_RF = (sm.precision_score(test_y, pred_y_pca_RF)*100) \n",
    "recall_pca_RF = (sm.recall_score(test_y, pred_y_pca_RF)*100) \n",
    "f1score_pca_RF = (sm.f1_score(test_y, pred_y_pca_RF)*100)\n",
    "\n",
    "\n",
    "print('Classifier\\tAcc\\tPreci\\tRecall\\tF1Score')\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_ae_ann, acc_ae_ann, pre_ae_ann, recall_ae_ann, f1score_ae_ann))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_sp_ann, acc_sp_ann, pre_sp_ann, recall_sp_ann, f1score_sp_ann))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_nodr_ann, acc_nodr_ann, pre_nodr_ann, recall_nodr_ann, f1score_nodr_ann))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_ae_RF, acc_ae_RF, pre_ae_RF, recall_ae_RF, f1score_ae_RF))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_spae_RF, acc_spae_RF, pre_spae_RF, recall_spae_RF, f1score_spae_RF))\n",
    "print('{0:}\\t\\t{1:.2f}\\t{2:.2f}\\t{3:.2f}\\t{4:.2f}'.format(classi_pca_RF, acc_pca_RF, pre_pca_RF, recall_pca_RF, f1score_pca_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1list = [[\"AE+DNN\",f1score_ae_ann],[\"SAE+DNN\",f1score_sp_ann],[\"DNN\",f1score_nodr_ann],\n",
    "          [\"AE+RF\",f1score_ae_RF],[\"SAE+RF\",f1score_spae_RF],[\"PCA+RF\",f1score_pca_RF]]\n",
    "\n",
    "xs, ys = [*zip(*f1list)]\n",
    "\n",
    "'{:.2f}'.format(f1score_ae_ann)\n",
    "\n",
    "plt.figure(figsize=(8,6), )\n",
    "plt.barh(xs, ys, color = \"purple\")\n",
    "plt.title(\"F1 score vs Classifier\", fontsize=16)\n",
    "plt.xlabel(\"Classifier\", fontsize=14)\n",
    "plt.ylabel(\"F1 score\", fontsize=14)\n",
    "plt.xticks(np.arange(0, 101, 10), fontsize=12)\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "for i, v in enumerate(ys):\n",
    "    plt.text(v+1, i+0.1, '{:.2f}'.format(v), color='purple', fontsize=14)\n",
    "\n",
    "plt.savefig('./Figures/F1scoreplot_allmodels'+str(dsnum)+'bal_minmax.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
